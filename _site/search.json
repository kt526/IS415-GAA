[
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "",
    "text": "Human mobility, the movement of human beings in space and time, reflects the spatial-temporal characteristics of human behavior. With the advancement Information and Communication Technologies (ICT) especially smart phone, a large volume of data related to human mobility have been collected. By using appropriate GIS analysis methods, these data are potentially useful in supporting smart city planning and management.\nIn Singapore, one of the important source of data related to human mobility is from Land Transport Authority (LTA) DataMall. Two data sets related to human mobility are provided by the portal, they are: Passenger Volume by Origin Destination Train Stations and Passenger Volume by Origin Destination Bus Stops. One of the limitation of these data sets is that their location are biased to either bus stops or MRT/LRT stations. In 2020, another very interesting human mobility data set called Grab Posisi was released by GRAB, one of the largest shared taxi operator in South-east Asia. There are two data sets been released and one of them is for Singapore.\n\n\n\nGeospatial analytics hold tremendous potential to address complex problems facing society.\nIn this study, we will be working on the following tasks:\n\nApply appropriate spatial point patterns analysis methods\nDiscover the geographical and spatial-temporal distribution of Grab hailing services locations in Singapore\n\n\n\n\nIn this take-home exercise, we will be using the following packages:\n\n\n\nPackage Name\nDescription\n\n\n\n\narrow\narrow for reading in parquet files\n\n\ngifski\ngifski for rendering GIF animations\n\n\nlubridate\nlubridate for working with datetimes\n\n\nmaptools\nmaptools for manipulating geospatial data\nNote: Package maptools has been removed from CRAN repository. We would need to install from their archived repository.\n\n\ntidyverse\ntidyverse for performing data science tasks such as importing, wrangling and visualising data\n\n\ntmap\ntmap for creating thematic maps\n\n\nraster\nraster for writing, manipulating, analyzing and modeling gridded spatial data\n\n\nsf\nsf for handling geospatial data\n\n\nsp\nsp for managing SpatialPointsDataFrame, SpatialLinesDataFrame and performing projection transformation\n\n\nspatstat\nspatstat for performing point pattern analysis and deriving the kernel density estimation (KDE) layer\n\n\nspNetwork\nspNetwork for performing spatial analysis on network\n\n\n\nLet’s load in the packages using p_load() of pacman package.\n\npacman::p_load(arrow, gifski, lubridate, maptools, tidyverse, tmap,\n               raster, reshape2, sf, sp, spatstat, spNetwork)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#overview---setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#overview---setting-the-scene",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "",
    "text": "Human mobility, the movement of human beings in space and time, reflects the spatial-temporal characteristics of human behavior. With the advancement Information and Communication Technologies (ICT) especially smart phone, a large volume of data related to human mobility have been collected. By using appropriate GIS analysis methods, these data are potentially useful in supporting smart city planning and management.\nIn Singapore, one of the important source of data related to human mobility is from Land Transport Authority (LTA) DataMall. Two data sets related to human mobility are provided by the portal, they are: Passenger Volume by Origin Destination Train Stations and Passenger Volume by Origin Destination Bus Stops. One of the limitation of these data sets is that their location are biased to either bus stops or MRT/LRT stations. In 2020, another very interesting human mobility data set called Grab Posisi was released by GRAB, one of the largest shared taxi operator in South-east Asia. There are two data sets been released and one of them is for Singapore."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "",
    "text": "Geospatial analytics hold tremendous potential to address complex problems facing society.\nIn this study, we will be working on the following tasks:\n\nApply appropriate spatial point patterns analysis methods\nDiscover the geographical and spatial-temporal distribution of Grab hailing services locations in Singapore"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#getting-started",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "",
    "text": "In this take-home exercise, we will be using the following packages:\n\n\n\nPackage Name\nDescription\n\n\n\n\narrow\narrow for reading in parquet files\n\n\ngifski\ngifski for rendering GIF animations\n\n\nlubridate\nlubridate for working with datetimes\n\n\nmaptools\nmaptools for manipulating geospatial data\nNote: Package maptools has been removed from CRAN repository. We would need to install from their archived repository.\n\n\ntidyverse\ntidyverse for performing data science tasks such as importing, wrangling and visualising data\n\n\ntmap\ntmap for creating thematic maps\n\n\nraster\nraster for writing, manipulating, analyzing and modeling gridded spatial data\n\n\nsf\nsf for handling geospatial data\n\n\nsp\nsp for managing SpatialPointsDataFrame, SpatialLinesDataFrame and performing projection transformation\n\n\nspatstat\nspatstat for performing point pattern analysis and deriving the kernel density estimation (KDE) layer\n\n\nspNetwork\nspNetwork for performing spatial analysis on network\n\n\n\nLet’s load in the packages using p_load() of pacman package.\n\npacman::p_load(arrow, gifski, lubridate, maptools, tidyverse, tmap,\n               raster, reshape2, sf, sp, spatstat, spNetwork)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extracting-geospatial-and-aspatial-data-sets",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extracting-geospatial-and-aspatial-data-sets",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "2.1 Extracting Geospatial and Aspatial Data Sets",
    "text": "2.1 Extracting Geospatial and Aspatial Data Sets\nStart by creating a new folder labeled Take-home_Ex01. Within this folder, create a sub-folder named data. Inside the data sub-folder, create two additional sub-folders and rename them geospatial and aspatial respectively.\nUnzip the malaysia-singapore-brunei-latest-free.shp.zip and MPSZ-2019.zip folders and place all files into geospatial sub-folder.\nPlace all files from GrabPosisi into aspatial sub-folder.\n\n\n\n\n\n\nTip\n\n\n\nDid you observe that the file names from GrabPosisi are quite lengthy? Shortening them could make processing more convenient later on.\nAlternatively, we can list.files() to get a list of filenames that contains .parquet extension."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-aggregation-importing-and-combining-aspatial-parquet-files",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-aggregation-importing-and-combining-aspatial-parquet-files",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "3.1 Data Aggregation: Importing and Combining Aspatial parquet files",
    "text": "3.1 Data Aggregation: Importing and Combining Aspatial parquet files\n\n# Use list.files to get a list of filenames that match the pattern\nparquet_files &lt;- list.files(path = \"data/aspatial\", pattern = \"\\\\.parquet$\", full.names = TRUE)\n\ngrab_data &lt;- data.frame()\n\nfor (file_path in parquet_files) {\n  grab_data &lt;- bind_rows(grab_data, read_parquet(file_path))\n}"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-export-writing-dataframe-to-rds-file",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-export-writing-dataframe-to-rds-file",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "3.2 Data Export: Writing DataFrame to RDS file",
    "text": "3.2 Data Export: Writing DataFrame to RDS file\n\nwrite_rds(grab_data, \"data/rds/grab_data.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-import",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-import",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "3.3 Data Import",
    "text": "3.3 Data Import\n\n3.3.1 Importing Aspatial Data - Grab Posisi data in RDS format\n\nReading file using read_rds()Displaying file structure using str()\n\n\n\ngrab_df &lt;- read_rds(\"data/rds/grab_data.rds\")\n\n\n\n\nstr(grab_df)\n\n'data.frame':   30329685 obs. of  9 variables:\n $ trj_id       : chr  \"70014\" \"73573\" \"75567\" \"1410\" ...\n $ driving_mode : chr  \"car\" \"car\" \"car\" \"car\" ...\n $ osname       : chr  \"android\" \"android\" \"android\" \"android\" ...\n $ pingtimestamp: int  1554943236 1555582623 1555141026 1555731693 1555584497 1555395258 1554768955 1554783532 1554898418 1555593189 ...\n $ rawlat       : num  1.34 1.32 1.33 1.26 1.28 ...\n $ rawlng       : num  104 104 104 104 104 ...\n $ speed        : num  18.9 17.7 14 13 14.8 ...\n $ bearing      : int  248 44 34 181 93 73 82 321 324 31 ...\n $ accuracy     : num  3.9 4 3.9 4 3.9 ...\n\n\n\n\n\nWhat we can observe is that the grab data contains 30329685 observations and 9 variables. Notice that pingtimestamp is in the wrong format. It should be in date/time format and not integer. We will need to convert the data type in the next section (Data Preparation).\n\n\n3.3.2 Importing Geospatial Data - Road data in shapefile format\nWe can import geospatial data into RStudio using st_read() of sf package. Let’s try it now!\n\nReading file using st_read()Displaying file structure using str()\n\n\n\nroads_sf &lt;- st_read(dsn=\"data/geospatial\",\n                   layer=\"gis_osm_roads_free_1\")\n\nReading layer `gis_osm_roads_free_1' from data source \n  `C:\\kt526\\IS415-GAA\\Take-home_Ex\\Take-home_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1759836 features and 10 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 99.66041 ymin: 0.8021131 xmax: 119.2601 ymax: 7.514393\nGeodetic CRS:  WGS 84\n\n\n\n\n\nstr(roads_sf)\n\nClasses 'sf' and 'data.frame':  1759836 obs. of  11 variables:\n $ osm_id  : chr  \"4386520\" \"4578273\" \"4579495\" \"4579533\" ...\n $ code    : int  5113 5114 5122 5122 5122 5122 5141 5122 5122 5122 ...\n $ fclass  : chr  \"primary\" \"secondary\" \"residential\" \"residential\" ...\n $ name    : chr  \"Orchard Road\" \"Jalan Bukit Bintang\" \"Jalan Nagasari\" \"Persiaran Raja Chulan\" ...\n $ ref     : chr  NA NA NA NA ...\n $ oneway  : chr  \"F\" \"F\" \"B\" \"B\" ...\n $ maxspeed: int  50 0 0 0 0 0 0 0 0 0 ...\n $ layer   : num  0 0 0 0 0 0 -1 0 0 0 ...\n $ bridge  : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ tunnel  : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ geometry:sfc_LINESTRING of length 1759836; first list element:  'XY' num [1:2, 1:2] 103.83 103.83 1.31 1.31\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA\n  ..- attr(*, \"names\")= chr [1:10] \"osm_id\" \"code\" \"fclass\" \"name\" ...\n\n\n\n\n\n\n\n3.3.3 Importing Geospatial Data - Master Plan 2019 Subzone Boundary (No Sea) in shapefile format\n\nReading file using st_read()Displaying file structure using str()\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\kt526\\IS415-GAA\\Take-home_Ex\\Take-home_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\n\n\nstr(mpsz_sf)\n\nClasses 'sf' and 'data.frame':  332 obs. of  7 variables:\n $ SUBZONE_N : chr  \"MARINA EAST\" \"INSTITUTION HILL\" \"ROBERTSON QUAY\" \"JURONG ISLAND AND BUKOM\" ...\n $ SUBZONE_C : chr  \"MESZ01\" \"RVSZ05\" \"SRSZ01\" \"WISZ01\" ...\n $ PLN_AREA_N: chr  \"MARINA EAST\" \"RIVER VALLEY\" \"SINGAPORE RIVER\" \"WESTERN ISLANDS\" ...\n $ PLN_AREA_C: chr  \"ME\" \"RV\" \"SR\" \"WI\" ...\n $ REGION_N  : chr  \"CENTRAL REGION\" \"CENTRAL REGION\" \"CENTRAL REGION\" \"WEST REGION\" ...\n $ REGION_C  : chr  \"CR\" \"CR\" \"CR\" \"WR\" ...\n $ geometry  :sfc_MULTIPOLYGON of length 332; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:300, 1:2] 104 104 104 104 104 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA\n  ..- attr(*, \"names\")= chr [1:6] \"SUBZONE_N\" \"SUBZONE_C\" \"PLN_AREA_N\" \"PLN_AREA_C\" ...\n\n\n\n\n\nWe can observe that both roads_sf and mpsz_sf are currently using the WGS 84 geographic coordinate system.\n\n\n\n\n\n\nSummary Points\n\n\n\nAfter looking at the file structure and contents of the 3 datasets, we need to perform the following preparations:\n\ngrab_df\n\nConverting data type\nExtracting trip starting location\nConverting aspatial data into geospatial data\nGetting grab data points within Downtown Core\n\nroads_sf and mpsz_sf\n\nPerforming projection transformations\nExtracting study area\nCreating owin object\nGetting road layer within Singapore excluding outer islands"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-preparation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-preparation",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "3.4 Data Preparation",
    "text": "3.4 Data Preparation\ngrab_df\n\n3.4.1 Preparing and Converting grab_df into grab_sf (sf tibble data.framedata)\n\n# Converting data type using as_datetime()\n1grab_df$pingtimestamp &lt;- as_datetime(grab_df$pingtimestamp)\n\n# Checking first n rows of data frame using head()\n2head(grab_df)\n\ngrab_origins_sf &lt;- grab_df %&gt;% \n  group_by(trj_id) %&gt;% \n  arrange(pingtimestamp) %&gt;% \n  filter(row_number()==1) %&gt;%\n  mutate(weekday = wday(pingtimestamp,\n                        label=TRUE,\n                        abbr=TRUE),\n         start_hr = hour(pingtimestamp),\n         day = mday(pingtimestamp),\n         date_col = date(pingtimestamp)) %&gt;%\n3  st_as_sf(coords = c(\"rawlng\", \"rawlat\"),\n           crs = 4326) %&gt;%\n4  st_transform(crs = 3414)\n\n# Getting geometry details using st_geometry()\nst_geometry(grab_origins_sf)\n\n\n1\n\nConverting data type for pingtimestamp from integer into datetime using as_datetime() from lubridate package\n\n2\n\nBy default, the head() returns the first 6 rows\n\n3\n\nConverting grab_df into sf tibble data.frame using st_as_sf() and its location information\n\n4\n\nTransforming coordinates using st_transform()\n\n\n\n\n  trj_id driving_mode  osname       pingtimestamp   rawlat   rawlng    speed\n1  70014          car android 2019-04-11 00:40:36 1.342326 103.8890 18.91000\n2  73573          car android 2019-04-18 10:17:03 1.321781 103.8564 17.71908\n3  75567          car android 2019-04-13 07:37:06 1.327088 103.8613 14.02155\n4   1410          car android 2019-04-20 03:41:33 1.262482 103.8238 13.02652\n5   4354          car android 2019-04-18 10:48:17 1.283799 103.8072 14.81294\n6  32630          car android 2019-04-16 06:14:18 1.300330 103.9062 23.23818\n  bearing accuracy\n1     248      3.9\n2      44      4.0\n3      34      3.9\n4     181      4.0\n5      93      3.9\n6      73      3.9\nGeometry set for 28000 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3628.243 ymin: 25198.14 xmax: 49845.23 ymax: 49689.64\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\n\n\n3.4.2 Creating ppp objects\n\ngrab_origins_ppp &lt;- grab_origins_sf %&gt;%\n  as('Spatial') %&gt;%\n  as('SpatialPoints') %&gt;%\n  as('ppp')\nsummary(grab_origins_ppp)\n\nPlanar point pattern:  28000 points\nAverage intensity 2.473666e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [3628.24, 49845.23] x [25198.14, 49689.64] units\n                    (46220 x 24490 units)\nWindow area = 1131920000 square units\n\n\nThe presence of duplicates can affect the spatial point pattern analysis. Let us check if our grab_origins_ppp contains any duplicated points.\n\n# Checking for duplicated points\nany(duplicated(grab_origins_ppp))\n\n[1] FALSE\n\n\n\nplot(grab_origins_ppp)\n\n\n\n\n\n\n3.4.3 Performing projection transformation\nTo perform projection transformation, we will use st_transform(). Additionally, we will also use st_geometry() to inspect the contents of roads_sf and mpsz_sf after the projection transformation.\nroads_sf\n\n# Transforming coordinates using st_transform()\nroads_sf &lt;- st_transform(roads_sf,\n                           crs = 3414)\n\n# Getting geometry details using st_geometry()\nst_geometry(roads_sf)\n\nGeometry set for 1759836 features \nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -434085.6 ymin: -23036.54 xmax: 1759022 ymax: 741993.8\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nmpsz_sf\n\n# Transforming coordinates using st_transform()\nmpsz_sf &lt;- st_transform(mpsz_sf,\n                          crs = 3414)\n\n# Getting geometry details using st_geometry()\nst_geometry(mpsz_sf)\n\nGeometry set for 332 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nNow, we observe that both roads_sf and mpsz_sf are using the SVY21 projected coordinates system.\n\n\n3.4.4 Extracting specific planning area - Downtown Core\nGiven the high computational demands associated with analyzing the entire region of Singapore, our focus will be specifically on the Downtown Core planning area. This targeted approach aims to explore spatial data points within the Central Business District areas.\n\n# extract Downtown core planning area\nsg_downtown_sf &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"DOWNTOWN CORE\")\n\n# plot the mpsz with downtown core\ntmap_mode(\"plot\")\ntm_shape(mpsz_sf) +\n  tm_polygons() +\n  tmap_options(check.and.fix = TRUE) +\ntm_shape(sg_downtown_sf) +\n  tm_fill(col = \"pink\") +\n  tm_layout(main.title = \"Map of Singapore by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2) + \n  tm_view(set.zoom.limits = c(11, 16))\n\n\n\n\nAnd here’s how the zoom in version of Downtown core planning area would look like\n\nplot(sg_downtown_sf[\"SUBZONE_N\"], main = \"DOWNTOWN CORE\", col = \"pink\")\n\n\n\n\n\n\n3.4.5 Creating owin object - Downtown Core\nWe are creating an owin object to confine the analysis to Downtown Core planning area. After creating this object, we use the summary() to get a quick overview of its key features.\n\ndowntown_owin &lt;- as.owin(sg_downtown_sf)\nsummary(downtown_owin)\n\nWindow: polygonal boundary\nsingle connected closed polygon with 637 vertices\nenclosing rectangle: [28896.26, 31980.09] x [27914.19, 31855.48] units\n                     (3084 x 3941 units)\nWindow area = 5083640 square units\nFraction of frame area: 0.418\n\nplot(downtown_owin)\n\n\n\n\n\n\n3.4.6 Combining grab data points with study area - Downtown Core\n\ngrab_origins_dt_ppp &lt;- grab_origins_ppp[downtown_owin]\nplot(grab_origins_dt_ppp, main=\"DOWNTOWN CORE\")\n\n\n\n\n\n\n3.4.7 Getting grab data points within Downtown Core\nTo obtain grab data points within the Downtown Core, we can apply st_intersection() from the sf package to ensure exclusion of other planning areas and outer islands in the analysis.\n\nsg_downtown_grab_sf &lt;- st_intersection(grab_origins_sf, sg_downtown_sf)\n\n\n\n3.4.8 Getting road layer within Singapore excluding outer islands\nSimilarly, to get the road layer within Downtown Core (excluding other planning areas and outer islands), st_intersection() from the sf package will be used.\n\nsg_downtown_road_sf &lt;- st_intersection(roads_sf, sg_downtown_sf)\nsg_downtown_road_sf &lt;- st_cast(sg_downtown_road_sf, \"LINESTRING\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Preface",
    "section": "",
    "text": "Welcome to Geospatial Data Science and Analytics with R. This book aims to share with you the theory, the methods and the R tools specially designed to meet the challenges of analysing geographic problems and data.\n\nLesson Plan\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nHands-on Exercise 1: Geospatial Data Handling and Wrangling with R\n\n\n\n\n\n\n\n\n\n10 min\n\n\n\n\n\n\n  \n\n\n\n\nHands-on Exercise 2: Thematic Mapping and GeoVisualisation with R\n\n\n\n\n\n\n\n\n\n15 min\n\n\n\n\n\n\n  \n\n\n\n\nHands-on Exercise 3A: 1st Order Spatial Point Patterns Analysis Methods\n\n\n\n\n\n\n\n\n\n19 min\n\n\n\n\n\n\n  \n\n\n\n\nHands-on Exercise 3B: Network Constrained Spatial Point Patterns Analysis\n\n\n\n\n\n\n\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\nHands-on Exercise 4: Spatial Weights and Applications\n\n\n\n\n\n\n\n\n\n12 min\n\n\n\n\n\n\n  \n\n\n\n\nHands-on Exercise 5A: Global Measures of Spatial Autocorrelation\n\n\n\n\n\n\n\n\n\n8 min\n\n\n\n\n\n\n  \n\n\n\n\nHands-on Exercise 5B: Local Measures of Spatial Autocorrelation\n\n\n\n\n\n\n\n\n\n14 min\n\n\n\n\n\n\n  \n\n\n\n\nHands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques\n\n\n\n\n\n\n\n\n\n19 min\n\n\n\n\n\n\n  \n\n\n\n\nHands-on Exercise 8: Geograpgically Weighted Regression\n\n\n\n\n\n\n\n\n\n18 min\n\n\n\n\n\n\n  \n\n\n\n\nHands-on Exercise 9: Geographically Weighted Predictive Models\n\n\n\n\n\n\n\n\n\n3 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03_KDE.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03_KDE.html",
    "title": "In-class Exercise 3: kde",
    "section": "",
    "text": "In this in-class exercise, we will be using the following packages:\n\npacman::p_load(sf, spNetwork, tmap, classInt, viridis, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03_KDE.html#getting-started",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03_KDE.html#getting-started",
    "title": "In-class Exercise 3: kde",
    "section": "",
    "text": "In this in-class exercise, we will be using the following packages:\n\npacman::p_load(sf, spNetwork, tmap, classInt, viridis, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03_KDE.html#importing-geospatial-data",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03_KDE.html#importing-geospatial-data",
    "title": "In-class Exercise 3: kde",
    "section": "2.1 Importing Geospatial Data",
    "text": "2.1 Importing Geospatial Data\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\",\n                   layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `C:\\kt526\\IS415-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\nchildcare &lt;- st_read(dsn=\"data/geospatial\",\n                    layer=\"Punggol_CC\")\n\nReading layer `Punggol_CC' from data source \n  `C:\\kt526\\IS415-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03_KDE.html#visualizing-the-geospatial-data",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03_KDE.html#visualizing-the-geospatial-data",
    "title": "In-class Exercise 3: kde",
    "section": "2.2 Visualizing the Geospatial data",
    "text": "2.2 Visualizing the Geospatial data\n\ntmap_mode(\"view\")\ntm_shape(childcare) + \n  tm_dots() + \n  tm_shape(network) +\n  tm_lines()\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\nNote: The sequence of plotting is based on the sequence of the code.\n\n\nlixels &lt;- lixelize_lines(network,\n                         750,\n                         mindist=375)\n\n\nNote: Why 750? An empirical study was done to say people are willingly to walk 750m. 375 is to ensure that its equal distance.\n\nWhat can we learned from the code chunk above:\n\nThe length of lixel, lx_length is set to 750\nthe minimum length of a lixel, mindist is set to 375\n\nGenerating line center points\n\nsamples &lt;- lines_center(lixels)\n\n\nNote: The points are located in the center based on the length\n\n\ndensities &lt;- nkde(network,\n                  events=childcare,\n                  w=rep(1,nrow(childcare)),\n                  samples=samples,\n                  kernel_name = \"quartic\",\n                  bw = 300,\n                  div = \"bw\",\n                  method = \"simple\",\n                  digits=1,\n                  tol=1,\n                  grid_shape = c(1,1),\n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose=TRUE)\n\n\nNote: More important methods are kernel_name and bw.\nWe aggregate events within a 5m radius for faster calculation"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2: R for Geospatial Data Science",
    "section": "",
    "text": "In this in-class exercise, we will be using the following packages:\n\narrow\nlubridate\ntidyverse\ntmap\nsf\n\n\npacman::p_load(arrow, lubridate, tidyverse, tmap, sf)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#getting-started",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#getting-started",
    "title": "In-class Exercise 2: R for Geospatial Data Science",
    "section": "",
    "text": "In this in-class exercise, we will be using the following packages:\n\narrow\nlubridate\ntidyverse\ntmap\nsf\n\n\npacman::p_load(arrow, lubridate, tidyverse, tmap, sf)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-parquet-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-parquet-data",
    "title": "In-class Exercise 2: R for Geospatial Data Science",
    "section": "3.1 Importing parquet data",
    "text": "3.1 Importing parquet data\n\ndf &lt;- read_parquet(\"data/GrabPosisi/part-00000-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet\")\n\nWrite a code chunk to convert the data type of pingtimestamp from character to datetime.\n\ndf$pingtimestamp &lt;- as_datetime(df$pingtimestamp)\n\nWrite a code chunk to save the reformatted df into a new rds called part0.rds. Save the output into a sub-folder called rds.\n\nwrite_rds(df, \"rds/part0.rds\")\n\nUsing the step you learned in previous lesson,\n\nExtract trips’ origin locations\nDerive three new columns for weekday, start_hr and day of the month\nName the output tibble data.frame origin_df\n\n\norigin_df &lt;- df %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(pingtimestamp) %&gt;%\n  filter(row_number()==1) %&gt;%\n  mutate(Weekday = wday(pingtimestamp,\n                        label=TRUE,\n                        abbr=TRUE),\n         start_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\nExtracting trip ending locations\nWrite a code chunk to extract trips’ destination locations. Similarly, derive the weekday, end_hr and day of the month and name the output tibble data.frame destination_df.\n\ndestination_df &lt;- df %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(desc(pingtimestamp)) %&gt;%\n  filter(row_number()==1) %&gt;%\n  mutate(Weekday = wday(pingtimestamp,\n                        label=TRUE,\n                        abbr=TRUE),\n         end_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\nNote: It is recommend to save the output in .rds format.\n\nwrite_rds(origin_df, \"data/rds/origin_df.rds\")\nwrite_rds(destination_df, \"data/rds/destination_df.rds\")\nTo read back our data from the rds folder\norigin_df &lt;- read_rds(\"data/rds/origin_df.rds\")\ndestination_df &lt;- read_rds(\"data/rds/destination_df.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03B.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03B.html",
    "title": "Hands-on Exercise 3B: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "Network constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods special developed for analysing spatial point event occurs on or alongside network. The spatial point event can be locations of traffic accident or childcare centre The network, on the other hand, can be a road network or river network.\n\n\nIn this hands-on exercise, we will be using the following packages:\n\nrgdal\nsp\nspNetwork\ntmap\n\nrgdal is retired and binary is removed from CRAN. However, we can download from Posit Public Package Manager snapshots.\n\ninstall.packages(\"rgdal\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\npacman::p_load(sp, sf, rgdal, spNetwork, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03B.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03B.html#getting-started",
    "title": "Hands-on Exercise 3B: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "In this hands-on exercise, we will be using the following packages:\n\nrgdal\nsp\nspNetwork\ntmap\n\nrgdal is retired and binary is removed from CRAN. However, we can download from Posit Public Package Manager snapshots.\n\ninstall.packages(\"rgdal\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\npacman::p_load(sp, sf, rgdal, spNetwork, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03B.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03B.html#importing-geospatial-data",
    "title": "Hands-on Exercise 3B: Network Constrained Spatial Point Patterns Analysis",
    "section": "3.1 Importing Geospatial Data",
    "text": "3.1 Importing Geospatial Data\nWe will read in the geospatial data sets using the st_read() of sf package and display the structure of the sf data frames using str() of utils package.\n\n3.1.1 Punggol_St\n\nReading file using st_read()Displaying file structure using str()\n\n\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\",\n                   layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\n\n\n\nstr(network)\n\nClasses 'sf' and 'data.frame':  2642 obs. of  3 variables:\n $ LINK_ID : num  1.16e+08 1.16e+08 1.16e+08 1.16e+08 1.16e+08 ...\n $ ST_NAME : chr  \"PUNGGOL RD\" \"PONGGOL TWENTY-FOURTH AVE\" \"PONGGOL SEVENTEENTH AVE\" \"PONGGOL SEVENTEENTH AVE\" ...\n $ geometry:sfc_LINESTRING of length 2642; first list element:  'XY' num [1:2, 1:2] 36547 36559 44575 44614\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA\n  ..- attr(*, \"names\")= chr [1:2] \"LINK_ID\" \"ST_NAME\"\n\n\n\n\n\n\n\n3.1.2 Punggol_CC\n\nReading file using st_read()Displaying file structure using str()\n\n\n\nchildcare &lt;- st_read(dsn=\"data/geospatial\",\n                   layer=\"Punggol_CC\")\n\nReading layer `Punggol_CC' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\n\n\n\nstr(childcare)\n\nClasses 'sf' and 'data.frame':  61 obs. of  2 variables:\n $ Name    : chr  \"kml_10\" \"kml_99\" \"kml_100\" \"kml_101\" ...\n $ geometry:sfc_POINT of length 61; first list element:  'XYZ' num  36174 42550 0\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA\n  ..- attr(*, \"names\")= chr \"Name\""
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03B.html#preparing-the-lixels-objects",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03B.html#preparing-the-lixels-objects",
    "title": "Hands-on Exercise 3B: Network Constrained Spatial Point Patterns Analysis",
    "section": "5.1. Preparing the lixels objects",
    "text": "5.1. Preparing the lixels objects\nBefore computing NetKDE, the SpatialLines object need to be cut into lixels with a specified minimal distance. This task can be performed by using with lixelize_lines() of spNetwork\n\nlixels &lt;- lixelize_lines(network, \n                         700, \n                         mindist = 350)\n\nAfter cut, if the length of the final lixel is shorter than the minimum distance, then it is added to the previous lixel. If NULL, then mindist = maxdist/10. Also note that the segments that are already shorter than the minimum distance are not modified"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03B.html#generating-line-centre-points",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03B.html#generating-line-centre-points",
    "title": "Hands-on Exercise 3B: Network Constrained Spatial Point Patterns Analysis",
    "section": "5.2 Generating line centre points",
    "text": "5.2 Generating line centre points\nNext, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame (i.e.samples) with line centre points.\n\nsamples &lt;- lines_center(lixels)\n\nThe points are located at center of the line based on the length of the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03B.html#performing-netkde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03B.html#performing-netkde",
    "title": "Hands-on Exercise 3B: Network Constrained Spatial Point Patterns Analysis",
    "section": "5.3 Performing NetKDE",
    "text": "5.3 Performing NetKDE\n\ndensities &lt;- nkde(network, \n                  events = childcare,\n                  w = rep(1,nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03B.html#visualizing-netkde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03B.html#visualizing-netkde",
    "title": "Hands-on Exercise 3B: Network Constrained Spatial Point Patterns Analysis",
    "section": "5.4 Visualizing NetKDE",
    "text": "5.4 Visualizing NetKDE\nBefore we can visualise the NetKDE values, we will need to insert the computed density values (i.e. densities) into samples and lixels objects as density field.\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nSince SVY21 projection system is in meters, the computed density values are very small i.e 0.0000005. We need to rescale the density values from number of events per meters to number of events per kilometers.\n\n# rescaling to help the mapping\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\nAnd finally, we can start plotting!\nWe will use functions from tmap package to prepare interactive and high cartographic quality map visualization.\n\ntmap_mode('view')\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\n\n\n\ntmap_mode('plot')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03B.html#network-constrained-g--and-k-function-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03B.html#network-constrained-g--and-k-function-analysis",
    "title": "Hands-on Exercise 3B: Network Constrained Spatial Point Patterns Analysis",
    "section": "5.5 Network Constrained G- and K-Function Analysis",
    "text": "5.5 Network Constrained G- and K-Function Analysis\nIn this section, we are going to perform complete spatial randomness (CSR) test by using kfunctions() of spNetwork package.\nTo get started, let’s formulate our test hypothesis and state the confidence interval we are using:\n\nH0 = The observed spatial point events (i.e distribution of childcare centres) are uniformly distributed over a street network in Punggol Planning Area.\n\n\nkfun_childcare &lt;- kfunctions(network, \n                             childcare,\n                             start = 0, \n                             end = 1000, \n                             step = 50, \n                             width = 50, \n                             nsim = 50, \n                             resolution = 50,\n                             verbose = FALSE, \n                             conf_int = 0.05)\n\nThe output of kfunctions() is a list with the following values:\n\nplotkA, a ggplot2 object representing the values of the k-function\nplotgA, a ggplot2 object representing the values of the g-function\nvaluesA, a DataFrame with the values used to build the plots\n\nWe can visualise the ggplot2 object of k-function in the following manner:\n\nkfun_childcare$plotk\n\n\n\n\nThe blue line is the empirical network K-function of the childcare centres in Punggol planning area. The gray envelop represents the results of the 50 simulations in the interval 2.5% - 97.5%. Because the blue line between the distance of 250m-400m are below the gray area, we can infer that the childcare centres in Punggol planning area resemble regular pattern at the distance of 250m-400m."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "In this hands-on exercise, we will be using the following packages:\n\ntmap for creating thematic maps such as choropleth and proportional symbol maps,\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data\n\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "In this hands-on exercise, we will be using the following packages:\n\ntmap for creating thematic maps such as choropleth and proportional symbol maps,\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data\n\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#extracting-geospatial-and-aspatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#extracting-geospatial-and-aspatial-data-sets",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "2.1 Extracting Geospatial and Aspatial Data Sets",
    "text": "2.1 Extracting Geospatial and Aspatial Data Sets\nFollowing a structure similar to Hands-on Exercise 01, start by creating a new folder labeled Hands-on_Ex02. Within this folder, create a sub-folder named data. Inside the data sub-folder, create two additional sub-folders and rename them geospatial and aspatial respectively.\nUnzip the MasterPlan2014SubzoneBoundaryWebSHP.zip folder and place all files into geospatial sub-folder.\nUnzip the respopagesextod2011to2020.zip folder and place respopagesextod2011to2020.csv into aspatial sub-folder.\n\nNote: Our aspatial data file does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile!"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-geospatial-data",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "3.1 Importing Geospatial Data",
    "text": "3.1 Importing Geospatial Data\nIn the previous exercise, we have learnt to import geospatial data into RStudio by using st_read() of sf package. Let’s try it now!\n\n3.1.1 Importing polygon feature data in shapefile format\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "3.2 Checking the Content of A Simple Feature Data Frame",
    "text": "3.2 Checking the Content of A Simple Feature Data Frame\n\n3.2.1 Working with st_geometry()\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\n\n\n3.2.2 Working with glimpse()\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n3.2.3 Working with head()\n\nhead(mpsz)\n\nSimple feature collection with 6 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 24468.89 ymin: 28369.47 xmax: 32362.39 ymax: 30542.74\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n6        6          7 ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6         BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6 29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-and-converting-attribute-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-and-converting-attribute-data",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "4.1 Importing and Converting Attribute Data",
    "text": "4.1 Importing and Converting Attribute Data\nNext, we will import respopagsex2011to2020.csv file into RStudio using read_csv() of readr package. Save the file into a R dataframe called popdata.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\", show_col_types = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#checking-the-content-of-a-simple-feature-data-frame-1",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#checking-the-content-of-a-simple-feature-data-frame-1",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "4.2 Checking the Content of A Simple Feature Data Frame",
    "text": "4.2 Checking the Content of A Simple Feature Data Frame\n\n4.2.1 Working with glimpse()\n\nglimpse(popdata)\n\nRows: 984,656\nColumns: 7\n$ PA   &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K…\n$ SZ   &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T…\n$ AG   &lt;chr&gt; \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to…\n$ Sex  &lt;chr&gt; \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"M…\n$ TOD  &lt;chr&gt; \"HDB 1- and 2-Room Flats\", \"HDB 3-Room Flats\", \"HDB 4-Room Flats\"…\n$ Pop  &lt;dbl&gt; 0, 10, 30, 50, 0, 0, 40, 0, 0, 10, 30, 60, 0, 0, 40, 0, 0, 10, 30…\n$ Time &lt;dbl&gt; 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011,…\n\n\n\n\n4.2.2 Working with head()\n\nhead(popdata)\n\n# A tibble: 6 × 7\n  PA         SZ                     AG     Sex   TOD                   Pop  Time\n  &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;\n1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 1- and 2-Room …     0  2011\n2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 3-Room Flats       10  2011\n3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 4-Room Flats       30  2011\n4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 5-Room and Exe…    50  2011\n5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HUDC Flats (exclud…     0  2011\n6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males Landed Properties       0  2011"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-preparation",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "4.3 Data Preparation",
    "text": "4.3 Data Preparation\n\n4.3.1 Data wrangling\nTo create a thematic map, it is necessary for us to prepare a data table containing values for the year 2020. This table should encompass variables such as:\n\nYOUNG: age group 0 to 4 until age 20 to 24,\nECONOMY ACTIVE: age group 25 to 29 until age group 60 to 64,\nAGED: age group 65 and above\nTOTAL: all age groups\nDEPENDENCY: the ratio of YOUNG + AGED groups against the ECONOMY ACTIVE group\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n4.3.2 Combine attribute data with geospatial data\nBefore proceeding with the georelational join, an additional step is necessary to standardize the case of values in the PA and SZ fields. This is essential because the PA and SZ fields contain a mix of upper and lowercase characters. Conversely, the SUBZONE_N and PLN_AREA_N fields are consistently in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nFollowing this, we will use left_join() from the dplyr package to merge the geographical data and attribute table using the planning subzone name, denoted as SUBZONE_N and SZ respectively, as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#quick-plotting-choropleth-maps-using-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#quick-plotting-choropleth-maps-using-qtm",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.1 Quick Plotting Choropleth Maps using qtm()",
    "text": "5.1 Quick Plotting Choropleth Maps using qtm()\nA straightforward and quick method for creating a choropleth map with tmap pacakge involves utilizing the qtm(). It is succinct and offers a well-constructed default visualization that is suitable for many scenarios.\nTo generate a static map, tmap_mode() can be employed with the plot option, while for an interactive mode, the view option should be selected. The fill argument is utilized to map the attribute, namely, DEPENDENCY.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#customizing-choropleth-maps-with-tmap-elements",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#customizing-choropleth-maps-with-tmap-elements",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.2 Customizing Choropleth Maps with tmap elements",
    "text": "5.2 Customizing Choropleth Maps with tmap elements\nWhile qtm() is handy for quickly creating choropleth maps, it has a drawback—it makes it challenging to precisely control the appearance of individual map layers. To achieve a high-quality choropleth map with detailed aesthetics, it’s advisable to leverage tmap’s elements, as demonstrated below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n5.2.1 Drawing a base map\nThe fundamental component of tmap is tm_shape(), serving as the cornerstone for constructing maps. To initiate our map creation, we begin with the base map – the fundamental framework onto which we’ll incorporate statistical details. To achieve this, we input the data mpsz_pop2020 into tm_shape() and then enhance it with one or more layer elements, such as tm_fill() and tm_polygons(). Specifically, we use tm_polygons() to outline the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n5.2.2 Drawing a Choropleth Map using tm_polygons()\nTo create a choropleth map illustrating the geographical distribution of a chosen variable by planning subzone, simply assign the target variable (e.g., DEPENDENCY) to tm_polygons(). This straightforward approach allows us to achieve a visual representation similar to qtm().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n5.2.3 Drawing a Choropleth Maps using tm_fill() and tm_border()\nIn fact, tm_polygons() is a wrapper of tm_fill() and tm_border(). With tm_fill(), polygons are shaded using the default color scheme, while tm_borders() adds the shapefile borders to the choropleth map.\nIf we just use tm_fill() on its own…\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nThe shading on the planning subzones reflects their dependency values, but there are no boundaries. Let’s address that:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nThere’s a noticeable difference from using just tm_polygons() – observe the thinner grey borders? This happens because we adjusted the settings for tm_borders. We tweaked parameters like alpha (transparency from 0 to 1), col (border color), lwd (line width), and lty (line type). The default alpha value is typically 1, col is the border color, lwd defaults to 1, and lty defaults to “solid”."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.3 Data Classification methods",
    "text": "5.3 Data Classification methods\nChoropleth maps often use classification methods to group a bunch of data into different categories or classes. In tmap, there are ten methods you can use for this, like fixed, sd, equal, pretty (the default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a classification method, we can simply use the style argument in tm_fill() or tm_polygons().\n\n5.3.1 Built in classification methods\nNow, let’s try using the jenks and equal classification methods with 5 classes!\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n5.3.2 Custom breaks\nFor all the preset styles, the breaks between categories are calculated automatically. However, if you want to customize these breaks, you can explicitly set them using the breaks option in tm_fill().\n\nNote: for tmap, breaks include a minimum and maximum - so if you want n categories, you’ll need to specify n+1 elements in the breaks argument!\n\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we will set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00).\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#customizing-colour-scheme-with-rcolorbrewer",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#customizing-colour-scheme-with-rcolorbrewer",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.4 Customizing colour scheme with RColorBrewer",
    "text": "5.4 Customizing colour scheme with RColorBrewer\ntmap enables the use of color ramps, which can be either user-defined or selected from a set of predefined ramps in the RColorBrewer package.\nTo modify the color, assign your chosen color to the palette parameter in tm_fill().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nDid you notice that the choropleth map is now shaded in blue?\nWe can also reverse the colour shading by adding a “-“ prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#may-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#may-layouts",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.5 May layouts",
    "text": "5.5 May layouts\nMap layout involves bringing together various map elements into a cohesive design. These elements include the objects being mapped, the title, scale bar, compass, margins, and aspect ratios, among others. The color settings and data classification methods we discussed earlier, related to the palette and breakpoints, contribute to shaping the overall look of the map.\n\n5.5.1 Map legend\nIn tmap, various legend options are available to modify the positioning, format, and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n5.5.2 Map style\nTo change a wide variety of layout settings, we can use the tmap_style():\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n5.5.3 Cartographic furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nAnd lastly, reset to the default style with:\n\ntmap_style(\"white\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#facet-maps",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#facet-maps",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.6 Facet maps",
    "text": "5.6 Facet maps\nAt times, comparing maps is often more effective when they are displayed side by side, an arrangement commonly referred to as small multiple maps or facet maps. These arrangements involve organizing numerous maps side-by-side or occasionally stacked vertically. Small multiple maps are particularly useful for illustrating how spatial relationships evolve concerning another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange()\n\n\n5.6.1 By assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\nAssigning multiple values to at least one of the aesthetic arguments:\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n5.6.2 By defining a group-by variable in tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n5.6.3 By creating multiple stand-alone maps with tmap_arrange()\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#mapping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#mapping-spatial-object-meeting-a-selection-criterion",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.7 Mapping Spatial Object Meeting a Selection Criterion",
    "text": "5.7 Mapping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, an alternative approach is to utilize the selection function to map spatial objects that meet specific selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, we will be using sf and tidyverse packages:\n\nsf for handling geospatial data\ntidyverse for performing data science tasks such as importing, wrangling and visualising data\n\n\nNote: Tidyverse consists of a family of R packages, such as readr, tidyr, and dplyr.\n\n\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, we will be using sf and tidyverse packages:\n\nsf for handling geospatial data\ntidyverse for performing data science tasks such as importing, wrangling and visualising data\n\n\nNote: Tidyverse consists of a family of R packages, such as readr, tidyr, and dplyr.\n\n\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#extracting-geospatial-and-aspatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#extracting-geospatial-and-aspatial-data-sets",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "2.1 Extracting Geospatial and Aspatial Data Sets",
    "text": "2.1 Extracting Geospatial and Aspatial Data Sets\nStart by creating a new folder labeled Hands-on_Ex01. Within this folder, create a sub-folder named data. Inside the data sub-folder, create two additional sub-folders and rename them geospatial and aspatial respectively. Take note of this hierarchical structure as we will be using it to manage our datasets for the upcoming exercises.\nUnzip CyclingPath.zip and MasterPlan2014SubzoneBoundaryWebSHP.zip and place all the unzipped files and PreSchoolsLocation.kml into the geospatial sub-folder.\nPlace listings.csv into aspatial sub-folder."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "3.1 Importing Geospatial Data",
    "text": "3.1 Importing Geospatial Data\nThe geospatial data we have are:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format\nCyclingPath, a line feature layer in ESRI shapefile format\nPreSchool, a point feature layer in kml file format\n\nNow that we have obtained our data, it’s time to examine the formats they are in and explore the process of importing them into R using st_read() of sf package. The arguments it takes in depends on the file format.\n\nFor shapefile format, we need to provide two arguments:\n\ndsn: To define the data path, a.k.a, the file directory pointing to the shapefile (no file extension needed!)\nlayer: To provide the name of the shapefile\n\nFor kml format, the only argument we need is the complete path with the kml file extension\n\n\n3.1.1 Importing polygon feature data in shapefile format\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe message above reveals that the geospatial objects are multipolygon features. There are a total of 323 multipolygon features and 15 fields in mpsz simple feature data frame. mpsz is in SVY21 projected coordinates systems. The bounding box provides the x extend and y extend of the data.\n\n\n3.1.2 Importing polyline feature data in shapefile form\n\ncyclingpath &lt;- st_read(dsn = \"data/geospatial\", layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe message above reveals that there are a total of 2558 features and 2 fields in cyclingpath linestring feature data frame and it is in SVY21 projected coordinates system too.\n\n\n3.1.3 Importing GIS data in kml format\n\npreschool &lt;- st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe message above reveals that preschool is a point feature data frame. There are a total of 2290 features and 2 fields. Different from the previous two simple feature data frame, preschool is in WGS 84 coordinates system."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "3.2 Checking the Content of A Simple Feature Data Frame",
    "text": "3.2 Checking the Content of A Simple Feature Data Frame\nIn this sub-section, we will learn different ways to retrieve information related to the content of a simple feature data frame.\n\n3.2.1 Working with st_geometry()\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\n\n\n3.2.2 Working with glimpse()\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n3.2.3 Working with head()\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "4.1 Plotting Geospatial Data",
    "text": "4.1 Plotting Geospatial Data\nIn the field of geospatial data science, simply examining feature information is insufficient. We are also interested to visualize geospatial features, and this can be accomplished by using plot().\nAs illustrated below, the default plot of an sf object showcases a multi-plot visualization of all attributes (up to a reasonable amount).\n\nplot(mpsz)\n\n\n\n\nHowever, there might be occasions when our focus is solely on visualizing a particular attribute…\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\nIn some cases, we may just want to visualize the geometry (map outline):\n\nplot(st_geometry(mpsz))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-projections",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-projections",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "4.2 Working with Projections",
    "text": "4.2 Working with Projections\nMap projection is an important property of geospatial data. To effectively process two sets of geospatial data, we need to ensure that both data are projected using similar coordinate system.\nIn this section, we will learn how to project a simple feature data frame from one coordinate system to another coordinate system. This technical process is referred to as projection transformation.\nThere are two common issues that require projection transformation:\n\nMissing or inaccurate coordinate system\nInappropriate coordinate systems\n\n\n4.2.1 Missing/inaccurate coordinate system\nOne of the common issue that can happen during importing geospatial data into RStudio is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz simple feature data frame is projected in SVY21, the output near the end indicates that EPSG is 9001. This is a wrong EPSG code. The correct EPSG code for SVY21 should be 3414. Let’s change it using st_set_crs() of sf package:\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nNow, let us check the CSR again.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG code is 3414 now.\n\n\n4.2.2 Inappropriate coordinate systems\nRecall the geospatial data that was introduced in [3.1 Importing Geospatial Data]. You might have observed variations in the coordinate systems among the data frames:\n\nmpsz and cyclingpath uses SVY21\npreschool uses WGS 84\n\nWhen we are geoprocessing preschool, we might run into issues due to the inappropriate usage of a geographic coordinate system, especially when distance and/or area measurements are essential for the analysis.\nThus, it is a common practiceto transform original data from geographic coordinate system to projected coordinate system.\nIn the case of preschool, st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\nLet us display the content of preschool3414.\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nNotice that it is now in SVY21 projected coordinate system.\n\nYou might notice a change in the values within the bounding box—they are now extended beyond the typical 0-360 range of decimal degrees commonly used by the majority of geographic coordinate systems."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-and-converting-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-and-converting-aspatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "5.1 Importing and Converting Aspatial Data",
    "text": "5.1 Importing and Converting Aspatial Data\nSince listings.csv is in csv file format, we will use read_csv() of readr package to import it.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,457 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,447 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe output R object is called listings and it is a tibble data frame. There are 4252 rows and 16 columns (not features and fields like in our simple data feature frame!)\n\nTake note of the latitude and longitude fields as we will be using them in the next phase.\n\nWe can convert listing into a simple feature data frame by using st_as_sf() of sf packages.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThis results in the creation of a new simple feature data frame - listings_sf.\n\nglimpse(listings_sf)\n\nRows: 3,457\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 64, 78, 220, 85, 75, 69, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.13, 0.16, 0.30, 0.15, 0.11, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 51, 51, 5, 7, 51, 51, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 55, 91, 91, 183, 183, 54, 365, 183, 183…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 2, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\n\nNotice that a new column called geometry has been added! In addition,longtitude and latitude columns have both been dropped."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "6.1 Buffering",
    "text": "6.1 Buffering\nImagine a bustling town with a popular cycling path that has become a hub for outdoor enthusiasts. The local authority, recognizing the path’s significance, has decided to embark on an ambitious project to upgrade and enhance the existing cycling infrastructure. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. Your role in this exciting venture is to determine the extent of land required and their total area.\nFirstly, let’s compute the 5-meter buffers around the cycling paths using the st_buffer() of sf package:\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nNext, let’s calculate the area of the buffers:\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, let’s find the total land involved with sum():\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "6.2 Point-in-polygon count",
    "text": "6.2 Point-in-polygon count\nHere’s another scenario:\nLet’s say that preschool service group is planning to organize future outreach events and is curious about the number of preschools in each Planning Subzone.\nWe can perform two operations at one go, using both st_intersects() and length().\n\nst_intersects(): To identify pre-schools located inside each Planning Subzone\nlength(): To calculate numbers of pre-schools that fall inside each Planning Subzone\n\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nWe can check the summary statistics of the newly derived PreSch Count field by using summary().\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the Planning Subzone with the most number of pre-school, the top_n() of dplyr package.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nLastly, to find out the density of preschools by Planning Subzone for future outreach events, we will need derive the area of each Planning Subzone using st_area() of sf package:\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html",
    "title": "Hands-on Exercise 3A: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "In this hands-on exercise, we will be using the following packages:\n\nmaptools for manipulating geographic data\n(Note: We will use maptools to convert Spatial objects into ppp format of spatstat)\nraster for reading, writing, manipulating, analyzing and modelling of gridded spatial data\n(Note: We will use raster to convert image output generated by spatstat into raster format)\nsf for handling geospatial data\nspatstat for point pattern analysis\n(Note: We will use spatstat to perform 1st order spatial point patterns analysis and derive kernel density estimation (KDE) layer)\ntmap for creating thematic maps such as choropleth and proportional symbol maps,\n\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\npackage 'maptools' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\user\\AppData\\Local\\Temp\\Rtmpi4HJ43\\downloaded_packages\n\n\n\npacman::p_load(maptools, raster, sf, spatstat, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#getting-started",
    "title": "Hands-on Exercise 3A: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "In this hands-on exercise, we will be using the following packages:\n\nmaptools for manipulating geographic data\n(Note: We will use maptools to convert Spatial objects into ppp format of spatstat)\nraster for reading, writing, manipulating, analyzing and modelling of gridded spatial data\n(Note: We will use raster to convert image output generated by spatstat into raster format)\nsf for handling geospatial data\nspatstat for point pattern analysis\n(Note: We will use spatstat to perform 1st order spatial point patterns analysis and derive kernel density estimation (KDE) layer)\ntmap for creating thematic maps such as choropleth and proportional symbol maps,\n\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\npackage 'maptools' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\user\\AppData\\Local\\Temp\\Rtmpi4HJ43\\downloaded_packages\n\n\n\npacman::p_load(maptools, raster, sf, spatstat, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#extracting-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#extracting-geospatial-data-sets",
    "title": "Hands-on Exercise 3A: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.1 Extracting Geospatial Data Sets",
    "text": "2.1 Extracting Geospatial Data Sets\nFollowing a structure similar to Hands-on Exercise 01, start by creating a new folder labeled Hands-on_Ex03. Within this folder, create a sub-folder named data. Inside the data sub-folder, create one additional sub-folders and rename them geospatial.\nUnzip MasterPlan2014SubzoneBoundaryWebSHP.zip and place all the unzipped files, PreSchoolsLocation.geojson into the geospatial sub-folder."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#importing-geospatial-data",
    "title": "Hands-on Exercise 3A: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "3.1 Importing Geospatial Data",
    "text": "3.1 Importing Geospatial Data\nIn the previous exercises, we have learnt to import geospatial data into RStudio by using st_read() of sf package. Let’s try it now!\n\nchildcare_sf &lt;- st_read(\"data/geospatial/PreSchoolsLocation.geojson\")\n\nReading layer `PreSchoolsLocation' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\geospatial\\PreSchoolsLocation.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\ncoastaloutline_sf &lt;- st_union(mpsz_sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#checking-the-contents-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#checking-the-contents-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 3A: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "3.2 Checking the Contents of A Simple Feature Data Frame",
    "text": "3.2 Checking the Contents of A Simple Feature Data Frame\n\n3.2.1 Using st_geometry() to check for inappropriate coordinate systems\n\nst_geometry(childcare_sf)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\n\nst_geometry(mpsz_sf)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\n\nst_geometry(coastaloutline_sf)\n\nGeometry set for 1 feature \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou might have observed variations in the coordinate systems among the data frames. Recall in Hands-on Exercise 01, it is a common practice to transform original data from geographical coordinate system to projected coordinate system.\n\nchildcare_sf uses WGS 84 (geographic coordinate system)\nmpsz_sf and coastal_outline_sf uses uses SVY21 (projected coordinate system)\n\nLet’s perform projection transformation on childcare_sf and sgsz_sf using st_transform() of sf package.\n\nchildcare3414 &lt;- st_transform(childcare_sf, \n                              crs = 3414)\n\nNow, we will display the contents of childcare3414.\n\nst_geometry(childcare3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nNotice that childcare3414 is now in SVY21 projected coordinate system.\n\n\n3.2.2 Using st_crs() to check for missing/inaccurate coordinate systems\n\nDIY: Using the appropriate sf function you learned in Hands-on Exercise 2, retrieve the referencing system information of these geospatial data.\n\nTo retrieve coordinate reference system from sf object, we need to use st_crs() from sf package.\n\nst_crs(childcare3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nst_crs(coastaloutline_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz_sf and coastaloutline_sf are projected in SVY21, the output near the end indicates that EPSG is 9001. This is a wrong EPSG code. The correct EPSG code for SVY21 should be 3414. Let’s change it using st_transform() of sf package.\n\nDIY: Using the method you learned in Lesson 2, assign the correct crs to mpsz_sf and coastaloutline_sf.\n\n\nmpsz3414 &lt;- st_transform(mpsz_sf, 3414)\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\ncoastaloutline3414 &lt;- st_transform(coastaloutline_sf, 3414)\nst_crs(coastaloutline3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG code are in 3414 now."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#converting-sf-data-frames-to-sps-spatial-class",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#converting-sf-data-frames-to-sps-spatial-class",
    "title": "Hands-on Exercise 3A: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.1 Converting sf data frames to sp’s Spatial* class",
    "text": "5.1 Converting sf data frames to sp’s Spatial* class\nLet’s convert sf data frames into sp’s Spatial* class using as_Spatial() of sf package.\n\nchildcare &lt;- as_Spatial(childcare3414)\nmpsz &lt;- as_Spatial(mpsz3414)\ncoastaloutline &lt;- as_Spatial(coastaloutline3414)\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 2290 \nextent      : 11810.03, 45404.24, 25596.33, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                       Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;3-IN-1 FAMILY CENTRE&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;ST0027&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;DF7EC9C2478FA5A5&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,   &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;Zulfa Kindergarten&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT9603&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;527C1231DDD0FA64&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093632&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\ncoastaloutline\n\nclass       : SpatialPolygons \nfeatures    : 1 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\nNotice that the geospatial data have been converted into their respective sp’s Spatial* classes now."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "Hands-on Exercise 3A: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.2 Converting the Spatial* class into generic sp format",
    "text": "5.2 Converting the Spatial* class into generic sp format\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nmpsz_sp &lt;- as(mpsz, \"SpatialPolygons\")\ncoastaloutline_sp &lt;- as(coastaloutline, \"SpatialPolygons\")\n\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 2290 \nextent      : 11810.03, 45404.24, 25596.33, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nmpsz_sp\n\nclass       : SpatialPolygons \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\ncoastaloutline_sp\n\nclass       : SpatialPolygons \nfeatures    : 1 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "Hands-on Exercise 3A: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.3 Converting the generic sp format into spatstat’s ppp format",
    "text": "5.3 Converting the generic sp format into spatstat’s ppp format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as(childcare_sp, \"ppp\")\n\nNow, let us plot childcare_ppp and examine the different.\n\nplot(childcare_ppp)\n\n\n\n\nWe can take a quick look at the summary statistics of the newly created ppp object by using summary().\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  2290 points\nAverage intensity 2.875673e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis, an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#handling-duplicated-points",
    "title": "Hands-on Exercise 3A: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.4 Handling Duplicated Points",
    "text": "5.4 Handling Duplicated Points\nTo check for duplication in a ppp object, we can do the following:\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of co-incidence point, we will use multiplicity().\n\nmultiplicity(childcare_ppp)\n\nTo know the total number of locations that have more than one point event, we can use sum():\n\nsum(multiplicity(childcare_ppp))\n\n[1] 3676\n\n\nThe output shows that there are 2451 duplicated point events.\nTo view the locations of these duplicate point events, we will plot the childcare data.\n\ntmap_mode(\"view\")\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nThere are 3 ways to handle duplicated points:\n\nDelete the duplicates\nUse jittering\nMake each point “unique” and then attach the duplicates of the points to the patterns as marks\n\nIn this hands-on exercise, we will implement the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp,\n                             retry=TRUE,\n                             nsim=1,\n                             drop=TRUE)\n\n\nDIY: Using the method you learned in previous section, check if any duplicated point in this geospatial data.\n\nTo check for any duplicated point, recall any(duplicated()).\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#creating-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#creating-owin-object",
    "title": "Hands-on Exercise 3A: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.5 Creating owin object",
    "text": "5.5 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nTo convert sg SpatialPolygon object into owin object of spatstat, run the following:\n\nsg_owin &lt;- as(coastaloutline_sp, \"owin\")\n\nThe ouput object can be displayed by using plot() and summary():\n\nplot(sg_owin)\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n80 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1                4  9.47108e+01      1.21e-07\npolygon 2               37  1.29481e+04      1.66e-05\npolygon 3               30  4.28933e+03      5.49e-06\npolygon 4              145  9.61782e+05      1.23e-03\npolygon 5              227  1.10308e+06      1.41e-03\npolygon 6               19  3.09221e+04      3.95e-05\npolygon 7               10  6.60195e+03      8.44e-06\npolygon 8              234  2.08755e+06      2.67e-03\npolygon 9               22  6.74651e+03      8.63e-06\npolygon 10              71  5.63061e+03      7.20e-06\npolygon 11              10  1.99717e+02      2.55e-07\npolygon 12           14663  6.97996e+08      8.93e-01\npolygon 13 (hole)        3 -2.05920e-03     -2.63e-12\npolygon 14 (hole)        3 -2.89050e-05     -3.70e-14\npolygon 15 (hole)        3 -2.83151e-01     -3.62e-10\npolygon 16 (hole)        3 -3.99521e-02     -5.11e-11\npolygon 17 (hole)        3 -4.95057e-02     -6.33e-11\npolygon 18 (hole)        3 -3.65501e-03     -4.67e-12\npolygon 19 (hole)        4 -2.05611e-02     -2.63e-11\npolygon 20 (hole)        3 -1.68316e-04     -2.15e-13\npolygon 21 (hole)       26 -1.25665e+03     -1.61e-06\npolygon 22 (hole)        3 -2.18000e-06     -2.79e-15\npolygon 23 (hole)        3 -6.62377e-01     -8.47e-10\npolygon 24 (hole)        3 -2.09065e-03     -2.67e-12\npolygon 25 (hole)       36 -7.79904e+03     -9.97e-06\npolygon 26 (hole)        3 -8.83647e-03     -1.13e-11\npolygon 27 (hole)        3 -2.21090e+00     -2.83e-09\npolygon 28 (hole)       40 -6.00381e+03     -7.68e-06\npolygon 29 (hole)        7 -1.40545e-01     -1.80e-10\npolygon 30 (hole)       20 -4.39069e+00     -5.62e-09\npolygon 31 (hole)       28 -1.99862e+01     -2.56e-08\npolygon 32 (hole)       48 -1.38338e+02     -1.77e-07\npolygon 33 (hole)      351 -1.21433e+03     -1.55e-06\npolygon 34 (hole)       12 -8.36709e+01     -1.07e-07\npolygon 35 (hole)      317 -5.11280e+04     -6.54e-05\npolygon 36 (hole)       36 -4.01660e+04     -5.14e-05\npolygon 37              30  2.80002e+04      3.58e-05\npolygon 38              27  1.50315e+04      1.92e-05\npolygon 39              15  4.03300e+04      5.16e-05\npolygon 40            1045  4.44510e+06      5.68e-03\npolygon 41 (hole)       13 -3.91907e+02     -5.01e-07\npolygon 42              47  3.82087e+04      4.89e-05\npolygon 43              65  8.42861e+04      1.08e-04\npolygon 44             478  2.06120e+06      2.64e-03\npolygon 45             266  1.50631e+06      1.93e-03\npolygon 46             234  4.72886e+05      6.05e-04\npolygon 47              14  5.86546e+03      7.50e-06\npolygon 48              83  5.28920e+03      6.76e-06\npolygon 49              75  1.73526e+04      2.22e-05\npolygon 50             148  3.10395e+03      3.97e-06\npolygon 51             142  3.22293e+03      4.12e-06\npolygon 52              45  2.51218e+03      3.21e-06\npolygon 53              40  1.38607e+04      1.77e-05\npolygon 54              10  4.90942e+02      6.28e-07\npolygon 55              95  5.96187e+04      7.62e-05\npolygon 56 (hole)        4 -1.86410e-02     -2.38e-11\npolygon 57              64  3.43149e+04      4.39e-05\npolygon 58 (hole)        3 -1.98390e-03     -2.54e-12\npolygon 59 (hole)        3 -5.55856e-03     -7.11e-12\npolygon 60 (hole)        3 -5.12482e-03     -6.55e-12\npolygon 61 (hole)        3 -1.96410e-03     -2.51e-12\npolygon 62 (hole)        4 -1.13774e-02     -1.46e-11\npolygon 63             155  2.67502e+05      3.42e-04\npolygon 64             106  3.04104e+03      3.89e-06\npolygon 65            1027  1.27782e+06      1.63e-03\npolygon 66 (hole)        3 -3.23310e-04     -4.13e-13\npolygon 67 (hole)        3 -1.16959e-03     -1.50e-12\npolygon 68 (hole)        3 -1.46474e-03     -1.87e-12\npolygon 69             211  4.70521e+05      6.02e-04\npolygon 70               4  2.69313e+02      3.44e-07\npolygon 71             132  9.53357e+04      1.22e-04\npolygon 72               6  4.50259e+02      5.76e-07\npolygon 73             285  1.61128e+06      2.06e-03\npolygon 74              91  1.49663e+04      1.91e-05\npolygon 75              71  8.18750e+03      1.05e-05\npolygon 76             668  5.40368e+07      6.91e-02\npolygon 77              77  3.29939e+05      4.22e-04\npolygon 78             711  1.28815e+07      1.65e-02\npolygon 79 (hole)        3 -3.41405e-01     -4.37e-10\npolygon 80              44  2.26577e+03      2.90e-06\nenclosing rectangle: [2667.54, 56396.44] x [15748.72, 50256.33] units\n                     (53730 x 34510 units)\nWindow area = 781945000 square units\nFraction of frame area: 0.422"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#combining-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#combining-point-events-object-and-owin-object",
    "title": "Hands-on Exercise 3A: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.6 Combining point events object and owin object",
    "text": "5.6 Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore.\n\nchildcareSG_ppp &lt;- childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class.\n\nsummary(childcareSG_ppp)\n\n\nDIY: Using the method you learned in previous exercise, plot the newly derived childcareSG_ppp as shown below.\n\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#kernel-density-estimation-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#kernel-density-estimation-kde",
    "title": "Hands-on Exercise 3A: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "6.1 Kernel Density Estimation (KDE)",
    "text": "6.1 Kernel Density Estimation (KDE)\nWhat is Kernel Density Estimation? Kernel Density Estimation, KDE, is a non-parametric technique that estimates the probability density function of a continuous variable. In simple terms, it smooths out your data by placing a kernel (usually a Gaussian kernel is used as default) at each data point and then summing up these kernels to create a continuous curve. This curve offers a more refined view of how data points are distributed across the variable’s range\nRead more about KDE here.\nHow does KDE actually works?\n\n\n\nFig 1. Equation for Gaussian kernel\n\n\nRead more about how KDE works here.\n\n6.1.1 Computing KDE using Automatic Bandwidth Selection method\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                              kernel=\"gaussian\") \n\n\nplot(kde_childcareSG_bw)\n\n\n\n\nNotice how the density values of the legend range from 0 to 0.000035. This is way too small to comprehend ! 👀\nWhy is this the case? This is because the default unit measurement for SVY 21 is in meter.\nAs a result, the density values computer is in ” umber of points per square meter”.\n\nNote: We can retrieve the bandwidth used to compute the KDE layer using bw.diggle().\n\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n295.4419 \n\n\n\n\n6.1.2 Rescaling KDE values\nNoting that the default unit measurement for SVY 21 is in meter, is it possible to convert the unit measurement into kilometer? To do so, we can use the rescale().\n\nchildcareSG_ppp.km &lt;- rescale(childcareSG_ppp, 1000, \"km\")\n\nLet’s run density() using childcareSG_ppp.km (a.k.a. rescaled dataset) and plot out the KDE map.\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp.km,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\nplot(kde_childcareSG_bw)\n\n\n\n\nNotice that output image looks identical to the earlier version, the only changes in the data values (refer to the legend).\n\n\n6.1.3 Working with different automatic bandwidth methods\nBesides bw.diggle(), there are three other spatstat functions that can be used to determine the bandwidth, they are:\n\nbw.CvL(),\nbw.scott(), and\nbw.ppl()\n\nLet’s take a look at the bandwidth returned by these automatic bandwidth calculation methods.\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2954419 \n\n\n\nbw.CvL(childcareSG_ppp.km)\n\n  sigma \n4.54311 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.111666 1.347496 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.2109003 \n\n\nThere is ongoing debate regarding the optimal methods for pattern detection. However, according to a study, it is recommended to employ bw.ppl() when dealing with patterns predominantly characterized by tight clusters. On the other hand, bw.diggle() is suggested for detecting a single tight cluster within a background of random noise. In comparing bw.diggle() and bw.ppl():\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2), mar = c(2, 2, 2, 2))\nplot(kde_childcareSG_bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n6.1.4 Working with different kernel methods\nThe default kernel method employed in density.ppp() is Gaussian. However, there are three alternative options available:\n\nEpanechnikov,\nQuartic, and\nDics\n\n\npar(mfrow=c(2,2), mar = c(2, 2, 2, 2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"),\n     main=\"Disc\")\n\n\n\n\n\n\n6.1.5 Computing KDE by using Fixed Bandwidth\nLet’s compute a KDE layer by defining a bandwidth of 600 meters. We’ll use a sigma value of 0.6 in this case, as the unit of measurement of our childcareSG_ppp.km object is in kilometers, hence the 600m is 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\nA downside of fixed bandwidth is that this method is very sensitive to highly skewed distributions.\n\n\n6.1.6 Computing KDE by using Adaptive Bandwidth\nOne way to overcome this problem is by using adaptive bandwidth with density.adaptive() of spatstat package.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\nWe can now compare the results of fixed and adaptive kernel density estimation.\n\npar(mfrow=c(1,2), mar = c(2, 2, 2, 2))\nplot(kde_childcareSG_bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n6.1.7 Converting KDE output into grid object and grid object into raster\nIn order for a KDE output to be suitable for mapping purposes, we can convert it into a grid object.\n\nNote: The results will be the same.\n\n\ngridded_kde_childcareSG_bw &lt;- as.SpatialGridDataFrame.im(kde_childcareSG_bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\nNext, we will convert the gridded kernal density objects into RasterLayer object by using raster() of raster package.\n\nkde_childcareSG_bw_raster &lt;- raster(gridded_kde_childcareSG_bw)\n\nLet’s take a look at the properties of kde_childcareSG_bw_raster RasterLayer.\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.419757, 0.2695907  (x, y)\nextent     : 2.667538, 56.39644, 15.74872, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -1.227421e-14, 43.27275  (min, max)\n\n\n\nNotice that the crs property is NA.\n\n\n\n6.1.8 Assigning projection systems\nTo assign projection systems:\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.419757, 0.2695907  (x, y)\nextent     : 2.667538, 56.39644, 15.74872, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -1.227421e-14, 43.27275  (min, max)\n\n\nLastly, let’s visualize raster in cartographic quality map using tmap package.\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field.\n\n\n\n6.1.9 Comparing Spatial Point Patterns using KDE\nLet’s compare the KDE of childcare at Punggol, Tampines, Chua Chu Kang and Jurong West planning areas.\n\n6.1.9.1 Extracting study area\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\n\n\n6.1.9.2 Plotting target planning areas\n\npar(mfrow=c(2,2), mar = c(2, 2, 2, 2))\nplot(pg, main = \"PUNGGOL\")\nplot(tm, main = \"TAMPINES\")\nplot(ck, main = \"CHOA CHU KANG\")\nplot(jw, main = \"JURONG WEST\")\n\n\n\n\n\n\n6.1.9.3 Converting the spatial point data frame into generic sp format\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n\n\n6.1.9.4 Creating owin object\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\n\n\n6.1.9.5 Combining childcare points and the study area\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nWe will use rescale() to transform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nLastly, let’s plot out the four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2), mar = c(2, 2, 2, 2))\nplot(childcare_pg_ppp.km, main=\"PUNGGOL\")\nplot(childcare_tm_ppp.km, main=\"TAMPINES\")\nplot(childcare_ck_ppp.km, main=\"CHOA CHU KANG\")\nplot(childcare_jw_ppp.km, main=\"JURONG WEST\")\n\n\n\n\n\n\n6.1.9.6 Computing KDE of four planning areas using Automatic Bandwidth Selection method\nWe will now use the bw.diggle() automatic bandwidth selection to derive the bandwidths for each planning areas.\n\npar(mfrow=c(2,2), mar = c(2, 2, 2, 2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"PUNGGOL\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"TAMPINES\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"CHOA CHU KANG\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JURONG WEST\")\n\n\n\n\n\n\n6.1.9.7 Computing KDE of four planning areas using Fixed Bandwidth Selection method\nFor comparison purposes, let’s also try computing the KDE layers by defining a fixed bandwidth of 250 meters.\n\npar(mfrow=c(2,2), mar = c(2, 2, 2, 2))\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"PUNGGOL\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"TAMPINES\")\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"CHOA CHU KANG\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JURONG WEST\")\n\n\n\n\n\nNote: The sigma value of 0.25 in this case, as the unit of measurement of our childcare_tm_ppp.km object is in kilometers, hence the 250m is 0.25km."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#nearest-neighbor-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03A.html#nearest-neighbor-analysis",
    "title": "Hands-on Exercise 3A: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "6.2 Nearest Neighbor Analysis",
    "text": "6.2 Nearest Neighbor Analysis\nIn this section, we will be performing the Clark-Evans test of aggregation for SPPA, using the clarkevans.test() of statspat package.\nTo get started, let’s formulate our test hypotheses and state the confidence interval we are using:\n\nH0 = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confidence interval will be used.\n\n\nNote:\nNull Hypothesis (H0) – This can be thought of as the implied hypothesis. “Null” meaning “nothing”. This hypothesis states that there is no difference between groups or no relationship between variables. The null hypothesis is a presumption of status quo or no change.\nAlternative Hypothesis (H1) – This is also known as the claim. This hypothesis should state what you expect the data to show, based on your research on the topic. This is your answer to your research question.\nRead more about null and alternative hypotheses here.\n\n\n6.2.1 Testing spatial point patterns using Clark-Evans Test\n1clarkevans.test(childcareSG_ppp,\n2                correction=\"none\",\n3                clipregion=\"sg_owin\",\n4                alternative=c(\"clustered\"),\n5                nsim=99)\n\n1\n\nchildcareSG_ppp: a spatial point pattern - object of class ppp,\n\n2\n\ncorrection: character string of the type of edge correction to be applied; correction=\"none\" denotes no edge correction is applied,\n\n3\n\nclipregion a window for guard area correction - object of class owin,\n\n4\n\nalternative: string indicating the type of alternative for the hypothesis test. Partially matched; alternative=“clustered” denotes the alternative hypothesis is that R &lt; 1 corresponding to a clustered point pattern\n\n5\n\nnsim: number of Monte Carlo simulations to perform\n\n\nNote: If the argument clipregion is given, then the selected edge corrections will be assumed to include correction=\"guard\".\n\n6.2.1.1 Performing Clark-Evans Test in Choa Chu Kang planning area\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.77501, p-value = 4.894e-05\nalternative hypothesis: two-sided\n\n\n\n\n6.2.1.2 Performing Clark-Evans Test in Tampines planning area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.59762, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, we will be using the following packages:\n\nknitr\nsf\nspdep\ntidyverse\ntmap\n\n\npacman::p_load(knitr, sf, spdep, tidyverse, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-started",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, we will be using the following packages:\n\nknitr\nsf\nspdep\ntidyverse\ntmap\n\n\npacman::p_load(knitr, sf, spdep, tidyverse, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-geospatial-data",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "3.1 Importing Geospatial Data",
    "text": "3.1 Importing Geospatial Data\n\n3.1.1 Importing Geospatial Data in shapefile format\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nThe message above reveals that the geospatial objects are polygon features. There are a total of 88 polygon features and 7 fields in hunan_sf. hunan_sf is in WGS 84 geographic coordinates systems. The bounding box provides the x extend and y extend of the data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-aspatial-data",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "3.2 Importing Aspatial Data",
    "text": "3.2 Importing Aspatial Data\n\n3.2.1 Importing Aspatial Data in csv format\nSince Hunan_2012.csv is in csv file format, we will use read_csv() of readr package to import it.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#data-preparation",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "3.3 Data Preparation",
    "text": "3.3 Data Preparation\n\nhunan_joined &lt;- left_join(hunan_sf, hunan2012 )%&gt;%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "4.1 Computing Contiguity Spatial Weights",
    "text": "4.1 Computing Contiguity Spatial Weights\nIn this section, we will be utilizing the poly2nb() from spdep package to calculate contiguity weight matrices within the study area. This function generates a list of neighbors by considering regions with shared boundaries.\n\nNote: The “queen” argument from poly2nb() is set to TRUE as default. If this argument is not given, the default value will be used and a list of first-order neighbors based on the Queen criteria will be provided.\n\n\n4.1.1 Computing (QUEEN) contiguity based neighbours\n\nwm_q &lt;- poly2nb(hunan_joined, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 regions (area units) in Hunan. The most connected region has 11 neighbours. There are two area units with only one neighbour.\nFor each polygon in our polygon object, wm_q lists all the neighboring polygons. Let’s see the neighbors for the first polygon:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors, with each number representing the polygon IDs as stored in our hunan SpatialPolygonsDataFrame class. Let’s try retrieving the county name of Polygon ID=1:\n\nhunan_joined$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nWe can also retrieve the county names of the five neighboring polygons:\n\nhunan_joined$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nTo find out the GDPPC of the five neighboring polygons, we can do the following:\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan_joined$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\nLastly, we can display the complete weight matrix using str():\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan_joined, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output might span across several pages.\n\n\n\n\n4.1.2 Creating (ROOK) contiguity based neighbours\n\n1wm_r &lt;- poly2nb(hunan_joined, queen=FALSE)\nsummary(wm_r)\n\n\n1\n\nWe mentioned previously that the default queen argument is set to TRUE. If we set the queen argument to FALSE, we will be computing the contiguity based neighbours using the rook criteria.\n\n\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 regions (area units) in Hunan. The most connected region has 10 neighbours. There are two area units with only one neighbour."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-contiguity-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-contiguity-weights",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "4.2 Visualising contiguity weights",
    "text": "4.2 Visualising contiguity weights\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan_joined$geometry, ~st_centroid(.x)[[1]])\n\n\nlatitude &lt;- map_dbl(hunan_joined$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object\n\ncoords &lt;- cbind(longitude, latitude)\n\nWe check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n4.2.1 Plotting Queen contiguity based neighbours map\n\nplot(hunan_joined$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n4.2.2 Plotting Rook contiguity based neighbours map\n\nplot(hunan_joined$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"orange\")\n\n\n\n\n\n\n4.2.3 Plotting Rook contiguity based neighbours map\n\npar(mfrow = c(1,2))\nplot(hunan_joined$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch=19, cex=0.6, add=TRUE, col=\"red\")\nplot(hunan_joined$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch=19, cex=0.6, add=TRUE, col=\"orange\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-distance-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-distance-based-neighbours",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "4.3 Computing distance based neighbours",
    "text": "4.3 Computing distance based neighbours\nIn this section, we will learn how to derive distance-based weight matrices by using dnearneigh() of spdep package.\nThe function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n4.3.1 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band. To do so, we will follow the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n4.3.2 Computing fixed distance weight\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\nQuiz: What is the meaning of “Average number of links: 3.681818” shown above?\n\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAlternatively, we can display the weight matrix in another structure by combining table() and card() of spdep package.\n\ntable(hunan_joined$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n4.3.2.1 Plotting fixed distance weight matrix\n\nplot(hunan_joined$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other.\n\npar(mfrow=c(1,2))\nplot(hunan_joined$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan_joined$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n4.3.3 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry .\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nTo display the contents of the matrix, we use str():\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nNotice that each county has six neighbours, no less no more!\n\n4.3.3.1 Plotting fixed distance weight matrix\n\nplot(hunan_joined$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#weights-based-on-idw",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#weights-based-on-idw",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "4.4 Weights based on IDW",
    "text": "4.4 Weights based on IDW\nIn this section, we will learn how to derive a spatial weight matrix based on Inversed Distance method.\nFirst, we will compute the distances between areas by using nbdists() of spdep package.\n\ndist &lt;- nbdists(wm_q, coords, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034\n\n\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values.\nWhile this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.\nFor this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nTo see the weight of the first polygon’s eight neighbors:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.2 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix.\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#application-of-spatial-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#application-of-spatial-weight-matrix",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "4.5 Application of Spatial Weight Matrix",
    "text": "4.5 Application of Spatial Weight Matrix\nThere are four different spatial lagged variables we will be going through in this section, they are:\n\nspatial lag with row-standardized weights,\nspatial lag as a sum of neighbouring values,\nspatial window average, and\nspatial window sum\n\n\n4.5.1 Spatial lag with row-standardized weights\nFirstly, we will compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan_joined$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nRecalled in the previous section, we retrieved the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan_joined$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\nQuestion: Can you see the meaning of Spatial lag with row-standardized weights now?\n\nWe can append the spatially lag GDPPC values onto hunan_joined data frame and display a table to show the average neighboring income values (stored in the Inc.lag object) for each county.\n\nlag.list &lt;- list(hunan_joined$NAME_3, lag.listw(rswm_q, hunan_joined$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan_joined &lt;- left_join(hunan_joined,lag.res)\nhead(hunan_joined)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\n\ngdppc &lt;- qtm(hunan_joined, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan_joined, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n4.5.2 Spatial lag as a sum of neighboring values\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw() to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunan_joined$NAME_3, lag.listw(b_weights2, hunan_joined$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nLet’s examine the results\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNext, we will append the lag_sum GDPPC field into hunan_joined data frame and plot both the GDPPC and Spatial Lag Sum GDPPC for comparison.\n\nhunan_joined &lt;- left_join(hunan_joined, lag.res)\ngdppc &lt;- qtm(hunan_joined, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan_joined, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n4.5.3 Spatial window average\nThe spatial window average uses row-standardized weights and includes the diagonal element. \n\nwm_qs &lt;- include.self(wm_q)\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nLet’s take a good look at the neighbour list of area [1].\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nNotice that now [1] has six neighbours instead of five.\nNow we obtain weights with nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs,\n                             hunan_joined$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan_joined$NAME_3, lag.listw(wm_qs, hunan_joined$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\nhunan_joined &lt;- left_join(hunan_joined, lag_wm_qs.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan_joined %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly,qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\nw_avg_gdppc &lt;- qtm(hunan_joined, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n4.5.4 Spatial window sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nNotice that now [1] has six neighbours instead of five.\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc &lt;- list(hunan_joined$NAME_3, lag.listw(b_weights2, hunan_joined$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame() and append w_sum GDPPC values onto hunan_joined data.frame by using left_join() of dplyr package.\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\n1colnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\nhunan_joined &lt;- left_join(hunan_joined, w_sum_gdppc.res)\n\n\n1\n\nThis line renames the field names of w_sum_gdppc.re object into NAME_3 and w_sum GDPPC respectively\n\n\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table.\n\nhunan_joined %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nw_sum_gdppc &lt;- qtm(hunan_joined, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3: Kernel Density Estimation",
    "section": "",
    "text": "pacman::p_load(maptools, raster, sf, spatstat, tmap, tidyverse)\n\n\nchildcare_sf &lt;- st_read(\"data/geospatial/ChildCareServices.geojson\") %&gt;%\n  st_transform(crs=3414)\n\nReading layer `ChildCareServices' from data source \n  `C:\\kt526\\IS415-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial\\ChildCareServices.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\kt526\\IS415-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nDifferences between st_combine() and st_union()\n\nmpsz_sf %&gt;%\n  st_combine() %&gt;%\n  plot()\n\n\n\n\n\nmpsz_sf %&gt;%\n  st_union() %&gt;%\n  plot()\n\n\n\n\n\nsg_sf &lt;- mpsz_sf %&gt;%\n  st_union()\n\nCreating ppp objects using sf method instead of spatstat (reduces all 3 steps)\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1925 character character \n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\nIn ppp, it is important for us to detect duplicates and remove them. Duplicates are usually found if we are using geo-referencing on postal codes.\nWhat we are doing in jitter is to seperate the points so that they do not overlap.\nPurpose of owin is to define / confine all the data points in the sturdy area.\nCreating owin using sf method\n\nsg_owin &lt;- as.owin(sg_sf) # note that the input has to be a sf layer\n\nExtracting study area using the sf layer\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\n\nplot(pg, main=\"PUNGGOL\")\n\n\n\nplot(tm, main=\"TAMPINES\")\n\n\n\nplot(ck, main=\"CHOA CHU KANG\")\n\n\n\nplot(jw, main=\"JURONG WEST\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4: Spatial weights and Applications",
    "section": "",
    "text": "Recapping on Hands-on Exercise 04\nLoading packages\n\npacman::p_load(dplyr, sf, spdep, tmap, tidyverse, knitr, GWmodel)\n\n\nhunan &lt;- st_read(dsn=\"data/geospatial\",\n                 layer=\"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\kt526\\IS415-GAA\\In-class_Ex\\In-class_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3 Shape_Leng Shape_Area  County\n1 Changde 21098 Anxiang      County   1.869074 0.10056190 Anxiang\n2 Changde 21100 Hanshou      County   2.360691 0.19978745 Hanshou\n3 Changde 21101  Jinshi County City   1.425620 0.05302413  Jinshi\n4 Changde 21102      Li      County   3.474325 0.18908121      Li\n5 Changde 21103   Linli      County   2.289506 0.11450357   Linli\n6 Changde 21104  Shimen      County   4.171918 0.37194707  Shimen\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\n\nhunan2012 &lt;- read.csv(\"data/aspatial/Hunan_2012.csv\")\n\nPerforming relational join on the two data frames\n\nhunan &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\nNote: Realized that we did not explicitly state the unique id for left_join to join by? This is because we have a common column in both of the data frames (county).\n\nWorking with Geographically weighted summary statistics\n\nhunan_sp &lt;- hunan %&gt;%\n  as_Spatial()\n\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = 6, # number of neighbours I want\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)\n\n\nNote:\n\nIf we are using adaptive = TRUE, bw will be based on the number of neighbours\nIf we are using adaptive = FALSE, bw will be based on the fixed distance"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/data/geospatial/MPSZ-2019.html",
    "href": "Take-home_Ex/Take-home_Ex01/data/geospatial/MPSZ-2019.html",
    "title": "IS415 Geospatial Analytics and Applications",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html",
    "title": "Hands-on Exercise 5A: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.\n\n\nIn this hands-on exercise, we will be using the following packages:\n\nsf\nspdep\ntidyverse\ntmap\n\n\npacman::p_load(sf, spdep, tidyverse, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#getting-started",
    "title": "Hands-on Exercise 5A: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, we will be using the following packages:\n\nsf\nspdep\ntidyverse\ntmap\n\n\npacman::p_load(sf, spdep, tidyverse, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#importing-geospatial-data",
    "title": "Hands-on Exercise 5A: Global Measures of Spatial Autocorrelation",
    "section": "3.1 Importing Geospatial Data",
    "text": "3.1 Importing Geospatial Data\n\n3.1.1 Importing Geospatial Data in shapefile format\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\",\n                    layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nThe message above reveals that the geospatial objects are polygon features. There are a total of 88 polygon features and 7 fields in hunan_sf. hunan_sf is in WGS 84 geographic coordinates systems. The bounding box provides the x extend and y extend of the data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#importing-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#importing-aspatial-data",
    "title": "Hands-on Exercise 5A: Global Measures of Spatial Autocorrelation",
    "section": "3.2 Importing Aspatial Data",
    "text": "3.2 Importing Aspatial Data\n\n3.2.1 Importing Aspatial Data in csv format\nSince Hunan_2012.csv is in csv file format, we will use read_csv() of readr package to import it.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#data-preparation",
    "title": "Hands-on Exercise 5A: Global Measures of Spatial Autocorrelation",
    "section": "3.3 Data Preparation",
    "text": "3.3 Data Preparation\n\nhunan_joined &lt;- left_join(hunan_sf, hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\n\nNote: by argument in left_join() uses NULL as default if it is not specified. A natural join will be performed join all variables in common across hunan_sf and hunan2012.\nIn our case, County is the common variable between hunan_sf and hunan2012."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 5A: Global Measures of Spatial Autocorrelation",
    "section": "5.1 Computing Contiguity Spatial Weights",
    "text": "5.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nThe poly2nb() of spdep package is used to compute contiguity weight matrices for the study area.\n\nwm_q &lt;- poly2nb(hunan_joined, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 5A: Global Measures of Spatial Autocorrelation",
    "section": "5.2 Row-standardised weights matrix",
    "text": "5.2 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”).\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#morans-i",
    "title": "Hands-on Exercise 5A: Global Measures of Spatial Autocorrelation",
    "section": "5.3 Moran’s I",
    "text": "5.3 Moran’s I\n\n5.3.1 Performing Moran’s I statistics testing\nIn this section, we will learn how to perform Moran’s I statistics testing by using moran.test() of spdep package.\n\nmoran.test(hunan_joined$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan_joined$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\n\n\n5.3.2 Computing Monte Carlo Moran’s I\nNext, we will perform permutation test for Moran’s I statistic using moran.mc() of spdep package. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm= moran.mc(hunan_joined$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan_joined$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\nQuestion: What statistical conclustion can you draw fro mthe output above?\n\n\n\n5.3.3 Visualising Monte Carlo Moran’s I\nIt is always a good practice for us the examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\nQuestion: What statistical observation can you draw fro mthe output above?\n\n\nChallenge: Instead of using Base Graph to plot the values, plot the values by using ggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#gearys-c",
    "title": "Hands-on Exercise 5A: Global Measures of Spatial Autocorrelation",
    "section": "5.4 Geary’s C",
    "text": "5.4 Geary’s C\n\n5.4.1 Performing Geary’s C statistical testing\nIn this section, we will learn how to perform Moran’s I statistics testing by using geary.test() of spdep package.\n\ngeary.test(hunan_joined$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan_joined$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n5.4.2 Computing Monte Carlo Geary’s C\nNext, we will perform permutation test for Geary’s C statistic using geary.mc() of spdep package. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm=geary.mc(hunan_joined$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan_joined$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n5.4.3 Visualising Monte Carlo Geary’s C\nNext, we will plot a histogram to reveal the distribution of the simulated values\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#compute-morans-i-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#compute-morans-i-correlogram",
    "title": "Hands-on Exercise 5A: Global Measures of Spatial Autocorrelation",
    "section": "6.1 Compute Moran’s I correlogram",
    "text": "6.1 Compute Moran’s I correlogram\nWe will use sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\nNote: In order to use Moran’s I, we need set the method argument in sp.correlogram() to I.\n\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan_joined$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\nHowever, based on the plot output, we might not be able to interpret the results completely. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan_joined$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nQuestion: What statistical observation can you draw from the plot above?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#compute-gearys-c-correlogram-and-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05A.html#compute-gearys-c-correlogram-and-plot",
    "title": "Hands-on Exercise 5A: Global Measures of Spatial Autocorrelation",
    "section": "6.2 Compute Geary’s C correlogram and plot",
    "text": "6.2 Compute Geary’s C correlogram and plot\nSimilar to how we compute Morgan’s I, we will use the same sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. However, this time round, we will use the global spatial autocorrelation used in Geary’s C.\n\nNote: In order to use Geary’s C, we need set the method argument in sp.correlogram() to C.\n\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan_joined$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\nLet’s also print out the analysis report.\n\nprint(GC_corr)\n\nSpatial correlogram for hunan_joined$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html",
    "title": "Hands-on Exercise 5B: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.\n\n\nIn this hands-on exercise, we will be using the following packages:\n\nsf\nspdep\ntidyverse\ntmap\n\n\npacman::p_load(sf, spdep, tidyverse, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#getting-started",
    "title": "Hands-on Exercise 5B: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, we will be using the following packages:\n\nsf\nspdep\ntidyverse\ntmap\n\n\npacman::p_load(sf, spdep, tidyverse, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#importing-geospatial-data",
    "title": "Hands-on Exercise 5B: Local Measures of Spatial Autocorrelation",
    "section": "3.1 Importing Geospatial Data",
    "text": "3.1 Importing Geospatial Data\n\n3.1.1 Importing Geospatial Data in shapefile format\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\",                     layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nThe message above reveals that the geospatial objects are polygon features. There are a total of 88 polygon features and 7 fields in hunan_sf. hunan_sf is in WGS 84 geographic coordinates systems. The bounding box provides the x extend and y extend of the data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#importing-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#importing-aspatial-data",
    "title": "Hands-on Exercise 5B: Local Measures of Spatial Autocorrelation",
    "section": "3.2 Importing Aspatial Data",
    "text": "3.2 Importing Aspatial Data\n\n3.2.1 Importing Aspatial Data in csv format\nSince Hunan_2012.csv is in csv file format, we will use read_csv() of readr package to import it.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#data-preparation",
    "title": "Hands-on Exercise 5B: Local Measures of Spatial Autocorrelation",
    "section": "3.3 Data Preparation",
    "text": "3.3 Data Preparation\n\nhunan_joined &lt;- left_join(hunan_sf, hunan2012)%&gt;%   select(1:4, 7, 15)\n\n\nNote: by argument in left_join() uses NULL as default if it is not specified. A natural join will be performed join all variables in common across hunan_sf and hunan2012.\nIn our case, County is the common variable between hunan_sf and hunan2012."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 5B: Local Measures of Spatial Autocorrelation",
    "section": "5.1 Computing Contiguity Spatial Weights",
    "text": "5.1 Computing Contiguity Spatial Weights\nSimilar to the previous Hands-on Exercise, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nThe poly2nb() of spdep package is used to compute contiguity weight matrices for the study area.\n\nwm_q &lt;- poly2nb(hunan_joined, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 5B: Local Measures of Spatial Autocorrelation",
    "section": "5.2 Row-standardised weights matrix",
    "text": "5.2 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”).\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#cluster-and-outlier-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#cluster-and-outlier-analysis",
    "title": "Hands-on Exercise 5B: Local Measures of Spatial Autocorrelation",
    "section": "5.3 Cluster and Outlier Analysis",
    "text": "5.3 Cluster and Outlier Analysis\nLocal Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable. For instance, if we are studying cancer rates among census tracts in a given city local clusters in the rates mean that there are areas that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.\nIn this section, we will learn how to apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran’s I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.\n\n5.3.1 Computing local Moran’s I\nTo compute local Moran’s I of GDPPC2012 at the county level the localmoran() function of spdep package will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\n\nfips &lt;- order(hunan_joined$County)\nlocalMI &lt;- localmoran(hunan_joined$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\nWe can list the contents of the local Moran matrix derived using printCoefmat().\nNote: We added head() to display the top 6 rows.\n\nprintCoefmat(head(data.frame(\n  localMI[fips,], \n  row.names=hunan_joined$County[fips]),\n  check.names=FALSE))\n\n                   Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua     -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren     -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang   -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing    3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling    2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\n\n\n\n\n5.3.2 Mapping the local Moran’s I\nBefore mapping the local Moran’s I map, we need to append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The output SpatialPolygonDataFrame is called hunan.localMI.\n\nhunan.localMI &lt;- cbind(hunan_joined,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n5.3.3 Mapping local Moran’s I values\nUsing choropleth mapping functions of tmap package, we can plot the local Moran’s I values.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n5.3.4 Mapping local Moran’s I p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n5.3.5 Mapping both local Moran’s I values and p-values\nIf we want to compare choropleth maps for both Moran’s I values and p-values, we can do the fo\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#creating-a-lisa-cluster-map",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#creating-a-lisa-cluster-map",
    "title": "Hands-on Exercise 5B: Local Measures of Spatial Autocorrelation",
    "section": "5.4 Creating a LISA Cluster Map",
    "text": "5.4 Creating a LISA Cluster Map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\n5.4.1 Plotting Moran scatterplot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations. We can plot the Moran’s scatterplot of GDPPC 2012 by using moran.plot() of spdep package.\n\nnci &lt;- moran.plot(hunan_joined$GDPPC, rswm_q,\n                  labels=as.character(hunan_joined$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\nNotice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC.\n\n\n5.4.2 Plotting Moran scatterplot with standardised variable\nFirst we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\nThe as.vector() is added to the end is to make sure that the data type we get out of this is a vector, that map neatly into our dataframe.\n\nhunan_joined$Z.GDPPC &lt;- scale(hunan_joined$GDPPC) %&gt;% \n  as.vector \n\nNow, we are ready to plot the Moran scatterplot again.\n\nnci2 &lt;- moran.plot(hunan_joined$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan_joined$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n5.4.3 Preparing LISA map classes\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n1hunan_joined$lag_GDPPC &lt;- lag.listw(rswm_q, hunan_joined$GDPPC)\n2DV &lt;- hunan_joined$lag_GDPPC - mean(hunan_joined$lag_GDPPC)\n3LM_I &lt;- localMI[,1]\n4signif &lt;- 0.05\n5quadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\n6quadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\n7quadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3\n8quadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4\n9quadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\n1\n\nDerive the spatially lagged variable of interest (i.e. GDPPC)\n\n2\n\nCenter the spatially lagged variable around its mean\n\n3\n\nCenter the Local Moran around its mean\n\n4\n\nSet a statistical significance level for the local Moran\n\n5\n\nDefine the low-low (1) category\n\n6\n\nDefine the low-high (2) category\n\n7\n\nDefine the high-low (3) category\n\n8\n\nDefine the low-high (4) category\n\n9\n\nPlace non-significant Moran in the category 0\n\n\n\n\n\n\n5.4.3 Plotting LISA map\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\n\ngdppc &lt;- qtm(hunan_joined, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05B.html#hot-spot-and-cold-spot-area-analysis",
    "title": "Hands-on Exercise 5B: Local Measures of Spatial Autocorrelation",
    "section": "5.5 Hot Spot and Cold Spot Area Analysis",
    "text": "5.5 Hot Spot and Cold Spot Area Analysis\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\nThe term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\n\n5.5.1 Getis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\n5.5.2 Deriving distance-based spatial weight matrix\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix\n\n\n5.5.2.1 Deriving the centroid\n\nlongitude &lt;- map_dbl(hunan_joined$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan_joined$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n5.5.2.2 Determine the cut-off distance\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\n\n5.5.2.3 Computing fixed and adaptive distance weight matrix\n\nFixed distance weight matrixAdaptive distance weight matrix\n\n\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014\n\n\n\n\n\n\n\n\n5.5.3 Computing Gi statistics\n\nUsing Fixed distance weight matrixUsing Adaptive distance weight matrix\n\n\n\nfips &lt;- order(hunan_joined$County)\ngi.fixed &lt;- localG(hunan_joined$GDPPC, wm62_lw)\n\n\nhunan_fixed.gi &lt;- cbind(hunan_joined, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\n\n\n\nfips &lt;- order(hunan_joined$County)\ngi.adaptive &lt;- localG(hunan_joined$GDPPC, knn_lw)\n\n\nhunan_adaptive.gi &lt;- cbind(hunan_joined, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n\n\n\n5.5.4 Mapping Gi values\n\nUsing Fixed distance weight matrixUsing Adaptive distance weight matrix\n\n\n\ngdppc &lt;- qtm(hunan_joined, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan_fixed.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\n\n\n\n\n\n\ngdppc&lt;- qtm(hunan_joined, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan_adaptive.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#kernel-density-estimation-kde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#kernel-density-estimation-kde",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "4.1 Kernel Density Estimation (KDE)",
    "text": "4.1 Kernel Density Estimation (KDE)\nWe will employ Kernel Density Estimation (KDE) to visualize the spatial distribution patterns of the initial trajectory locations of Grab hailing services (Grab hailing service pickups). This analysis aims to identify regions exhibiting a high concentration of these starting trajectory locations. KDE is a statistical method that allows us to create a smooth representation of the data, helping us uncover areas with dense clusters of Grab hailing service pickups.\nWe will calculate the KDE using the bw.diggle bandwidth parameter and the default smoothing kernel - gaussian. As the default unit of measurement for SVY 21 is in meters, the resulting density values will be expressed in terms of points per square meter. To facilitate a more comprehensible interpretation, we will employ the rescale() to convert the measurement unit from meters to kilometers. This conversion ensures that the density values represent the number of points per square kilometer, providing a more intuitive understanding of the spatial patterns in the data.\n\npar(mfrow=c(2,2))\n\n# KDE with default values\nkde_grab_origins_dt_bw &lt;- density(grab_origins_dt_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nplot(kde_grab_origins_dt_bw, main = \"KDE Grab Origins for Downtown Core\")\n\n# Rescalling KDE values\ngrab_origins_dt_ppp.km &lt;- rescale(grab_origins_dt_ppp, 1000, \"km\")\n\n# KDE with rescaled values\nkde_grab_origins_dt_bw &lt;- density(grab_origins_dt_ppp.km,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nplot(kde_grab_origins_dt_bw, main = \"KDE Grab Origins for Downtown Core\")\n\n\n\n\nUpon comparing the two plots above, the differences in the legends become apparent. It is important to highlight that the resulting plots look the same, with the only differences being reflected in the data values specified in the legends.\n\n4.1.1 Working with different automatic bandwidth methods\n\npar(mfrow=c(1,4))\n# Choosing automatic bandwidth\nplot(density(grab_origins_dt_ppp.km,\n             sigma=bw.CvL,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Using bw.Cv\")\n\nplot(density(grab_origins_dt_ppp.km,\n             sigma=bw.scott,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Using bw.scott\")\n\nplot(density(grab_origins_dt_ppp.km,\n             sigma=bw.diggle,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Using bw.diggle\")\n\nplot(density(grab_origins_dt_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Using bw.ppl\")\n\n\n\n\n\n\n4.1.1 Working with different kernels\n\npar(mfrow=c(1,4))\n# Choosing kernels\nplot(density(grab_origins_dt_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n             main=\"Using gaussian\")\n\nplot(density(grab_origins_dt_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"epanechnikov\"),\n             main=\"Using epanechnikov\")\n\nplot(density(grab_origins_dt_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"quartic\"),\n             main=\"Using quartic\")\n\nplot(density(grab_origins_dt_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"disc\"),\n             main=\"Using Disc\")\n\n\n\n\nSince we did not observe any significant differences across the kernels, we will use the default Gaussian kernel. Thus, we will be using Gaussian kernel with bw.ppl() as our final KDE plot.\n\n  kde_grab_origins_dt_bw_ppl &lt;- density(grab_origins_dt_ppp.km, \n                                      sigma=bw.ppl, \n                                      edge=TRUE,\n                                      kernel=\"gaussian\")\n\nplot(kde_grab_origins_dt_bw_ppl)\n\n\n\n\n\n\n4.1.2 Display KDE Maps on OpenStreetMap\n\n4.1.2.1 Convert to raster for tmap display\n\ngridded_kde_grab_origins_dt_bw_ppl &lt;- as.SpatialGridDataFrame.im(kde_grab_origins_dt_bw_ppl)\nraster_kde_grab_origins_dt_bw_ppl &lt;- raster(gridded_kde_grab_origins_dt_bw_ppl)\n\n\nspplot(gridded_kde_grab_origins_dt_bw_ppl)\n\n\n\n\nLet us take a look at the properties of raster_kde_grab_origins_dt_bw_ppl RasterLayer.\n\nraster_kde_grab_origins_dt_bw_ppl\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.02409239, 0.03079135  (x, y)\nextent     : 28.89626, 31.98009, 27.91419, 31.85548  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -2.057805e-13, 2788.346  (min, max)\n\n\nNotice that the crs property is NA.\n\n\n4.1.2.2 Assigning projection systems\n\nprojection(raster_kde_grab_origins_dt_bw_ppl) &lt;- CRS(\"+init=EPSG:3414 +units=km\")\nraster_kde_grab_origins_dt_bw_ppl\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.02409239, 0.03079135  (x, y)\nextent     : 28.89626, 31.98009, 27.91419, 31.85548  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=km +no_defs \nsource     : memory\nnames      : v \nvalues     : -2.057805e-13, 2788.346  (min, max)\n\n\nNotice that the crs property is completed.\n\n\n4.1.2.3 Display on tmap OpenStreetMap\n\ntmap_mode('view')\n\ntm_basemap('OpenStreetMap') +\n  tm_shape(raster_kde_grab_origins_dt_bw_ppl) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE) + \n  tm_shape(sg_downtown_sf) + \n  tm_borders() +\n  tm_text(\"SUBZONE_N\", size = 0.65)\n\n\n\n\ntmap_mode('plot')\n\nInterpretations of Spatial Analysis from KDE map🔎:\n\nThe specific subzones that have relatively higher concentration are Cecil, Raffles Place and Bugis. They are denoted by the darker green color\nSubzones like Philip and Maxwell have relatively lower concentration. They are denoted by lighter yellow color\nFrom KDE map, we can only infer if a particular area / subzone area is highly or lessly concentrated but not specific road segments\n\nDespite experimenting with various Kernel Density Estimation (KDE) methods and parameters, the interpretability of the generated plots remain constrained by a fundamental limitation of KDE, that is, the inability to comprehensively account for the intricate structure of road networks. The complexity of urban road layouts is not effectively captured by traditional KDE approaches, leading to a less precise representation of spatial patterns. As a consequence, the visualizations may not offer a nuanced understanding of the spatial dynamics, particularly in urban environments with intricate road networks."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#network-kernel-density-estimation-nkde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#network-kernel-density-estimation-nkde",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "4.2 Network Kernel Density Estimation (NKDE)",
    "text": "4.2 Network Kernel Density Estimation (NKDE)\nAs a response to the limitation of KDE, we turn to NKDE. Network KDE considers the constraints and pathways defined by the road network, addressing the shortcomings of KDE by offering a more nuanced and accurate depiction of the concentrated areas for Grab hailing service pickups within urban landscapes.\n\n4.2.1 Visualizing the Geospatial data\nLet us visualize the geospatial data first.\n\ntmap_mode('view')\ntm_shape(sg_downtown_sf) +\n  tm_fill(col = \"SUBZONE_N\", alpha = 0.5) + \n  tm_shape(sg_downtown_road_sf) +\n  tm_lines() + \n  tm_shape(sg_downtown_grab_sf) + \n  tm_dots()\n\n\n\n\n\ntmap_mode('plot')\n\nWe can see that both grab data points and the road networks are confined to the Downtown core planning area. However, it is hard for us to tell which specific road segments are highly concentrated.\n\n\n4.2.2 Preparing the lixel objects and Generating line center points\nLet us prepare the lixel objects and generate the line center points first before we perform NetKDE. We will set the length of a lixel (lx_length) to 700 meters, and the minimum length of a lixel (mindist) to 350 meters.\n\n# splitting the lines as lixels\nlixels &lt;- lixelize_lines(sg_downtown_road_sf, \n                         700, \n                         mindist = 350)\n\n# extracting the center of lixels as sampling points\nsample_pts &lt;- lines_center(lixels)\n\n\n\n4.2.3 Performing NetKDE\nTo identify hot spots of grab origins, we will be performing a simple NKDE with a quartic kernel and bandwidth of 300 meters.\n\n# densities for the simple NKDE\nnkde_simple &lt;- nkde(sg_downtown_road_sf, \n                  events = sg_downtown_grab_sf,\n                  w = rep(1,nrow(sg_downtown_grab_sf)),\n                  samples = sample_pts,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\nTo obtain more readable results, we can multiply the obtained densities by 1000 to get the estimated numbers of grab data points per kilometer.\n\n# adding the densities as new columns to the sampling\nsample_pts$density &lt;- nkde_simple\nlixels$density &lt;- nkde_simple\n\n# rescaling to help the mapping\nsample_pts$density &lt;- sample_pts$density*1000\nlixels$density &lt;- lixels$density*1000\n\nFinally, let us visualize the network kernel density estimate values.\n\ntmap_mode('view')\ntm_shape(sg_downtown_sf) +\n  tm_fill(col = \"SUBZONE_N\", alpha = 0.5) + \n  tm_shape(lixels) +\n  tm_lines(col=\"density\") +\n  tm_shape(sg_downtown_grab_sf) +\n  tm_dots()\n\n\n\n\n\ntmap_mode('plot') \n\nInterpretations of Spatial Analysis from NKDE map🔎:\n\nRoad segments that are darker in color have relatively higher density of grab pickups than road segments that are lighter in color\nSimilar to KDE map, the specific subzones that have relatively higher concentration are Cecil, Raffles Place and Bugis. They are denoted by the darker green color\nSubzones like Philip and Maxwell have relatively lower concentration. They are denoted by lighter yellow color"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#temporal-network-kernel-density-estimation-tnkde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#temporal-network-kernel-density-estimation-tnkde",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "4.3 Temporal Network Kernel Density Estimation (TNKDE)",
    "text": "4.3 Temporal Network Kernel Density Estimation (TNKDE)\nVery often, when dealing with events on a network, it is common for things to happen over time periods. Temporal Network Kernel Density Estimation (TNKDE) helps us to understand not just where events occur on the network, but also when. This approach is able to provide us with a more detailed picture of how events unfold.\nIn this section, we would like to find out:\n\nHow are grab hailing service pickups distributed across the days?\nDoes the concentration of grab hailing service pickups differs across subzones and days?\n\n\n4.3.1 Temporal Dimension\n\nggplot(sg_downtown_grab_sf) + \n  geom_histogram(aes(x = date_col), fill = \"lightblue\", binwidth = 1, color = \"white\") +\n  scale_x_date(breaks = unique(sg_downtown_grab_sf$date_col), labels = unique(sg_downtown_grab_sf$date_col)) +\n  labs(title = \"Distribution of Grab Hailing services over 2 weeks\",\n       x = \"Date\",\n       y = \"Frequency\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1), plot.title = element_text(hjust = 0.5))\n\n\n\n\nIt seems that the bar plot illustrates a non-uniform distribution, suggesting that certain days are experiencing heightened or reduced demand, contributing to variations in the overall biweekly pattern of Grab hailing service pickups. Notably, 2019-04-12, 2019-04-17 and 2019-04-18 emerge as the top three days with the highest Grab hailing service pickups frequencies, indicating that there is an increase demand or activities on these specific dates. Conversely, 2019-04-14, 2019-04-20 and 2019-04-21 stand out as the bottom three days with the lowest service occurrences, suggesting a potential decrease in demand or activity during these periods.\n\n\n4.3.2 Preparing leave one out cross validation\n\nw &lt;- rep(1,nrow(sg_downtown_grab_sf))\nsg_downtown_grab_sf$Time &lt;- sg_downtown_grab_sf$date_col\nstart &lt;- as.POSIXct(min(sg_downtown_grab_sf$date_col), format = \"%Y/%m/%d\")\nsg_downtown_grab_sf$Time &lt;- difftime(sg_downtown_grab_sf$Time, start, units = \"days\")\nsg_downtown_grab_sf$Time &lt;- as.numeric(sg_downtown_grab_sf$Time)\n\ncv_scores &lt;- bws_tnkde_cv_likelihood_calc(\n  bw_net_range = c(200,1100),\n  bw_net_step = 100,\n  bw_time_range = c(10,70),\n  bw_time_step = 10,\n  lines = sg_downtown_road_sf,\n  events = sg_downtown_grab_sf,\n  time_field = \"Time\",\n  w = rep(1, nrow(sg_downtown_grab_sf)),\n  kernel_name = \"quartic\",\n  method = \"discontinuous\",\n  diggle_correction = FALSE,\n  study_area = NULL,\n  max_depth = 10,\n  digits = 2,\n  tol = 0.1,\n  agg = 10,\n  sparse=TRUE,\n  grid_shape=c(1,1),\n  sub_sample=1,\n  verbose = FALSE,\n  check = TRUE)\n\n\nknitr::kable(cv_scores)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10\n20\n30\n40\n50\n60\n70\n\n\n\n\n200\n-70.57674\n-70.74650\n-71.41831\n-71.92215\n-72.32111\n-72.65038\n-72.93034\n\n\n300\n-54.18005\n-55.11196\n-55.80120\n-56.31779\n-56.72682\n-57.06440\n-57.35143\n\n\n400\n-49.37225\n-50.32364\n-51.01893\n-51.53972\n-51.95203\n-52.29228\n-52.58158\n\n\n500\n-46.72133\n-47.68459\n-48.38357\n-48.90684\n-49.32105\n-49.66285\n-49.95345\n\n\n600\n-44.05158\n-45.02121\n-45.72338\n-46.24897\n-46.66502\n-47.00833\n-47.30022\n\n\n700\n-42.79765\n-43.04995\n-43.75432\n-44.28161\n-44.69900\n-45.04343\n-45.33628\n\n\n800\n-42.25632\n-43.22859\n-43.93303\n-44.46033\n-44.87772\n-45.22216\n-45.51500\n\n\n900\n-40.25435\n-41.23169\n-41.93853\n-42.46759\n-42.88637\n-43.23194\n-43.52575\n\n\n1000\n-40.40334\n-41.38194\n-42.08879\n-42.61784\n-43.03662\n-43.38219\n-43.67600\n\n\n1100\n-40.54406\n-41.52340\n-42.23028\n-42.75933\n-43.17811\n-43.52367\n-43.81748\n\n\n\n\n\n\noptimal_value &lt;- max(cv_scores)\n\n# Get the row and column values of the optimal value\noptimal_indices &lt;- which(cv_scores == optimal_value, arr.ind = TRUE)\n\n# Extract the row and column values\noptimal_row &lt;- rownames(cv_scores)[optimal_indices[, \"row\"]]\noptimal_col &lt;- colnames(cv_scores)[optimal_indices[, \"col\"]]\n\n# Display the results\ncat(\"Optimal value:\", optimal_value, \"\\n\")\n\nOptimal value: -40.25435 \n\ncat(\"Optimal meters:\", optimal_row, \"\\n\")\n\nOptimal meters: 900 \n\ncat(\"Optimal days:\", optimal_col, \"\\n\")\n\nOptimal days: 10 \n\n\n\n\n4.3.3 Performing TNKDE\nAccording to the “leave one out cross validation” method, the optimal set of bandwidths is 900 metres and 10 days. We will use these bandwidths to perform a discontinuous TNKDE with a quartic kernel.\n\n# choosing sample in times (every 10 days)\nsample_time &lt;- seq(0, max(sg_downtown_grab_sf$Time), 1)\n\n# calculating densities\ntnkde_densities &lt;- tnkde(lines = sg_downtown_road_sf,\n                   events = sg_downtown_grab_sf,\n                   time_field = \"Time\",\n                   w = rep(1, nrow(sg_downtown_grab_sf)), \n                   samples_loc = sample_pts,\n                   samples_time = sample_time, \n                   kernel_name = \"quartic\",\n                   bw_net = 900, bw_time = 10,\n                   adaptive = TRUE,\n                   trim_bw_net = 900,\n                   trim_bw_time = 80,\n                   method = \"discontinuous\",\n                   div = \"bw\", max_depth = 10,\n                   digits = 2, tol = 0.01,\n                   agg = 15, grid_shape = c(1,1), \n                   verbose  = FALSE)\n\n# creating a color palette for all the densities\nlibrary(classInt)\nlibrary(viridis)\nall_densities &lt;- c(tnkde_densities$k)\ncolor_breaks &lt;- classIntervals(all_densities, n = ncol(tnkde_densities$k), style = \"kmeans\")\n\n\n# generating a map at each sample time\nall_maps &lt;- lapply(1:ncol(tnkde_densities$k), function(i){\n  time &lt;- sample_time[[i]]\n  date &lt;- as.Date(start) + time\n\n  sample_pts$density &lt;- tnkde_densities$k[,i]\n  map1 &lt;- \n    tm_shape(sample_pts) + \n    tm_dots(col = \"density\", size = 0.01,\n          breaks = color_breaks$brks, palette = viridis(10)) + \n    tm_layout(legend.show=FALSE, main.title = as.character(date), main.title.size = 0.5)\n  return(map1)\n})\n\n\n# creating a gif with all the maps\ntmap_animation(all_maps, filename = \"imgs/animated_map.gif\", \n               width = 1000, height = 1000, dpi = 300, delay = 50)\n\nCreating frames\n======\n\n\n=====\n\n\n======\n\n\n======\n\n\n======\n\n\n=====\n\n\n======\n\n\n======\n\n\n=====\n\n\n======\n\n\n======\n\n\n======\n\n\n=====\n\n\n======\n\n\n\nCreating animation\nAnimation saved to C:\\kt526\\IS415-GAA\\Take-home_Ex\\Take-home_Ex01\\imgs\\animated_map.gif \n\n\n\nNote: If target directory specified for saving the GIF file does not exist, we need to create the directory before attempting to save the animated GIF. Check if there is an imgs folder, else create one.\n\n\nknitr::include_graphics(\"imgs/animated_map.gif\")\n\n\n\n\nInterpretations of Spatio Temporal Analysis from TNKDE map🔎:\n\nRoad segments that are greener in color have relatively higher density of Grab hailing service pickups\nThe TNKDE map reveal subtle variations in the concentration of Grab hailing service pickups across different subzones and days over the observed two weeks\nWhile the overall pattern indicates similarities between the NKDE map, the TNKDE map suggest that the Grab hailing service pickups differs slightly from day to day"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation, Emerging Hot Spot Analysis: sfdep methods",
    "section": "",
    "text": "Loading packages\npacman::p_load(sf, tmap, sfdep, tidyverse)\nThe Data\nFor the purpose of this In-class exercise, the Hunan data sets will be used. There are two data sets used in this case, they are:\nImporting geospatial files\nhunan &lt;- st_read(dsn=\"data/geospatial\",\n                 layer=\"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\kt526\\IS415-GAA\\In-class_Ex\\In-class_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nImporting aspatial files\nhunan_2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\nhunan_gdppc &lt;- read_csv(\"data/aspatial/Hunan_GDPPC.csv\")\nPerforming relational join on the two data frames - hunan and hunan_2012\nhunan_gdppc_joined &lt;- left_join(hunan,hunan_2012) %&gt;%\n  select(1:4, 7, 15)\nVisualizing the choropleth map\ntmap_mode('plot')\n\ntm_shape(hunan_gdppc_joined) +\n  tm_fill(\"GDPPC\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by county\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) + \n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\nStep 1: Deriving contiguity weights: Queen’s method\nwm_q &lt;- hunan_gdppc_joined %&gt;%\n1  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n2         .before = 1)\n\n\n1\n\nWe are using Queen’s method as default. To use Rook’s method, write st_contiguity(geometry, queen = FALSE)\n\n2\n\n.before = 1 will put the mutated columns in front of column 1\nComputing Global Moran’s I\nmoran_i &lt;- global_moran(wm_q$GDPPC,\n                        wm_q$nb,\n                        wm_q$wt)\nPerforming Global Moran’s I Permutation test\nIt is always a good practice to use set.seed().\nset.seed(1234)\nglobal_moran_perm() is used to perform Monte Carlo simulation.\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n1                  nsim = 99)\n\n\n1\n\nnsim = 99 will run 100 simulations because the simulations will start from 0\n\n\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "",
    "text": "Dengue Hemorrhagic Fever (in short dengue fever) is one of the most widespread mosquito-borne diseases in the most tropical and subtropical regions. It is an acute disease caused by dengue virus infection which is transmitted by female Aedes aegypti and Aedes albopictus mosquitoes.\nIn 2015, Taiwan had recorded the most severe dengue fever outbreak with more than 43,000 dengue cases and 228 deaths. Since then, the annual reported dengue fever cases were maintained at the level of not more than 200 cases. However, in 2023, Taiwan recorded 26703 dengue fever cases.\n\n\n\nIn this study, we are interested to discover:\n\nIf the distribution of dengue fever outbreak at Tainan City, Taiwan are independent from spatial (space) and spatio-temporal (space-time).\nIf the outbreak is indeed spatial and spatio-temporal dependent, then, you would like to detect where are the clusters and outliers, and the emerging hot spot/cold spot areas.\n\n\n\n\nIn this take-home exercise, we will be using the following packages.\n\npacman::p_load(Kendall, plotly, tidyverse, tmap, sf, sp, sfdep)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#overview---setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#overview---setting-the-scene",
    "title": "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "",
    "text": "Dengue Hemorrhagic Fever (in short dengue fever) is one of the most widespread mosquito-borne diseases in the most tropical and subtropical regions. It is an acute disease caused by dengue virus infection which is transmitted by female Aedes aegypti and Aedes albopictus mosquitoes.\nIn 2015, Taiwan had recorded the most severe dengue fever outbreak with more than 43,000 dengue cases and 228 deaths. Since then, the annual reported dengue fever cases were maintained at the level of not more than 200 cases. However, in 2023, Taiwan recorded 26703 dengue fever cases."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#objectives",
    "title": "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "",
    "text": "In this study, we are interested to discover:\n\nIf the distribution of dengue fever outbreak at Tainan City, Taiwan are independent from spatial (space) and spatio-temporal (space-time).\nIf the outbreak is indeed spatial and spatio-temporal dependent, then, you would like to detect where are the clusters and outliers, and the emerging hot spot/cold spot areas."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#getting-started",
    "title": "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "",
    "text": "In this take-home exercise, we will be using the following packages.\n\npacman::p_load(Kendall, plotly, tidyverse, tmap, sf, sp, sfdep)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/data/geospatial/TAINAN_VILLAGE.html",
    "href": "Take-home_Ex/Take-home_Ex02/data/geospatial/TAINAN_VILLAGE.html",
    "title": "IS415 Geospatial Analytics and Applications",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“TWD97”,DATUM[“Taiwan Datum 1997”,ELLIPSOID[“GRS 1980”,6378137,298.257222101,LENGTHUNIT[“metre”,1]]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“Taiwan, Republic of China - onshore and offshore - Taiwan Island, Penghu (Pescadores) Islands.”],BBOX[17.36,114.32,26.96,123.61]],ID[“EPSG”,3824]] +proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs 27230 3824 EPSG:3824 TWD97 longlat EPSG:7019 true"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-geospatial-data---taiwan_village_2020-in-shapefile-format",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-geospatial-data---taiwan_village_2020-in-shapefile-format",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "3.1 Importing Geospatial data - TAIWAN_VILLAGE_2020 in shapefile format",
    "text": "3.1 Importing Geospatial data - TAIWAN_VILLAGE_2020 in shapefile format\nThe TAIWAN_VILLAGE_2020 dataset was acquired in ESRI shapefile format (.shp). To utilise this dataset in the R-environment, we need to import it as an sf object using the st_read() function from the sf package. This function is used to read the simple features or layers from file or database and returns an sf object.\n\ntainan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"TAINAN_VILLAGE\")\n\nReading layer `TAINAN_VILLAGE' from data source \n  `C:\\kt526\\IS415-GAA\\Take-home_Ex\\Take-home_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 649 features and 10 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0269 ymin: 22.88751 xmax: 120.6563 ymax: 23.41374\nGeodetic CRS:  TWD97\n\n\n\nst_crs(tainan_sf)\n\nCoordinate Reference System:\n  User input: TWD97 \n  wkt:\nGEOGCRS[\"TWD97\",\n    DATUM[\"Taiwan Datum 1997\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"Taiwan, Republic of China - onshore and offshore - Taiwan Island, Penghu (Pescadores) Islands.\"],\n        BBOX[17.36,114.32,26.96,123.61]],\n    ID[\"EPSG\",3824]]"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-aspatial-data---dengue_daily.csv",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-aspatial-data---dengue_daily.csv",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "3.2 Importing Aspatial data - Dengue_Daily.csv",
    "text": "3.2 Importing Aspatial data - Dengue_Daily.csv\nThe Dengue_Daily dataset is available in CSV format and was obtained from the Taiwan CDC Open Data Portal. Like the previous dataset, it needs to be imported into the R environment for use. However, since this dataset is aspatial and in CSV format, a different method is required for reading it. We will utilize the read_csv() function to import the CSV dataset.\n\ndengue &lt;- read_csv(\"data/aspatial/Dengue_Daily.csv\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#preparing-a-study-area-layer-with-specific-counties-of-tainan-city-taiwan",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#preparing-a-study-area-layer-with-specific-counties-of-tainan-city-taiwan",
    "title": "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "4.1 Preparing a study area layer with specific counties of Tainan City, Taiwan",
    "text": "4.1 Preparing a study area layer with specific counties of Tainan City, Taiwan\nIn this Take-home Exercise, we are interested in narrowing our focus to specific counties within Tainan City, specifically D01, D02, D04, D06, D07, D08, D32, and D39. To prepare a study area layer focusing on these specific counties, we can do the following:\n\ncounties &lt;- c('D01', 'D02', 'D04', 'D06', 'D07', 'D08', 'D32', 'D39')\ntainan_counties_sf &lt;- tainan_sf %&gt;%\n  select(COUNTYNAME,\n         TOWNID,\n         TOWNNAME,\n         VILLNAME,\n         geometry) %&gt;%\n  mutate(TOWNNAME_VILLNAME = paste(TOWNNAME, VILLNAME, sep=\"_\")) %&gt;%\n  filter(TOWNID %in% counties)\n\n\nfiltered_rows &lt;- tainan_sf[tainan_sf$TOWNID %in% counties, ]\nunique_townnames &lt;- unique(filtered_rows$TOWNNAME)\nprint(unique_townnames)\n\n[1] \"安南區\" \"仁德區\" \"中西區\" \"南區\"   \"永康區\" \"東區\"   \"北區\"   \"安平區\"\n\n\nThe c() function is used to combine the specified counties into a vector (a one dimensional array) named counties. Next, we will filter the Tainan City spatial data frame (tainan_sf) based on the TOWNID column, selecting only those entries that match the counties of interest listed in the counties vector. This refined dataset, named tainan_counties_sf, will serve as our study area layer for further analysis or visualization tasks.\n\n\n\n\n\n\nTip\n\n\n\nTo ensure that the filter() function works properly, we can check the unique values present in the TOWNID field using the unique() function.\n\n\n\nunique(tainan_counties_sf$TOWNID)\n\n[1] \"D06\" \"D32\" \"D08\" \"D02\" \"D39\" \"D01\" \"D04\" \"D07\"\n\n\nAnd here’s how our map for the study area looks like:"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#extracting-dengue-fever-cases-with-epidemiology-week-31-50-2023",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#extracting-dengue-fever-cases-with-epidemiology-week-31-50-2023",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "4.2 Extracting dengue fever cases with epidemiology week 31-50, 2023",
    "text": "4.2 Extracting dengue fever cases with epidemiology week 31-50, 2023"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#preparing-a-dengue-fever-layer-with-specific-counties-of-tainan-city-taiwan",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#preparing-a-dengue-fever-layer-with-specific-counties-of-tainan-city-taiwan",
    "title": "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "4.2 Preparing a dengue fever layer with specific counties of Tainan City, Taiwan",
    "text": "4.2 Preparing a dengue fever layer with specific counties of Tainan City, Taiwan\nThe subsequent tasks entail preparing the dengue fever layer for specific counties within Tainan City, Taiwan. This involves:\n\nConfining dengue fever layer to D01, D02, D04, D06, D07, D08, D32 and D39 counties\nExtracting dengue fever cases within epidemiology week 31-50, 2023\n\nFirstly, we use the colnames() function to see all the column names present in dengue.\n\ncolnames(dengue)\n\n [1] \"發病日\"             \"個案研判日\"         \"通報日\"            \n [4] \"性別\"               \"年齡層\"             \"居住縣市\"          \n [7] \"居住鄉鎮\"           \"居住村里\"           \"最小統計區\"        \n[10] \"最小統計區中心點X\"  \"最小統計區中心點Y\"  \"一級統計區\"        \n[13] \"二級統計區\"         \"感染縣市\"           \"感染鄉鎮\"          \n[16] \"感染村里\"           \"是否境外移入\"       \"感染國家\"          \n[19] \"確定病例數\"         \"居住村里代碼\"       \"感染村里代碼\"      \n[22] \"血清型\"             \"內政部居住縣市代碼\" \"內政部居住鄉鎮代碼\"\n[25] \"內政部感染縣市代碼\" \"內政部感染鄉鎮代碼\"\n\n\nAfter reading in the dengue dataset, we will notice that the dataset contains 26 variables (columns). Similar to tainan_sf, not all columns will be relevant for our investigation. So, let us select the relevant columns from dengue and rename them so that its easier for our analysis later on.\n\n發病日: ONSET_DATE\n最小統計區中心點X: X_COORDINATE (longitude)\n最小統計區中心點Y: Y_COORDINATE (latitude)\n居住縣市: COUNTYNAME\n居住鄉鎮: TOWNNAME\n居住村里: VILLNAME\n\nLet us save the output as a variable called dengue_extracted. Afterwards, we will display the structure of dengue_extracted using str().\n\ndengue_extracted &lt;- dengue %&gt;%\n  select(發病日,\n         最小統計區中心點X,\n         最小統計區中心點Y,\n         居住縣市,\n         居住鄉鎮,\n         居住村里) %&gt;%\n  rename(\"ONSET_DATE\" = 發病日,\n         \"X_COORDINATE\" = 最小統計區中心點X,\n         \"Y_COORDINATE\" = 最小統計區中心點Y,\n         \"COUNTYNAME\" = 居住縣市,\n         \"TOWNNAME\" = 居住鄉鎮,\n         \"VILLNAME\" = 居住村里)\n\n\nstr(dengue_extracted)\n\ntibble [106,861 × 6] (S3: tbl_df/tbl/data.frame)\n $ ONSET_DATE  : Date[1:106861], format: \"1998-01-02\" \"1998-01-03\" ...\n $ X_COORDINATE: chr [1:106861] \"120.505898941\" \"120.453657460\" \"121.751433765\" \"120.338158907\" ...\n $ Y_COORDINATE: chr [1:106861] \"22.464206650\" \"22.466338948\" \"24.749214667\" \"22.630316700\" ...\n $ COUNTYNAME  : chr [1:106861] \"屏東縣\" \"屏東縣\" \"宜蘭縣\" \"高雄市\" ...\n $ TOWNNAME    : chr [1:106861] \"屏東市\" \"東港鎮\" \"宜蘭市\" \"苓雅區\" ...\n $ VILLNAME    : chr [1:106861] \"None\" \"None\" \"None\" \"None\" ...\n\n\nThe dengue_extracted is a tibble data.frame and we are now left with 6 variables.\nWe can also use RStudio’s Data Viewer to view the contents of dengue_extracted.\n\n\n\nFigure 1. Image\n\n\nNotice the following after using the str() and viewing the dengue_extracted contents from Data Viewer :\n\nX_COORDINATE and Y_COORDINATE are in chr and contains “None”\nVILLNAME contains “None”\nONSET_DATE includes year such as 1998 (We only want year 2023)\n\n\n\n\n\n\n\nTip\n\n\n\nThe str() function is articularly useful for getting a quick summary of the structure of the data, including the data types of each column and a glimpse of the actual data.\n\n\nWe definitely have to do something about this … Let us fix these issues and also create a new column called EPIWEEK using the code chunk below. The output will be saved in dengue_2023.\n\ndengue_2023 &lt;- dengue_extracted %&gt;%\n  filter(year(ONSET_DATE) == 2023 &\n           X_COORDINATE != \"None\" &\n           Y_COORDINATE != \"None\" &\n           VILLNAME != \"None\") %&gt;%\n  mutate(X_COORDINATE = as.numeric(X_COORDINATE),\n         Y_COORDINATE = as.numeric(Y_COORDINATE),\n         EPIWEEK = epiweek(ONSET_DATE))\n\nstr(dengue_2023)\n\ntibble [24,047 × 7] (S3: tbl_df/tbl/data.frame)\n $ ONSET_DATE  : Date[1:24047], format: \"2023-01-01\" \"2023-01-03\" ...\n $ X_COORDINATE: num [1:24047] 120 120 120 120 121 ...\n $ Y_COORDINATE: num [1:24047] 22.8 22.8 22.7 23 24.2 ...\n $ COUNTYNAME  : chr [1:24047] \"高雄市\" \"屏東縣\" \"高雄市\" \"台南市\" ...\n $ TOWNNAME    : chr [1:24047] \"岡山區\" \"里港鄉\" \"仁武區\" \"東區\" ...\n $ VILLNAME    : chr [1:24047] \"灣裡里\" \"三廍村\" \"文武里\" \"崇文里\" ...\n $ EPIWEEK     : num [1:24047] 1 1 2 5 5 5 5 7 9 12 ...\n\n\nAfter running the code chunk above, we will see that the new column EPIWEEK has been added into dengue_2023. X_COORDINATE and Y_COORDINATE are also now having num data type.\nTo check if the “None” values are still present in X_COORDINATE, Y_COORDINATE and VILLNAME, we can run the following code chunk:\n\ndengue_2023 %&gt;% \n  select(contains(\"None\"))\n\n# A tibble: 24,047 × 0\n\n\nIf we were to look at dengue_2023 from the Data Viewer, we can observe that the COUNTYNAME contains counties besides 台南市, TOWNNAME contains more than the 8 unique towns we want and EPIWEEK is not within 31 to 50.\n\n\n\n\n\nWe can verify this by using the unique() function.\nUnique County names (COUNTYNAME):\n\nunique(dengue_2023$COUNTYNAME)\n\n [1] \"高雄市\" \"屏東縣\" \"台南市\" \"台中市\" \"台東縣\" \"台北市\" \"花蓮縣\" \"雲林縣\"\n [9] \"桃園市\" \"南投縣\" \"彰化縣\" \"新北市\" \"新竹市\" \"宜蘭縣\" \"新竹縣\" \"苗栗縣\"\n[17] \"嘉義縣\" \"基隆市\" \"嘉義市\" \"澎湖縣\" \"金門縣\"\n\n\nUnique Town names (TOWNNAME)\n\nunique(dengue_2023$TOWNNAME)\n\n  [1] \"岡山區\"   \"里港鄉\"   \"仁武區\"   \"東區\"     \"北區\"     \"鳥松區\"  \n  [7] \"歸仁區\"   \"鼓山區\"   \"善化區\"   \"楠梓區\"   \"新化區\"   \"大里區\"  \n [13] \"鳳山區\"   \"北屯區\"   \"大甲區\"   \"西屯區\"   \"永康區\"   \"烏日區\"  \n [19] \"台東市\"   \"萬華區\"   \"壽豐鄉\"   \"中區\"     \"仁德區\"   \"古坑鄉\"  \n [25] \"南屯區\"   \"后里區\"   \"龍潭區\"   \"太平區\"   \"南投市\"   \"安南區\"  \n [31] \"茄萣區\"   \"南區\"     \"斗六市\"   \"中壢區\"   \"沙鹿區\"   \"屏東市\"  \n [37] \"台西鄉\"   \"湖內區\"   \"芳苑鄉\"   \"板橋區\"   \"三民區\"   \"太麻里鄉\"\n [43] \"新營區\"   \"左營區\"   \"大寮區\"   \"路竹區\"   \"大社區\"   \"永和區\"  \n [49] \"三重區\"   \"中西區\"   \"淡水區\"   \"新市區\"   \"阿蓮區\"   \"中山區\"  \n [55] \"深坑區\"   \"壯圍鄉\"   \"新埔鎮\"   \"關廟區\"   \"虎尾鎮\"   \"信義區\"  \n [61] \"西區\"     \"苓雅區\"   \"林內鄉\"   \"前鎮區\"   \"梓官區\"   \"北投區\"  \n [67] \"竹山鎮\"   \"柳營區\"   \"松山區\"   \"樹林區\"   \"八德區\"   \"前金區\"  \n [73] \"旗津區\"   \"萬丹鄉\"   \"左鎮區\"   \"小港區\"   \"楠西區\"   \"七股區\"  \n [79] \"大同區\"   \"頭份市\"   \"汐止區\"   \"大林鎮\"   \"竹崎鄉\"   \"莿桐鄉\"  \n [85] \"安平區\"   \"平鎮區\"   \"清水區\"   \"梅山鄉\"   \"彰化市\"   \"豐原區\"  \n [91] \"中正區\"   \"潮州鎮\"   \"湖口鄉\"   \"桃園區\"   \"竹田鄉\"   \"西港區\"  \n [97] \"花蓮市\"   \"士林區\"   \"安樂區\"   \"文山區\"   \"佳里區\"   \"大安區\"  \n[103] \"大雅區\"   \"南化區\"   \"楊梅區\"   \"彌陀區\"   \"八里區\"   \"麻豆區\"  \n[109] \"溪州鄉\"   \"斗南鎮\"   \"新莊區\"   \"大村鄉\"   \"玉井區\"   \"竹北市\"  \n[115] \"新店區\"   \"外埔區\"   \"蘆洲區\"   \"竹東鎮\"   \"林園區\"   \"大埤鄉\"  \n[121] \"六甲區\"   \"安定區\"   \"西螺鎮\"   \"蘆竹區\"   \"太保市\"   \"香山區\"  \n[127] \"橋頭區\"   \"二林鎮\"   \"官田區\"   \"通霄鎮\"   \"九如鄉\"   \"大樹區\"  \n[133] \"旗山區\"   \"學甲區\"   \"大溪區\"   \"七堵區\"   \"中和區\"   \"大內區\"  \n[139] \"龍崎區\"   \"內門區\"   \"民雄鄉\"   \"新興區\"   \"鹽埕區\"   \"桃源區\"  \n[145] \"大肚區\"   \"南港區\"   \"名間鄉\"   \"田寮區\"   \"長治鄉\"   \"鹿港鎮\"  \n[151] \"山上區\"   \"神岡區\"   \"泰山區\"   \"下營區\"   \"埔里鎮\"   \"水上鄉\"  \n[157] \"佳冬鄉\"   \"燕巢區\"   \"鹽水區\"   \"中埔鄉\"   \"杉林區\"   \"五股區\"  \n[163] \"布袋鎮\"   \"朴子市\"   \"新園鄉\"   \"三峽區\"   \"來義鄉\"   \"內湖區\"  \n[169] \"麥寮鄉\"   \"麟洛鄉\"   \"礁溪鄉\"   \"林口區\"   \"番路鄉\"   \"將軍區\"  \n[175] \"內埔鄉\"   \"龜山區\"   \"二崙鄉\"   \"和美鎮\"   \"甲仙區\"   \"公館鄉\"  \n[181] \"東港鎮\"   \"美濃區\"   \"仁愛鄉\"   \"宜蘭市\"   \"龍井區\"   \"觀音區\"  \n[187] \"恆春鎮\"   \"頭城鎮\"   \"後壁區\"   \"土城區\"   \"綠島鄉\"   \"高樹鄉\"  \n[193] \"新豐鄉\"   \"春日鄉\"   \"萬巒鄉\"   \"埤頭鄉\"   \"員林市\"   \"馬公市\"  \n[199] \"溪湖鎮\"   \"新港鄉\"   \"鹽埔鄉\"   \"三星鄉\"   \"林邊鄉\"   \"五結鄉\"  \n[205] \"潭子區\"   \"北斗鎮\"   \"新埤鄉\"   \"霧峰區\"   \"集集鎮\"   \"東山區\"  \n[211] \"湖西鄉\"   \"蘇澳鎮\"   \"瑪家鄉\"   \"土庫鎮\"   \"崁頂鄉\"   \"牡丹鄉\"  \n[217] \"崙背鄉\"   \"成功鎮\"   \"六龜區\"   \"金城鎮\"   \"伸港鄉\"   \"花壇鄉\"  \n[223] \"四湖鄉\"   \"竹南鎮\"   \"鹿谷鄉\"  \n\n\nUnique Epiweek (EPIWEEK)\n\nunique(dengue_2023$EPIWEEK)\n\n [1]  1  2  5  7  9 12 13 14 15 16 17 19 20 22 23 24 25 26 27 28 29 30 31 32 33\n[26] 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52\n\n\n\n4.2.1 Confining dengue fever layer to D01, D02, D04, D06, D07, D08, D32 and D39 counties\nWe need to filter COUNTYNAME to contain only 台南市 and TOWNNAME to contain only the 8 specific towns (安南區, 仁德區, 中西區, 南區, 永康區, 東區, 北區, 安平區). We will save the output in dengue_fever_layer_df.\n\ndengue_fever_layer_df &lt;- dengue_2023 %&gt;%\n  mutate(TOWNNAME_VILLNAME = paste(TOWNNAME, VILLNAME, sep=\"_\")) %&gt;%\n  filter(COUNTYNAME == \"台南市\" & TOWNNAME %in% unique_townnames)\n\nNow, let us check COUNTYNAME and TOWNNAME in dengue_fever_layer_df. We should observe that we only have 1 specific county and 8 towns.\n\ncat(\"County:\", unique(dengue_fever_layer_df$COUNTYNAME))\n\nCounty: 台南市\n\ncat(\"Towns:\", unique(dengue_fever_layer_df$TOWNNAME))\n\nTowns: 東區 永康區 仁德區 北區 安南區 南區 中西區 安平區\n\n\n\n\n4.2.2 Extracting dengue fever cases within epidemiology week 31-50, 2023\nLet us visualize the distribution of dengue fever cases across the epidemiology weeks in 2023.\n\nggplot(dengue_fever_layer_df, aes(x = EPIWEEK)) +\n  geom_histogram(binwidth = 1, color = \"grey\") +\n  labs(x = \"EPIWEEK\", y = \"Number of dengue cases\") +\n  ggtitle(\"Distribution of Dengue Cases in 2023 by Epidemiology weeks\") +\n  theme_minimal()\n\n\n\n\nMore than 80% of the reported dengue fever cases occurred in epidemiology week 31-50, 2023. Let us filter out these dengue fever cases that falls within epidemiology week 31 to 50.\n\ndengue_2023_epiweeks_31_50_df &lt;- dengue_fever_layer_df %&gt;%\n  filter(between(EPIWEEK, 31, 50) )\n\nunique(dengue_2023_epiweeks_31_50_df$EPIWEEK)\n\n [1] 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-geospatial-data---taiwan_village_2020",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-geospatial-data---taiwan_village_2020",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "3.1 Importing Geospatial data - TAIWAN_VILLAGE_2020",
    "text": "3.1 Importing Geospatial data - TAIWAN_VILLAGE_2020\nThe TAIWAN_VILLAGE_2020 dataset was acquired in ESRI shapefile format (.shp). To utilise this dataset in the R-environment, we need to import it as an sf object using the st_read() function from the sf package. This function is used to read the shapefile containing the administrative boundaries of Tainan City and returns an sf object named tainan_sf.\n\ntainan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"TAINAN_VILLAGE\")\n\nReading layer `TAINAN_VILLAGE' from data source \n  `C:\\kt526\\IS415-GAA\\Take-home_Ex\\Take-home_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 649 features and 10 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0269 ymin: 22.88751 xmax: 120.6563 ymax: 23.41374\nGeodetic CRS:  TWD97"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-aspatial-data---dengue_daily",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-aspatial-data---dengue_daily",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "3.2 Importing Aspatial data - Dengue_Daily",
    "text": "3.2 Importing Aspatial data - Dengue_Daily\nThe Dengue_Daily dataset is available in csv format (.csv) and was obtained from the Taiwan CDC Open Data Portal. Like the previous dataset, it needs to be imported into the R environment for use. However, since this dataset is aspatial and in csv format, a different method is required for reading it. We will utilize the read_csv() function to import the csv cdataset and store the object in a tibble data frame named dengue.\n\ndengue &lt;- read_csv(\"data/aspatial/Dengue_Daily.csv\")\nhead(dengue)\n\n# A tibble: 6 × 26\n  發病日     個案研判日 通報日     性別  年齡層 居住縣市 居住鄉鎮 居住村里\n  &lt;date&gt;     &lt;chr&gt;      &lt;date&gt;     &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n1 1998-01-02 None       1998-01-07 男    40-44  屏東縣   屏東市   None    \n2 1998-01-03 None       1998-01-14 男    30-34  屏東縣   東港鎮   None    \n3 1998-01-13 None       1998-02-18 男    55-59  宜蘭縣   宜蘭市   None    \n4 1998-01-15 None       1998-01-23 男    35-39  高雄市   苓雅區   None    \n5 1998-01-20 None       1998-02-04 男    55-59  宜蘭縣   五結鄉   None    \n6 1998-01-22 None       1998-02-19 男    20-24  桃園市   蘆竹區   None    \n# ℹ 18 more variables: 最小統計區 &lt;chr&gt;, 最小統計區中心點X &lt;chr&gt;,\n#   最小統計區中心點Y &lt;chr&gt;, 一級統計區 &lt;chr&gt;, 二級統計區 &lt;chr&gt;,\n#   感染縣市 &lt;chr&gt;, 感染鄉鎮 &lt;chr&gt;, 感染村里 &lt;chr&gt;, 是否境外移入 &lt;chr&gt;,\n#   感染國家 &lt;chr&gt;, 確定病例數 &lt;dbl&gt;, 居住村里代碼 &lt;chr&gt;, 感染村里代碼 &lt;chr&gt;,\n#   血清型 &lt;chr&gt;, 內政部居住縣市代碼 &lt;chr&gt;, 內政部居住鄉鎮代碼 &lt;chr&gt;,\n#   內政部感染縣市代碼 &lt;chr&gt;, 內政部感染鄉鎮代碼 &lt;chr&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#preparing-a-dengue-fever-layer-with-specific-counties-of-tainan-city-taiwan-1",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#preparing-a-dengue-fever-layer-with-specific-counties-of-tainan-city-taiwan-1",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "4.3 Preparing a dengue fever layer with specific counties of Tainan City, Taiwan",
    "text": "4.3 Preparing a dengue fever layer with specific counties of Tainan City, Taiwan"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#checking-the-coordinate-system",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#checking-the-coordinate-system",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "4.4 Checking the coordinate system",
    "text": "4.4 Checking the coordinate system\n\ntainan_counties_sfdengue_2023_epiweeks_31_50_sf\n\n\n\nst_crs(tainan_counties_sf)\n\nCoordinate Reference System:\n  User input: TWD97 \n  wkt:\nGEOGCRS[\"TWD97\",\n    DATUM[\"Taiwan Datum 1997\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"Taiwan, Republic of China - onshore and offshore - Taiwan Island, Penghu (Pescadores) Islands.\"],\n        BBOX[17.36,114.32,26.96,123.61]],\n    ID[\"EPSG\",3824]]\n\n\n\n\n\nst_crs(dengue_2023_epiweeks_31_50_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3826 \n  wkt:\nPROJCRS[\"TWD97 / TM2 zone 121\",\n    BASEGEOGCRS[\"TWD97\",\n        DATUM[\"Taiwan Datum 1997\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",3824]],\n    CONVERSION[\"Taiwan 2-degree TM zone 121\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",121,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9999,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",250000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"easting (X)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"northing (Y)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Taiwan, Republic of China - between 120°E and 122°E, onshore and offshore - Taiwan Island.\"],\n        BBOX[20.41,119.99,26.72,122.06]],\n    ID[\"EPSG\",3826]]\n\n\n\n\n\nEnsure that both sfs are in the same coordinate systems."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#converting-aspatial-data-converting-to-sf-tibble-data.frame",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#converting-aspatial-data-converting-to-sf-tibble-data.frame",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "4.3 Converting aspatial data (converting to sf tibble data.frame)",
    "text": "4.3 Converting aspatial data (converting to sf tibble data.frame)\n\ndengue_2023_epiweeks_31_50_sf &lt;- st_as_sf(dengue_2023_epiweeks_31_50,\n                                          coords = c(\"最小統計區中心點X\", \"最小統計區中心點Y\"),\n                                          crs=3826)\n\nglimpse(dengue_2023_epiweeks_31_50_sf)\n\nRows: 25,461\nColumns: 3\n$ 發病日   &lt;date&gt; 2023-07-30, 2023-07-30, 2023-07-30, 2023-07-30, 2023-07-30, …\n$ EPIWEEK  &lt;dbl&gt; 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 3…\n$ geometry &lt;POINT [m]&gt; POINT (120.2202 22.97608), POINT (120.218 22.98007), PO…\n\n\nNote: Check that dengue_2023_epiweeks_31_50_sf only contains point features."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#preparing-a-dengue-fever-layer-in-spacetime-d3-class-of-sfdep",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#preparing-a-dengue-fever-layer-in-spacetime-d3-class-of-sfdep",
    "title": "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "4.3 Preparing a dengue fever layer in spacetime d3 class of sfdep",
    "text": "4.3 Preparing a dengue fever layer in spacetime d3 class of sfdep\nThe next task is to prepare dengue fever layer in spacetime d3 class using the sfdep package.\n\ndengue_grp &lt;- dengue_2023_epiweeks_31_50_df %&gt;%\n  group_by(TOWNNAME_VILLNAME, EPIWEEK) %&gt;%\n  summarise(num_dengue_cases = n()) %&gt;% \n  complete(EPIWEEK = 31:50, fill = list(num_dengue_cases = 0))\ndengue_grp &lt;- as_tibble(dengue_grp)\n\n\ntainan_towns_with_dengue &lt;- tainan_towns_sf %&gt;% \n  mutate(TOWNNAME_VILLNAME = paste(TOWNNAME, VILLNAME, sep=\"_\")) %&gt;%\n  select(TOWNNAME_VILLNAME, geometry) %&gt;%\n  filter(TOWNNAME_VILLNAME %in% unique(dengue_grp$TOWNNAME_VILLNAME))\n\n\ntainan_dengue_st &lt;- spacetime(.data = dengue_grp,\n                              .geometry = tainan_towns_with_dengue,\n                              .loc_col = \"TOWNNAME_VILLNAME\",\n                              .time_col = \"EPIWEEK\")\n\n\nis_spacetime_cube(tainan_dengue_st)\n\n[1] TRUE\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe TRUE return confirms that tainan_dengue_st is indeed an time-space cube."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#global-spatial-autocorrelation-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#global-spatial-autocorrelation-analysis",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "5.2 Global Spatial Autocorrelation Analysis",
    "text": "5.2 Global Spatial Autocorrelation Analysis\n\n5.1.1 Measures of Global of Spatial Autocorrelation: Moran’s I and Geary’s C\n\n\n\n\n\n\n\nMoran’s I\nGeary’s C\n\n\n\n\n\n\n\n\nDescribe how features differ from the values in the study area as a whole.\nInterpreting the Z value using Moran’s I:\n\npositive (I&gt;0): Clustered, observations tend to be similar;\nnegative(I&lt;0): Dispersed, observations tend to be dissimilar;\napproximately zero: observations are arranged randomly over space.\n\nDescribing how features differ from their immediate neighbours.\nInterpreting the Z value using Geary’s c:\n\nLarge c value (&gt;1) : Dispersed, observations tend to be dissimilar;\nSmall c value (&lt;1) : Clustered, observations tend to be similar;\nc = 1: observations are arranged randomly over space.\n\n\n\n\n\n\n5.2.1 Global measures of spatial autocorrelation\n\n5.2.1.1 Compute Spatial Weights\nTo calculate global spatial autocorrelation statistics effectively, we need to first construct the spatial weights for the study area. The spatial weights play a critical role in defining the neighbourhood relationships between geographical units within the study area.\nThere are several methods to construct spatial weights. We will be using the Contiguity-Based method to construct the spatial weights and derive the Weights Matrix.\nContiguity-Based Weights\nThis method establishes neighbourhood relationships based on contiguity, where geographical units sharing common borders (boundaries) are considered neighbours. Contiguity can be further categorised into the following cases:\n\n\n\n\n\n\n“rook” contiguity (sharing a common edge)\n“bishop” contiguity, (sharing common vertices)\n“queen” contiguity (sharing a common edge or vertex)\n\n\n\n\n\n\n\nNote\n\n\n\n“rook” and “queen” contiguity are more commonly used. Therefore, the number of neighbours according to the queen criterion will always be at least as large as for the rook criterion.\n\n\nTo derive the Contiguity-Based Weights,\n\nwm_q &lt;- tainan_dengue_cases_by_village %&gt;%\n  mutate(nb = st_contiguity(geometry, queen=TRUE),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\n\n\n5.1.2.2 Compute Global Moran’s I\nWe will compute the global moran’s I value  using the global_moran() function. The output is a tibble data.frame.\n\nmoranI &lt;- global_moran(wm_q$total_dengue_cases,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.419\n $ K: num 5.64\n\n\n\n\n5.1.2.2 Perform Global Moran’s I Test\nIn order to perform the Global Moran’s I Test, we will be using the global_moran_test() function from sfdep package.\n\nglobal_moran_test(wm_q$total_dengue_cases,\n                       wm_q$nb,\n                       wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 11.523, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.418994015      -0.003891051       0.001346765 \n\n\nInterpreting the results\n\n\n5.1.2.3 Perform Global Moran’s I Permutation Test with Monte-Carlo Simulation\nIn practice, monte carlo simulation should be used to perform the statistical test. We can use the global_moran_perm() function of sfdep package to run the  monte carlo simulation.\n\n\n\n\n\n\nNote\n\n\n\nThe set.seed() function in R is used to create reproducible results when writing code that involves creating variables that take on random values. The value placed in the seed can be any random integer. By using the set.seed() function, you guarantee that the same random values are produced each time you run the code. Read more about setting seeds here.\n\n\n\nset.seed(1234)\nglobal_moran_perm(wm_q$total_dengue_cases,\n                       wm_q$nb,\n                       wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.41899, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe number of simulations is always equal to nsim + 1. Since nsim = 99, this means that we will be performing  100 simulations.\n\n\nInterpreting the results\n\n\n5.1.2.4 Visualising Global Monte-Carlo Moran’s I\nLet us visualise the simulated Moran’s I test statistics by plotting the distribution of the statistical values using a histogram.\nWe can also look at the summary statistics using the summary() function"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#local-spatial-autocorrelation-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#local-spatial-autocorrelation-analysis",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "5.2 Local Spatial Autocorrelation Analysis",
    "text": "5.2 Local Spatial Autocorrelation Analysis\n\n5.2.2.1 Computing Local Moran’s I and p-value\nWe will compute the local moran’s I value using the local_moran() function. The output is a sf data.frame.\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    total_dengue_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\n\n5.2.2.2 Visualizing local Moran’s I and p-value\nThe tmap functions are used to prepare a choropleth map by using values in the ii and p_ii_sim fields.\n\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii_sim\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\n\n\n\n\n\n5.2.2.3 Visualize the Local Indicator of Spatial Association (LISA) map\nThe LISA map is a categorical map showing outliers and clusters. LISA map is an interpreted map by combining local Moran’s I of geographical areas and their respective p-values. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two types of clusters namely: High-High and Low-Low clusters.\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\nInterpreting the results"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hotspot-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hotspot-analysis",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "5.3 Emerging hotspot analysis",
    "text": "5.3 Emerging hotspot analysis"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#preparing-for-exploratory-data-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#preparing-for-exploratory-data-analysis",
    "title": "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "4.4 Preparing for Exploratory Data Analysis",
    "text": "4.4 Preparing for Exploratory Data Analysis\n\ntotal_dengue_cases_by_village &lt;- dengue_grp %&gt;%\n  select(TOWNNAME_VILLNAME,\n         num_dengue_cases) %&gt;%\n  group_by(TOWNNAME_VILLNAME) %&gt;%\n  summarise(total_dengue_cases = sum(num_dengue_cases))\n\n\ntainan_dengue_cases_by_village &lt;- left_join(tainan_towns_sf,\n                                            total_dengue_cases_by_village,\n                                            by = \"TOWNNAME_VILLNAME\") %&gt;% \n  replace_na(list(total_dengue_cases = 0))\n\n\nwhich(colSums(is.na(tainan_dengue_cases_by_village))&gt;0)\n\nnamed integer(0)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hotspot-analysis-ehsa",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hotspot-analysis-ehsa",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "7.0 Emerging HotSpot Analysis (EHSA)",
    "text": "7.0 Emerging HotSpot Analysis (EHSA)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on how to delineate homogeneous region by using geographically referenced multivariate data. There are two major analysis, namely:\n\nHierarchical cluster analysis; and\nSpatially constrained cluster analysis.\n\n\n\n\nIn geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data. In this hands-on exercise, we are interested to delineate Shan State, Myanmar into homogeneous regions by using multiple Information and Communication technology (ICT) measures, namely: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home.\n\n\n\n\npacman::p_load(rgdal, spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on how to delineate homogeneous region by using geographically referenced multivariate data. There are two major analysis, namely:\n\nHierarchical cluster analysis; and\nSpatially constrained cluster analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-analytical-question",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-analytical-question",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data. In this hands-on exercise, we are interested to delineate Shan State, Myanmar into homogeneous regions by using multiple Information and Communication technology (ICT) measures, namely: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#installing-and-loading-r-packages",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "pacman::p_load(rgdal, spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-geospatial-data",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "3.1 Importing Geospatial Data",
    "text": "3.1 Importing Geospatial Data\nThe Myanmar Township Boundary GIS data is in ESRI shapefile format. We will import this data into the R environment using the st_read() function of sf.\n\nshan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-aspatial-data",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "3.2 Importing Aspatial Data",
    "text": "3.2 Importing Aspatial Data\nThe Shan-ICT file is in .csv format. We will be import it using read_csv function of readr package.\n\nict &lt;- read_csv(\"data/aspatial/Shan-ICT.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-preparation",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "3.3 Data Preparation",
    "text": "3.3 Data Preparation\n\n3.3.1 Derive penetration rate of each ICT variable\nThe unit of measurement of the values are number of household. Using these values directly will be bias by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nWe can review the summary statistics of the newly derived penetration rates using the summary() function.\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#statistical-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#statistical-graphics",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "4.1 Statistical graphics",
    "text": "4.1 Statistical graphics\nWe can plot the distribution of the variables (i.e. Number of households with radio) by using appropriate Exploratory Data Analysis (EDA).\n\n4.1.1 Histograms\nHistogram is useful to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution)\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\n\n4.1.2 Statistical graphics - Multiple Histograms\n\nradio &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv &lt;- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone &lt;- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone &lt;- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer &lt;- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet &lt;- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe ggarrange() function of ggpubr package is used to group these histograms together.\n\n\n\n\n4.1.3 Statistical graphics - Boxplot\nBoxplot is useful to detect if there are outliers.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#choropleth-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#choropleth-map",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "4.2 Choropleth Map",
    "text": "4.2 Choropleth Map\n\n4.2.1 Preparing the data for choropleth map\nBefore we can prepare the choropleth map, we need to combine both the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived) into one using the left_join() function of dplyr package.\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \n# write_rds(shan_sf, \"data/rds/shan_sf.rds\")\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\n\n\n\n\n\n\n\nNote\n\n\n\nThe unique identifier used to join both data objects is TS_PCODE.\n\n\n\n\n4.2.2 Plotting choropleth map\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe distribution shown in the choropleth map above are bias to the underlying total number of households at the townships\n\n\nWhen we compare the two choropleth maps below, we can tell the biasness.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the choropleth maps above clearly show that townships with relatively larger number ot households are also showing relatively higher number of radio ownership.\n\n\nNow, let us plot the choropleth maps showing the distribution of total number of households and Radio penetration rate.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#extracting-clustering-variables",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#extracting-clustering-variables",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.1 Extracting clustering variables",
    "text": "6.1 Extracting clustering variables\nFirstly, let us extract the variables that will be used for clustering analysis from the shan_sf simple feature object into data.frame.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the final clustering variables list does not include variable INTERNET_PR because it is highly correlated with variable COMPUTER_PR.\n\n\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-standardisation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-standardisation",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.2 Data Standardisation",
    "text": "6.2 Data Standardisation\nIn general, multiple variables will be used in cluster analysis. It is not unusual their values range are different. In order to avoid the cluster analysis result is baised to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis.\n\n6.2.1 Min-Max standardisation\nThe normalize() of heatmaply package is used to stadardisation the clustering variables by using Min-Max method. The summary() is then used to display the summary statistics of the standardised clustering variables.\n\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the values range of the Min-max standardised clustering variables are 0-1 now.\n\n\n\n\n6.2.2 Z-score standardisation\nZ-score standardisation can be performed easily by using scale() of Base R\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice the mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.\n\n\n\n\n6.2.3 Visualising the standardised clustering variables\nBeside reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphical.\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-proximity-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-proximity-matrix",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.3 Computing proximity matrix",
    "text": "6.3 Computing proximity matrix\nWe will be using the dist() function of R to calculate the proximity distance matrix.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\n\nproxmat\n\n             Mongmit   Pindaya   Ywangan  Pinlaung    Mabein     Kalaw\nPindaya    171.86828                                                  \nYwangan    381.88259 257.31610                                        \nPinlaung    57.46286 208.63519 400.05492                              \nMabein     263.37099 313.45776 529.14689 312.66966                    \nKalaw      160.05997 302.51785 499.53297 181.96406 198.14085          \nPekon       59.61977 117.91580 336.50410  94.61225 282.26877 211.91531\nLawksawk   140.11550 204.32952 432.16535 192.57320 130.36525 140.01101\nNawnghkio   89.07103 180.64047 377.87702 139.27495 204.63154 127.74787\nKyaukme    144.02475 311.01487 505.89191 139.67966 264.88283  79.42225\nMuse       563.01629 704.11252 899.44137 571.58335 453.27410 412.46033\nLaihka     141.87227 298.61288 491.83321 101.10150 345.00222 197.34633\nMongnai    115.86190 258.49346 422.71934  64.52387 358.86053 200.34668\nMawkmai    434.92968 437.99577 397.03752 398.11227 693.24602 562.59200\nKutkai      97.61092 212.81775 360.11861  78.07733 340.55064 204.93018\nMongton    192.67961 283.35574 361.23257 163.42143 425.16902 267.87522\nMongyai    256.72744 287.41816 333.12853 220.56339 516.40426 386.74701\nMongkaing  503.61965 481.71125 364.98429 476.29056 747.17454 625.24500\nLashio     251.29457 398.98167 602.17475 262.51735 231.28227 106.69059\nMongpan    193.32063 335.72896 483.68125 192.78316 301.52942 114.69105\nMatman     401.25041 354.39039 255.22031 382.40610 637.53975 537.63884\nTachileik  529.63213 635.51774 807.44220 555.01039 365.32538 373.64459\nNarphan    406.15714 474.50209 452.95769 371.26895 630.34312 463.53759\nMongkhet   349.45980 391.74783 408.97731 305.86058 610.30557 465.52013\nHsipaw     118.18050 245.98884 388.63147  76.55260 366.42787 212.36711\nMonghsat   214.20854 314.71506 432.98028 160.44703 470.48135 317.96188\nMongmao    242.54541 402.21719 542.85957 217.58854 384.91867 195.18913\nNansang    104.91839 275.44246 472.77637  85.49572 287.92364 124.30500\nLaukkaing  568.27732 726.85355 908.82520 563.81750 520.67373 427.77791\nPangsang   272.67383 428.24958 556.82263 244.47146 418.54016 224.03998\nNamtu      179.62251 225.40822 444.66868 170.04533 366.16094 307.27427\nMonghpyak  177.76325 221.30579 367.44835 222.20020 212.69450 167.08436\nKonkyan    403.39082 500.86933 528.12533 365.44693 613.51206 444.75859\nMongping   265.12574 310.64850 337.94020 229.75261 518.16310 375.64739\nHopong     136.93111 223.06050 352.85844  98.14855 398.00917 264.16294\nNyaungshwe  99.38590 216.52463 407.11649 138.12050 210.21337  95.66782\nHsihseng   131.49728 172.00796 342.91035 111.61846 381.20187 287.11074\nMongla     384.30076 549.42389 728.16301 372.59678 406.09124 260.26411\nHseni      189.37188 337.98982 534.44679 204.47572 213.61240  38.52842\nKunlong    224.12169 355.47066 531.63089 194.76257 396.61508 273.01375\nHopang     281.05362 443.26362 596.19312 265.96924 368.55167 185.14704\nNamhkan    386.02794 543.81859 714.43173 382.78835 379.56035 246.39577\nKengtung   246.45691 385.68322 573.23173 263.48638 219.47071  88.29335\nLangkho    164.26299 323.28133 507.78892 168.44228 253.84371  67.19580\nMonghsu    109.15790 198.35391 340.42789  80.86834 367.19820 237.34578\nTaunggyi   399.84278 503.75471 697.98323 429.54386 226.24011 252.26066\nPangwaun   381.51246 512.13162 580.13146 356.37963 523.44632 338.35194\nKyethi     202.92551 175.54012 287.29358 189.47065 442.07679 360.17247\nLoilen     145.48666 293.61143 469.51621  91.56527 375.06406 217.19877\nManton     430.64070 402.42888 306.16379 405.83081 674.01120 560.16577\nMongyang   309.51302 475.93982 630.71590 286.03834 411.88352 233.56349\nKunhing    173.50424 318.23811 449.67218 141.58836 375.82140 197.63683\nMongyawng  214.21738 332.92193 570.56521 235.55497 193.49994 173.43078\nTangyan    195.92520 208.43740 324.77002 169.50567 448.59948 348.06617\nNamhsan    237.78494 228.41073 286.16305 214.33352 488.33873 385.88676\n               Pekon  Lawksawk Nawnghkio   Kyaukme      Muse    Laihka\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk   157.51129                                                  \nNawnghkio  113.15370  90.82891                                        \nKyaukme    202.12206 186.29066 157.04230                              \nMuse       614.56144 510.13288 533.68806 434.75768                    \nLaihka     182.23667 246.74469 211.88187 128.24979 526.65211          \nMongnai    151.60031 241.71260 182.21245 142.45669 571.97975 100.53457\nMawkmai    416.00669 567.52693 495.15047 512.02846 926.93007 429.96554\nKutkai     114.98048 224.64646 147.44053 170.93318 592.90743 144.67198\nMongton    208.14888 311.07742 225.81118 229.28509 634.71074 212.07320\nMongyai    242.52301 391.26989 319.57938 339.27780 763.91399 264.13364\nMongkaing  480.23965 625.18712 546.69447 586.05094 995.66496 522.96309\nLashio     303.80011 220.75270 230.55346 129.95255 313.15288 238.64533\nMongpan    243.30037 228.54223 172.84425 110.37831 447.49969 210.76951\nMatman     368.25761 515.39711 444.05061 505.52285 929.11283 443.25453\nTachileik  573.39528 441.82621 470.45533 429.15493 221.19950 549.08985\nNarphan    416.84901 523.69580 435.59661 420.30003 770.40234 392.32592\nMongkhet   342.08722 487.41102 414.10280 409.03553 816.44931 324.97428\nHsipaw     145.37542 249.35081 176.09570 163.95741 591.03355 128.42987\nMonghsat   225.64279 352.31496 289.83220 253.25370 663.76026 158.93517\nMongmao    293.70625 314.64777 257.76465 146.09228 451.82530 185.99082\nNansang    160.37607 188.78869 151.13185  60.32773 489.35308  78.78999\nLaukkaing  624.82399 548.83928 552.65554 428.74978 149.26996 507.39700\nPangsang   321.81214 345.91486 287.10769 175.35273 460.24292 214.19291\nNamtu      165.02707 260.95300 257.52713 270.87277 659.16927 185.86794\nMonghpyak  190.93173 142.31691  93.03711 217.64419 539.43485 293.22640\nKonkyan    421.48797 520.31264 439.34272 393.79911 704.86973 351.75354\nMongping   259.68288 396.47081 316.14719 330.28984 744.44948 272.82761\nHopong     138.86577 274.91604 204.88286 218.84211 648.68011 157.48857\nNyaungshwe 139.31874 104.17830  43.26545 126.50414 505.88581 201.71653\nHsihseng   105.30573 257.11202 209.88026 250.27059 677.66886 175.89761\nMongla     441.20998 393.18472 381.40808 241.58966 256.80556 315.93218\nHseni      243.98001 171.50398 164.05304  81.20593 381.30567 204.49010\nKunlong    249.36301 318.30406 285.04608 215.63037 547.24297 122.68682\nHopang     336.38582 321.16462 279.84188 154.91633 377.44407 230.78652\nNamhkan    442.77120 379.41126 367.33575 247.81990 238.67060 342.43665\nKengtung   297.67761 209.38215 208.29647 136.23356 330.08211 258.23950\nLangkho    219.21623 190.30257 156.51662  51.67279 413.64173 160.94435\nMonghsu    113.84636 242.04063 170.09168 200.77712 633.21624 163.28926\nTaunggyi   440.66133 304.96838 344.79200 312.60547 250.81471 425.36916\nPangwaun   423.81347 453.02765 381.67478 308.31407 541.97887 351.78203\nKyethi     162.43575 317.74604 267.21607 328.14177 757.16745 255.83275\nLoilen     181.94596 265.29318 219.26405 146.92675 560.43400  59.69478\nManton     403.82131 551.13000 475.77296 522.86003 941.49778 458.30232\nMongyang   363.58788 363.37684 323.32123 188.59489 389.59919 229.71502\nKunhing    213.46379 278.68953 206.15773 145.00266 533.00162 142.03682\nMongyawng  248.43910 179.07229 220.61209 181.55295 422.37358 211.99976\nTangyan    167.79937 323.14701 269.07880 306.78359 736.93741 224.29176\nNamhsan    207.16559 362.84062 299.74967 347.85944 778.52971 273.79672\n             Mongnai   Mawkmai    Kutkai   Mongton   Mongyai Mongkaing\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai    374.50873                                                  \nKutkai      91.15307 364.95519                                        \nMongton    131.67061 313.35220 107.06341                              \nMongyai    203.23607 178.70499 188.94166 159.79790                    \nMongkaing  456.00842 133.29995 428.96133 365.50032 262.84016          \nLashio     270.86983 638.60773 289.82513 347.11584 466.36472 708.65819\nMongpan    178.09554 509.99632 185.18173 200.31803 346.39710 563.56780\nMatman     376.33870 147.83545 340.86349 303.04574 186.95158 135.51424\nTachileik  563.95232 919.38755 568.99109 608.76740 750.29555 967.14087\nNarphan    329.31700 273.75350 314.27683 215.97925 248.82845 285.65085\nMongkhet   275.76855 115.58388 273.91673 223.22828 104.98924 222.60577\nHsipaw      52.68195 351.34601  51.46282  90.69766 177.33790 423.77868\nMonghsat   125.25968 275.09705 154.32012 150.98053 127.35225 375.60376\nMongmao    188.29603 485.52853 204.69232 206.57001 335.61300 552.31959\nNansang     92.79567 462.41938 130.04549 199.58124 288.55962 542.16609\nLaukkaing  551.56800 882.51110 580.38112 604.66190 732.68347 954.11795\nPangsang   204.25746 484.14757 228.33583 210.77938 343.30638 548.40662\nNamtu      209.35473 427.95451 225.28268 308.71751 278.02761 525.04057\nMonghpyak  253.26470 536.71695 206.61627 258.04282 370.01575 568.21089\nKonkyan    328.82831 339.01411 310.60810 248.25265 287.87384 380.92091\nMongping   202.99615 194.31049 182.75266 119.86993  65.38727 257.18572\nHopong      91.53795 302.84362  73.45899 106.21031 124.62791 379.37916\nNyaungshwe 169.63695 502.99026 152.15482 219.72196 327.13541 557.32112\nHsihseng   142.36728 329.29477 128.21054 194.64317 162.27126 411.59788\nMongla     354.10985 686.88950 388.40984 411.06668 535.28615 761.48327\nHseni      216.81639 582.53670 229.37894 286.75945 408.23212 648.04408\nKunlong    202.92529 446.53763 204.54010 270.02165 299.36066 539.91284\nHopang     243.00945 561.24281 263.31986 273.50305 408.73288 626.17673\nNamhkan    370.05669 706.47792 392.48568 414.53594 550.62819 771.39688\nKengtung   272.28711 632.54638 279.19573 329.38387 460.39706 692.74693\nLangkho    174.67678 531.08019 180.51419 236.70878 358.95672 597.42714\nMonghsu     84.11238 332.07962  62.60859 107.04894 154.86049 400.71816\nTaunggyi   448.55282 810.74692 450.33382 508.40925 635.94105 866.21117\nPangwaun   312.13429 500.68857 321.80465 257.50434 394.07696 536.95736\nKyethi     210.50453 278.85535 184.23422 222.52947 137.79420 352.06533\nLoilen      58.41263 388.73386 131.56529 176.16001 224.79239 482.18190\nManton     391.54062 109.08779 361.82684 310.20581 195.59882  81.75337\nMongyang   260.39387 558.83162 285.33223 295.60023 414.31237 631.91325\nKunhing    110.55197 398.43973 108.84990 114.03609 238.99570 465.03971\nMongyawng  275.77546 620.04321 281.03383 375.22688 445.78964 700.98284\nTangyan    180.37471 262.66006 166.61820 198.88460 109.08506 348.56123\nNamhsan    218.10003 215.19289 191.32762 196.76188  77.35900 288.66231\n              Lashio   Mongpan    Matman Tachileik   Narphan  Mongkhet\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan    172.33279                                                  \nMatman     628.11049 494.81014                                        \nTachileik  311.95286 411.03849 890.12935                              \nNarphan    525.63854 371.13393 312.05193 760.29566                    \nMongkhet   534.44463 412.17123 203.02855 820.50164 217.28718          \nHsipaw     290.86435 179.52054 344.45451 576.18780 295.40170 253.80950\nMonghsat   377.86793 283.30992 313.59911 677.09508 278.21548 167.98445\nMongmao    214.23677 131.59966 501.59903 472.95568 331.42618 375.35820\nNansang    184.47950 144.77393 458.06573 486.77266 398.13308 360.99219\nLaukkaing  334.65738 435.58047 903.72094 325.06329 708.82887 769.06406\nPangsang   236.72516 140.23910 506.29940 481.31907 316.30314 375.58139\nNamtu      365.88437 352.91394 416.65397 659.56458 494.36143 355.99713\nMonghpyak  262.09281 187.85699 470.46845 444.04411 448.40651 462.63265\nKonkyan    485.51312 365.87588 392.40306 730.92980 158.82353 254.24424\nMongping   454.52548 318.47482 201.65224 727.08969 188.64567 113.80917\nHopong     345.31042 239.43845 291.84351 632.45718 294.40441 212.99485\nNyaungshwe 201.58191 137.29734 460.91883 445.81335 427.94086 417.08639\nHsihseng   369.00833 295.87811 304.02806 658.87060 377.52977 256.70338\nMongla     179.95877 253.20001 708.17595 347.33155 531.46949 574.40292\nHseni       79.41836 120.66550 564.64051 354.90063 474.12297 481.88406\nKunlong    295.23103 288.03320 468.27436 595.70536 413.07823 341.68641\nHopang     170.63913 135.62913 573.55355 403.82035 397.85908 451.51070\nNamhkan    173.27153 240.34131 715.42102 295.91660 536.85519 596.19944\nKengtung    59.85893 142.21554 613.01033 295.90429 505.40025 531.35998\nLangkho    115.18145  94.98486 518.86151 402.33622 420.65204 428.08061\nMonghsu    325.71557 216.25326 308.13805 605.02113 311.92379 247.73318\nTaunggyi   195.14541 319.81385 778.45810 150.84117 684.20905 712.80752\nPangwaun   362.45608 232.52209 523.43600 540.60474 264.64997 407.02947\nKyethi     447.10266 358.89620 233.83079 728.87329 374.90376 233.25039\nLoilen     268.92310 207.25000 406.56282 573.75476 354.79137 284.76895\nManton     646.66493 507.96808  59.52318 910.23039 280.26395 181.33894\nMongyang   209.33700 194.93467 585.61776 448.79027 401.39475 445.40621\nKunhing    255.10832 137.85278 403.66587 532.26397 281.62645 292.49814\nMongyawng  172.70139 275.15989 601.80824 432.10118 572.76394 522.91815\nTangyan    429.84475 340.39128 242.78233 719.84066 348.84991 201.49393\nNamhsan    472.04024 364.77086 180.09747 754.03913 316.54695 170.90848\n              Hsipaw  Monghsat   Mongmao   Nansang Laukkaing  Pangsang\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat   121.78922                                                  \nMongmao    185.99483 247.17708                                        \nNansang    120.24428 201.92690 164.99494                              \nLaukkaing  569.06099 626.44910 404.00848 480.60074                    \nPangsang   205.04337 256.37933  57.60801 193.36162 408.04016          \nNamtu      229.44658 231.78673 365.03882 217.61884 664.06286 392.97391\nMonghpyak  237.67919 356.84917 291.88846 227.52638 565.84279 315.11651\nKonkyan    296.74316 268.25060 281.87425 374.70456 635.92043 274.81900\nMongping   168.92101 140.95392 305.57166 287.36626 708.13447 308.33123\nHopong      62.86179 100.45714 244.16253 167.66291 628.48557 261.51075\nNyaungshwe 169.92664 286.37238 230.45003 131.18943 520.24345 257.77823\nHsihseng   136.54610 153.49551 311.98001 193.53779 670.74564 335.52974\nMongla     373.47509 429.00536 216.24705 289.45119 202.55831 217.88123\nHseni      231.48538 331.22632 184.67099 136.45492 391.74585 214.66375\nKunlong    205.10051 202.31862 224.43391 183.01388 521.88657 258.49342\nHopang     248.72536 317.64824  78.29342 196.47091 331.67199  92.57672\nNamhkan    382.79302 455.10875 223.32205 302.89487 196.46063 231.38484\nKengtung   284.08582 383.72138 207.58055 193.67980 351.48520 229.85484\nLangkho    183.05109 279.52329 134.50170  99.39859 410.41270 167.65920\nMonghsu     58.55724 137.24737 242.43599 153.59962 619.01766 260.52971\nTaunggyi   462.31183 562.88102 387.33906 365.04897 345.98041 405.59730\nPangwaun   298.12447 343.53898 187.40057 326.12960 470.63605 157.48757\nKyethi     195.17677 190.50609 377.89657 273.02385 749.99415 396.89963\nLoilen      98.04789 118.65144 190.26490  94.23028 535.57527 207.94433\nManton     359.60008 317.15603 503.79786 476.55544 907.38406 504.75214\nMongyang   267.10497 312.64797  91.06281 218.49285 326.19219 108.37735\nKunhing     90.77517 165.38834 103.91040 128.20940 500.41640 123.18870\nMongyawng  294.70967 364.40429 296.40789 191.11990 454.80044 336.16703\nTangyan    167.69794 144.59626 347.14183 249.70235 722.40954 364.76893\nNamhsan    194.47928 169.56962 371.71448 294.16284 760.45960 385.65526\n               Namtu Monghpyak   Konkyan  Mongping    Hopong Nyaungshwe\nPindaya                                                                \nYwangan                                                                \nPinlaung                                                               \nMabein                                                                 \nKalaw                                                                  \nPekon                                                                  \nLawksawk                                                               \nNawnghkio                                                              \nKyaukme                                                                \nMuse                                                                   \nLaihka                                                                 \nMongnai                                                                \nMawkmai                                                                \nKutkai                                                                 \nMongton                                                                \nMongyai                                                                \nMongkaing                                                              \nLashio                                                                 \nMongpan                                                                \nMatman                                                                 \nTachileik                                                              \nNarphan                                                                \nMongkhet                                                               \nHsipaw                                                                 \nMonghsat                                                               \nMongmao                                                                \nNansang                                                                \nLaukkaing                                                              \nPangsang                                                               \nNamtu                                                                  \nMonghpyak  346.57799                                                   \nKonkyan    478.37690 463.39594                                         \nMongping   321.66441 354.76537 242.02901                               \nHopong     206.82668 267.95563 304.49287 134.00139                     \nNyaungshwe 271.41464 103.97300 432.35040 319.32583 209.32532           \nHsihseng   131.89940 285.37627 383.49700 199.64389  91.65458  225.80242\nMongla     483.49434 408.03397 468.09747 512.61580 432.31105  347.60273\nHseni      327.41448 200.26876 448.84563 395.58453 286.41193  130.86310\nKunlong    233.60474 357.44661 329.11433 309.05385 219.06817  285.13095\nHopang     408.24516 304.26577 348.18522 379.27212 309.77356  247.19891\nNamhkan    506.32466 379.50202 481.59596 523.74815 444.13246  333.32428\nKengtung   385.33554 221.47613 474.82621 442.80821 340.47382  177.75714\nLangkho    305.03473 200.27496 386.95022 343.96455 239.63685  128.26577\nMonghsu    209.64684 232.17823 331.72187 158.90478  43.40665  173.82799\nTaunggyi   518.72748 334.17439 650.56905 621.53039 513.76415  325.09619\nPangwaun   517.03554 381.95144 263.97576 340.37881 346.00673  352.92324\nKyethi     186.90932 328.16234 400.10989 187.43974 136.49038  288.06872\nLoilen     194.24075 296.99681 334.19820 231.99959 124.74445  206.40432\nManton     448.58230 502.20840 366.66876 200.48082 310.58885  488.79874\nMongyang   413.26052 358.17599 329.39338 387.80686 323.35704  294.29500\nKunhing    296.43996 250.74435 253.74202 212.59619 145.15617  189.97131\nMongyawng  262.24331 285.56475 522.38580 455.59190 326.59925  218.12104\nTangyan    178.69483 335.26416 367.46064 161.67411 106.82328  284.14692\nNamhsan    240.95555 352.70492 352.20115 130.23777 132.70541  315.91750\n            Hsihseng    Mongla     Hseni   Kunlong    Hopang   Namhkan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla     478.66210                                                  \nHseni      312.74375 226.82048                                        \nKunlong    231.85967 346.46200 276.19175                              \nHopang     370.01334 147.02444 162.80878 271.34451                    \nNamhkan    492.09476  77.21355 212.11323 375.73885 146.18632          \nKengtung   370.72441 202.45004  66.12817 317.14187 164.29921 175.63015\nLangkho    276.27441 229.01675  66.66133 224.52741 134.24847 224.40029\nMonghsu     97.82470 424.51868 262.28462 239.89665 301.84458 431.32637\nTaunggyi   528.14240 297.09863 238.19389 471.29032 329.95252 257.29147\nPangwaun   433.06326 319.18643 330.70182 392.45403 206.98364 310.44067\nKyethi      84.04049 556.02500 388.33498 298.55859 440.48114 567.86202\nLoilen     158.84853 338.67408 227.10984 166.53599 242.89326 364.90647\nManton     334.87758 712.51416 584.63341 479.76855 577.52046 721.86149\nMongyang   382.59743 146.66661 210.19929 247.22785  69.25859 167.72448\nKunhing    220.15490 306.47566 206.47448 193.77551 172.96164 314.92119\nMongyawng  309.51462 315.57550 173.86004 240.39800 290.51360 321.21112\nTangyan     70.27241 526.80849 373.07575 268.07983 412.22167 542.64078\nNamhsan    125.74240 564.02740 411.96125 310.40560 440.51555 576.42717\n            Kengtung   Langkho   Monghsu  Taunggyi  Pangwaun    Kyethi\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho    107.16213                                                  \nMonghsu    316.91914 221.84918                                        \nTaunggyi   186.28225 288.27478 486.91951                              \nPangwaun   337.48335 295.38434 343.38498 497.61245                    \nKyethi     444.26274 350.91512 146.61572 599.57407 476.62610          \nLoilen     282.22935 184.10672 131.55208 455.91617 331.69981 232.32965\nManton     631.99123 535.95620 330.76503 803.08034 510.79265 272.03299\nMongyang   217.08047 175.35413 323.95988 374.58247 225.25026 453.86726\nKunhing    245.95083 146.38284 146.78891 429.98509 229.09986 278.95182\nMongyawng  203.87199 186.11584 312.85089 287.73864 475.33116 387.71518\nTangyan    429.95076 332.02048 127.42203 592.65262 447.05580  47.79331\nNamhsan    466.20497 368.20978 153.22576 631.49232 448.58030  68.67929\n              Loilen    Manton  Mongyang   Kunhing Mongyawng   Tangyan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho                                                               \nMonghsu                                                               \nTaunggyi                                                              \nPangwaun                                                              \nKyethi                                                                \nLoilen                                                                \nManton     419.06087                                                  \nMongyang   246.76592 585.70558                                        \nKunhing    130.39336 410.49230 188.89405                              \nMongyawng  261.75211 629.43339 304.21734 295.35984                    \nTangyan    196.60826 271.82672 421.06366 249.74161 377.52279          \nNamhsan    242.15271 210.48485 450.97869 270.79121 430.02019  63.67613\n\n\n\n\n\n\n\n\nNote\n\n\n\ndist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-hierarchical-clustering",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-hierarchical-clustering",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.4 Computing hierarchical clustering",
    "text": "6.4 Computing hierarchical clustering\nNext, we will use the hclust() function of R stats to compute hierarchical clustering.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nhclust() employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\n\n\n\n6.4.1 Selecting the optimal clustering algorithm\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. This issue can be solve by using agnes() function of cluster package.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\nFrom the output above, we can see that the Ward’s method provides the strongest clustering structure among the four methods assessed. Thus, for subsequent analysis, we will be using the Ward’s method.\n\n\n6.4.2 Determining Optimal Clusters\nThe second challenge faced in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow method\nAverage silhoutte method\nGap statistic method\n\n\n6.4.2.1 Gap statistic method\nThe gap statistic method compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\n\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nWe can visualise the plot using fviz_gap_stat() of factoextra package.\n\nfviz_gap_stat(gap_stat)\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\n\n\n\n6.4.3 Interpreting Dendrograms\nWe can draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n6.4.4 Creating visually driven hierarchical clustering analysis\n\n6.4.4.1 Transforming data frame into matrix\nBefore we start to build the heatmap, we have to ensure that the data is loaded as a data matrix instead of data frame. To do so, we have to transform shan_ict data frame into a data matrix.\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n6.4.4.2 Plotting interactive cluster heatmap using heatmaply()\nNext, we will use the heatmaply() function of the heatmaply package to build an interactive cluster heatmap.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\")\n\n\n\n\n\n\n\n\n6.4.5 Mapping clusters formed\nWith closed examination of the dendragram above, we have decided to retain six clusters.\ncutree() of R Base will be used to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\nIn order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#skater-approach",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#skater-approach",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.1 SKATER approach",
    "text": "7.1 SKATER approach\n\n7.1.1 Converting into SpatialPolygonsDataFrame\nThe SKATER function only support sp objects such as SpatialPolygonDataFrame. Thus, we need to convert shan_sf into SpatialPolygonDataFrame using the as_Spatial() function of sf package.\n\nshan_sp &lt;- as_Spatial(shan_sf)\n\n\n\n7.1.2 Computing Neighbour List\nNext, we have to compute the neighbours list from polygon list.\n\nshan.nb &lt;- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\n\nplot(shan_sp, \n     border=grey(.5))\nplot(shan.nb, \n     coordinates(shan_sp), \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\n\n\n7.1.3 Computing minimum spanning tree\n\n7.1.3.1 Calculating edge costs\nThe nbcosts() of spdep package is used to compute the cost of each edge. It measures the distance between its nodes.\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\n\nshan.w &lt;- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\nTo compute the minimum spanning tree:\n\nshan.mst &lt;- mstree(shan.w)\ndim(shan.mst)\n\n[1] 54  3\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the dimension is 54 and not 55. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.\n\n\nLet us take a look at the contents of shan.mst.\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   54   48  47.79331\n[2,]   54   17 109.08506\n[3,]   54   45 127.42203\n[4,]   45   52 146.78891\n[5,]   52   13 110.55197\n[6,]   13   28  92.79567\n\n\n\nplot(shan_sp, border=gray(.5))\nplot.mst(shan.mst, \n         coordinates(shan_sp), \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)\n\n\n\n\n\n\n\n7.1.4 Computing spatially constrained clusters using SKATER method\n\nclust6 &lt;- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\n\nplot(shan_sp, border=gray(.5))\nplot(clust6, \n     coordinates(shan_sp), \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)\n\n\n\n\n\n\n7.1.5 Visualising the clusters in choropleth map\nWe can plot the newly derived clusters.\n\ngroups_mat &lt;- as.matrix(clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\nhclust.map &lt;- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map &lt;- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#clustgeo-method",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#clustgeo-method",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.2 ClustGeo Method",
    "text": "7.2 ClustGeo Method\nClustGeo package provides function called hclustgeo() to perform a typical Ward-like hierarchical clustering just like hclust().\n\n7.2.1 Non-spatially constrained hierarchical clustering\nTo perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix.\n\nnongeo_cluster &lt;- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\nTo map out the clusters:\n\ngroups &lt;- as.factor(cutree(nongeo_cluster, k=6))\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")\n\n\n\n\n\n\n7.2.2 Spatially constrained hierarchical clustering\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\nThe choicealpha() will be used to determine a suitable value for the mixing parameter alpha.\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\nFrom the graph outputs, we will choose 0.3 as our alpha value.\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.3)\ngroups &lt;- as.factor(cutree(clustG, k=6))\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nLet us plot the map of the newly delineated spatially constrained clusters.\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-individual-clustering-variable",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-individual-clustering-variable",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "8.1 Visualising individual clustering variable",
    "text": "8.1 Visualising individual clustering variable\n\nggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR)) +\n  geom_boxplot()\n\n\n\n\nThe boxplot reveals Cluster 3 displays the highest mean Radio Ownership Per Thousand Household. This is followed by Cluster 2, 1, 4, 6 and 5."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-multiple-clustering-variables---parallel-coordinate-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-multiple-clustering-variables---parallel-coordinate-plot",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "8.2 Visualising multiple clustering variables - Parallel coordinate plot",
    "text": "8.2 Visualising multiple clustering variables - Parallel coordinate plot\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-summary-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-summary-statistics",
    "title": "Hands-on Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "8.3 Computing summary statistics",
    "text": "8.3 Computing summary statistics\nWe can also compute the summary statistics such as mean, median, sd, etc to complement the visual interpretation.\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%\n  group_by(CLUSTER) %&gt;%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-geospatial-data",
    "title": "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "3.1 Importing Geospatial data",
    "text": "3.1 Importing Geospatial data\nTAIWAN_VILLAGE_2020\nThe TAIWAN_VILLAGE_2020 dataset was acquired in ESRI shapefile format (.shp). To utilise this dataset in the R-environment, we need to import it as an sf object using the st_read() function from the sf package. This function is used to read the shapefile containing the administrative boundaries of Tainan City and returns an sf object named tainan_sf.\n\ntainan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"TAINAN_VILLAGE\")\n\nReading layer `TAINAN_VILLAGE' from data source \n  `C:\\kt526\\IS415-GAA\\Take-home_Ex\\Take-home_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 649 features and 10 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0269 ymin: 22.88751 xmax: 120.6563 ymax: 23.41374\nGeodetic CRS:  TWD97\n\n\nThe dataset “TAINAN_VILLAGE” represents the polygon features delineating village boundaries within the Tainan City region of Taiwan. It comprises 649 features, each feature corresponding to a distinct village area. The dataset includes 10 fields providing additional attributes associated with each village polygon."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-aspatial-data",
    "title": "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "3.2 Importing Aspatial data",
    "text": "3.2 Importing Aspatial data\nDengue_Daily\nThe Dengue_Daily dataset is available in csv format (.csv) and was obtained from the Taiwan CDC Open Data Portal. Like the previous dataset, it needs to be imported into the R environment for use. However, since this dataset is aspatial and in csv format, a different method is required for reading it. We will utilize the read_csv() function to import the csv dataset and store the object in a tibble data frame named dengue.\n\ndengue &lt;- read_csv(\"data/aspatial/Dengue_Daily.csv\")\nhead(dengue)\n\n# A tibble: 6 × 26\n  發病日     個案研判日 通報日     性別  年齡層 居住縣市 居住鄉鎮 居住村里\n  &lt;date&gt;     &lt;chr&gt;      &lt;date&gt;     &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n1 1998-01-02 None       1998-01-07 男    40-44  屏東縣   屏東市   None    \n2 1998-01-03 None       1998-01-14 男    30-34  屏東縣   東港鎮   None    \n3 1998-01-13 None       1998-02-18 男    55-59  宜蘭縣   宜蘭市   None    \n4 1998-01-15 None       1998-01-23 男    35-39  高雄市   苓雅區   None    \n5 1998-01-20 None       1998-02-04 男    55-59  宜蘭縣   五結鄉   None    \n6 1998-01-22 None       1998-02-19 男    20-24  桃園市   蘆竹區   None    \n# ℹ 18 more variables: 最小統計區 &lt;chr&gt;, 最小統計區中心點X &lt;chr&gt;,\n#   最小統計區中心點Y &lt;chr&gt;, 一級統計區 &lt;chr&gt;, 二級統計區 &lt;chr&gt;,\n#   感染縣市 &lt;chr&gt;, 感染鄉鎮 &lt;chr&gt;, 感染村里 &lt;chr&gt;, 是否境外移入 &lt;chr&gt;,\n#   感染國家 &lt;chr&gt;, 確定病例數 &lt;dbl&gt;, 居住村里代碼 &lt;chr&gt;, 感染村里代碼 &lt;chr&gt;,\n#   血清型 &lt;chr&gt;, 內政部居住縣市代碼 &lt;chr&gt;, 內政部居住鄉鎮代碼 &lt;chr&gt;,\n#   內政部感染縣市代碼 &lt;chr&gt;, 內政部感染鄉鎮代碼 &lt;chr&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-the-distribution-of-dengue-fever-cases",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-the-distribution-of-dengue-fever-cases",
    "title": "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "5.1 Visualising the distribution of dengue fever cases",
    "text": "5.1 Visualising the distribution of dengue fever cases\n\ntmap_mode(\"plot\")\ntm_shape(tainan_dengue_cases_by_village) +\n  tm_fill(\"total_dengue_cases\",\n          style = \"jenks\",\n          palette = \"Reds\",\n          title = \"Number of Dengue Cases\",\n          legend.show = TRUE,\n          popup.vars = c(\"total_dengue_cases\")) +\n  tm_layout(main.title = \"Distribution of Total Dengue Cases in Tainan\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.5,\n            legend.width = 0.4,\n            frame = TRUE) +\n  tm_borders(alpha = 0.8) +\n  tm_compass(type=\"8star\", size = 1.5) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)\n\n\n\n\n\nequal &lt;- tm_shape(tainan_dengue_cases_by_village) +\n  tm_fill(\"total_dengue_cases\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(tainan_dengue_cases_by_village) +\n  tm_fill(\"total_dengue_cases\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#spatial-autocorrelation-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#spatial-autocorrelation-analysis",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "5.2 Spatial Autocorrelation Analysis",
    "text": "5.2 Spatial Autocorrelation Analysis\n\n“Everything is related to everything else, but near things are more related than distant things.”\n– Waldo Tobler, The First Law of Geography\n\nSpatial Autocorrelation is used to describe the presence of systematic spatial variation in a variable.\nThe two main types of Spatial Autocorrelation Analysis are:\n\nGlobal spatial autocorrelation analysis\nLocal spatial autocorrelation analysis\n\n\n5.2.1 Global Spatial Autocorrelation Analysis\n\n5.2.1.1 Measures of Global of Spatial Autocorrelation: Moran’s I and Geary’s C\nWe can test the presence of spatial autocorrelation using the Moran’s I or Geary’s C.\n\n\n\n\n\n\n\nMoran’s I\nGeary’s C\n\n\n\n\n\n\n\n\nDescribe how features differ from the values in the study area as a whole.\nInterpreting the Z value using Moran’s I:\n\npositive (I&gt;0): Clustered, observations tend to be similar;\nnegative(I&lt;0): Dispersed, observations tend to be dissimilar;\napproximately zero: observations are arranged randomly over space.\n\nDescribing how features differ from their immediate neighbours.\nInterpreting the Z value using Geary’s c:\n\nLarge c value (&gt;1) : Dispersed, observations tend to be dissimilar;\nSmall c value (&lt;1) : Clustered, observations tend to be similar;\nc = 1: observations are arranged randomly over space.\n\n\n\n\nIn this Take-home Exercise, we use Moran’s I to test the spatial autocorrelation. To test for spatial autocorrelation, we can follow the steps below:\n\nState the null and alternative hypotheses\n\nH0 (null hypothesis):\nH1 (alternative hypothesis):\n\nChoose the significance level ⍺\n\nStatistically, we select the confident interval as 95% =&gt; alpha value (⍺) = 0.05.\n\nCalculate the test statistic\nState the conclusion\n\nReject the Null hypothesis (H0) if p-value is smaller than alpha value.\nFailed to reject the Null Hypothesis (H0) if p-value is greater than alpha value.\n\n\n\n\n5.2.1.2 Compute Spatial Weights\nTo calculate global spatial autocorrelation statistics effectively, we need to first construct the spatial weights for the study area. The spatial weights play a critical role in defining the neighbourhood relationships between geographical units within the study area.\nThere are several methods to construct spatial weights. We will be using the Contiguity-Based method to construct the spatial weights and derive the Weights Matrix.\nContiguity-Based Weights\nThis method establishes neighbourhood relationships based on contiguity, where geographical units sharing common borders (boundaries) are considered neighbours. Contiguity can be further categorised into the following cases:\n\n\n\n\n\n\n“rook” contiguity (sharing a common edge)\n“bishop” contiguity, (sharing common vertices)\n“queen” contiguity (sharing a common edge or vertex)\n\n\n\n\n\n\n\nNote\n\n\n\n“rook” and “queen” contiguity are more commonly used. Therefore, the number of neighbours according to the queen criterion will always be at least as large as for the rook criterion.\n\n\nTo derive the Contiguity-Based Weights,\n\nwm_q &lt;- tainan_dengue_cases_by_village %&gt;%\n  mutate(nb = st_contiguity(geometry, queen=TRUE),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\nglimpse(wm_q)\n\nRows: 258\nColumns: 9\n$ nb                 &lt;nb&gt; &lt;6, 118, 160&gt;, &lt;126, 128, 138, 168, 222&gt;, &lt;68, 69, 1…\n$ wt                 &lt;list&gt; &lt;0.3333333, 0.3333333, 0.3333333&gt;, &lt;0.2, 0.2, 0.2,…\n$ COUNTYNAME         &lt;chr&gt; \"臺南市\", \"臺南市\", \"臺南市\", \"臺南市\", \"臺南市\", \"…\n$ TOWNID             &lt;chr&gt; \"D06\", \"D32\", \"D08\", \"D02\", \"D06\", \"D06\", \"D08\", \"D…\n$ TOWNNAME           &lt;chr&gt; \"安南區\", \"仁德區\", \"中西區\", \"南區\", \"安南區\", \"安…\n$ VILLNAME           &lt;chr&gt; \"青草里\", \"保安里\", \"赤嵌里\", \"大成里\", \"城北里\", \"…\n$ TOWNNAME_VILLNAME  &lt;chr&gt; \"安南區_青草里\", \"仁德區_保安里\", \"中西區_赤嵌里\", …\n$ total_dengue_cases &lt;int&gt; 2, 19, 111, 29, 1, 10, 37, 48, 108, 66, 26, 2, 3, 1…\n$ geometry           &lt;POLYGON [°]&gt; POLYGON ((120.1176 23.08387..., POLYGON ((1…\n\n\n\n\n5.2.1.3 Compute Global Moran’s I\nWe will compute the global moran’s I value using the global_moran() function. The output is a tibble data.frame.\n\nmoranI &lt;- global_moran(wm_q$total_dengue_cases,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.419\n $ K: num 5.64\n\n\n\n\n5.2.1.4 Perform Global Moran’s I Test\nIn order to perform the Global Moran’s I Test, we will be using the global_moran_test() function from sfdep package.\n\nglobal_moran_test(wm_q$total_dengue_cases,\n                       wm_q$nb,\n                       wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 11.523, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.418994015      -0.003891051       0.001346765 \n\n\n\n\n\n\n\n\nInterpreting the results\n\n\n\n\n\n\n\n\n5.2.1.5 Perform Global Moran’s I Permutation Test with Monte-Carlo Simulation\nIn practice, monte carlo simulation should be used to perform the statistical test. We can use the global_moran_perm() function of sfdep package to run the monte carlo simulation.\n\n\n\n\n\n\nNote\n\n\n\nThe set.seed() function in R is used to create reproducible results when writing code that involves creating variables that take on random values. The value placed in the seed can be any random integer. By using the set.seed() function, you guarantee that the same random values are produced each time you run the code. Read more about setting seeds here.\n\n\n\nset.seed(1234)\nglobal_moranI_perm &lt;- global_moran_perm(wm_q$total_dengue_cases,\n                       wm_q$nb,\n                       wm_q$wt,\n                       nsim = 99)\n\nglobal_moranI_perm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.41899, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe number of simulations is always equal to nsim + 1. Since nsim = 99, this means that we will be performing 100 simulations.\n\n\nInterpreting the results\n\n\n5.2.1.6 Visualising Global Monte-Carlo Moran’s I\nLet us visualise the simulated Moran’s I test statistics by plotting the distribution of the statistical values using a histogram.\n\nhist(global_moranI_perm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\nWe can also look at the summary statistics using the summary() function.\n\nsummary(global_moranI_perm$res[1:99])\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-0.096780 -0.028551 -0.008242 -0.006598  0.012804  0.097668 \n\n\n\n\n\n5.2.2 Local Spatial Autocorrelation Analysis\n\n5.2.2.1 Computing Local Moran’s I and p-value\nWe will compute the local moran’s I value using the local_moran() function. The output is a sf data.frame.\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    total_dengue_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\n\n5.2.2.2 Visualizing local Moran’s I and p-value\nThe tmap functions are used to prepare a choropleth map by using values in the ii and p_ii_sim fields.\n\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Local Moran's I\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii_sim\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\n\n\n\n\n\n5.2.2.3 Visualize the Local Indicator of Spatial Association (LISA) map\nThe LISA map is a categorical map showing outliers and clusters. LISA map is an interpreted map by combining local Moran’s I of geographical areas and their respective p-values. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two types of clusters namely: High-High and Low-Low clusters.\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\ntainan_counties_map &lt;- tm_shape(tainan_counties_sf) + \n  tm_polygons(\"TOWNID\")\n\nlisa_map &lt;- tm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\ntmap_arrange(tainan_counties_map, lisa_map, ncol = 2)\n\n\n\n\nInterpreting the results"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hot-spot-analysis-ehsa",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hot-spot-analysis-ehsa",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "7.0 Emerging Hot Spot Analysis (EHSA)",
    "text": "7.0 Emerging Hot Spot Analysis (EHSA)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#derive-spatial-weights-1",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#derive-spatial-weights-1",
    "title": "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "7.1 Derive Spatial Weights",
    "text": "7.1 Derive Spatial Weights\nFirstly, we need to derive the spatial weights.\n\ntainan_dengue_nb &lt;- tainan_dengue_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\nhead(tainan_dengue_nb)\n\n# A tibble: 6 × 5\n  TOWNNAME_VILLNAME EPIWEEK num_dengue_cases nb        wt       \n  &lt;chr&gt;               &lt;dbl&gt;            &lt;int&gt; &lt;list&gt;    &lt;list&gt;   \n1 安南區_青草里          31                0 &lt;int [4]&gt; &lt;dbl [4]&gt;\n2 仁德區_保安里          31                1 &lt;int [5]&gt; &lt;dbl [5]&gt;\n3 中西區_赤嵌里          31                0 &lt;int [4]&gt; &lt;dbl [4]&gt;\n4 南區_大成里            31                0 &lt;int [5]&gt; &lt;dbl [5]&gt;\n5 安南區_城北里          31                0 &lt;int [4]&gt; &lt;dbl [4]&gt;\n6 安南區_城南里          31                0 &lt;int [6]&gt; &lt;dbl [6]&gt;"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#compute-gi-statistics-1",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#compute-gi-statistics-1",
    "title": "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "7.2 Compute Gi* statistics",
    "text": "7.2 Compute Gi* statistics\nNext, we will compute the Gi* statistics using local_gstar_perm() function.\n\ngi_stars &lt;- tainan_dengue_nb %&gt;% \n  group_by(EPIWEEK) %&gt;% \n  mutate(gi_star = local_gstar_perm(\n    num_dengue_cases, nb, wt)) %&gt;% \n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#overview",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#overview",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation, Emerging Hot Spot Analysis: sfdep methods",
    "section": "Overview",
    "text": "Overview\nEmerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method for revealing and describing how hot spot and cold spot areas evolve over time. The analysis consist of four main steps:\n\nBuilding a space-time cube,\nCalculating Getis-Ord local Gi* statistic for each bin by using an FDR correction,\nEvaluating these hot and cold spot trends by using Mann-Kendall trend test,\nCategorising each study area location by referring to the resultant trend z-score and p-value for each location with data, and with the hot spot z-score and p-value for each bin."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#creating-a-time-series-cube",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#creating-a-time-series-cube",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation, Emerging Hot Spot Analysis: sfdep methods",
    "section": "Creating a Time Series Cube",
    "text": "Creating a Time Series Cube\n\nGDPPC_st &lt;- spacetime(hunan_gdppc, hunan,\n                      .loc_col = \"County\",\n                      .time_col = \"Year\")\n\n\nis_spacetime_cube(GDPPC_st)\n\n[1] TRUE"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#deriving-the-spatial-weights",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#deriving-the-spatial-weights",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation, Emerging Hot Spot Analysis: sfdep methods",
    "section": "Deriving the spatial weights",
    "text": "Deriving the spatial weights\n\nGDPPC_nb &lt;- GDPPC_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-gi",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-gi",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation, Emerging Hot Spot Analysis: sfdep methods",
    "section": "Computing Gi*",
    "text": "Computing Gi*\n\ngi_stars &lt;- GDPPC_nb %&gt;% \n  group_by(Year) %&gt;% \n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %&gt;% \n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#mann-kendall-test",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#mann-kendall-test",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation, Emerging Hot Spot Analysis: sfdep methods",
    "section": "Mann-Kendall Test",
    "text": "Mann-Kendall Test"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#mann-kendall-test",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#mann-kendall-test",
    "title": "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "7.3 Mann-Kendall Test",
    "text": "7.3 Mann-Kendall Test\nThe Mann-Kendall statistical test for trend is used to assess whether a set of data values is increasing over time or decreasing over time, and whether the trend in either direction is statistically significant. The null and alternative hypotheses we have are:\n\nH0 (null hypothesis): There is no monotonic trend in the series\nH1 (alternative hypothesis): A trend exists (i.e. this trend can be positive, negative or non-null)\n\nStatistically, we select the confident interval as 95%. Therefore, the significance level (alpha value ⍺) = 0.05. We will be select 安南區_溪墘里 as our study area since it has reported the highest number of dengue cases.\n\ncbg &lt;- gi_stars %&gt;% \n  ungroup() %&gt;% \n  filter(TOWNNAME_VILLNAME == \"安南區_溪墘里\") |&gt; \n  select(TOWNNAME_VILLNAME, EPIWEEK, gi_star)\n\n\np &lt;- ggplot(data = cbg, \n       aes(x = EPIWEEK, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n\n\n\n\n\nInterpreting the results\nBy the looking at the graph of Gi* plotted against EPIWEEK, we observed a downward trend. This is statistically confirmed by the Mann-Kendall Test. Thus, we can reject the null hypothesis that there is no monotonic trend and infer that as time goes by, the spread of dengue cases in 安南區_溪墘里 gradually decreases in comparison to the other villages.\n\ncbg %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n     tau       sl     S     D  varS\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 -0.632 0.000113  -120  190.   950\n\n\n\nehsa &lt;- gi_stars %&gt;%\n  group_by(TOWNNAME_VILLNAME) %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;%\n  tidyr::unnest_wider(mk)\n\n\nemerging &lt;- ehsa %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:5)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#performing-emerging-hotspot-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#performing-emerging-hotspot-analysis",
    "title": "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "7.4 Performing Emerging Hotspot Analysis",
    "text": "7.4 Performing Emerging Hotspot Analysis\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = tainan_dengue_st, \n  .var = \"num_dengue_cases\", \n  k = 1, \n  nsim = 99\n)\n\n\n7.4.1 Visualising the distribution of EHSA classes\n\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar() + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))\n\n\n\n\nInterpreting the results\n\nMore than 80 villages are classified as oscillating hotspots. This means that these villages are statistically significant hot spot for the final time-step interval that has a history of also being a statistically significant cold spot during a prior time step.\nLess than 10 villages are classified as new hotspot. This means that these villages are statistically significant hot spot for the final time step and has never been a statistically significant hot spot before.\n\n\n\n7.4.2 Visualising EHSA\n\ntainan_ehsa &lt;- tainan_towns_sf %&gt;%\n  left_join(ehsa,\n            by = join_by(TOWNNAME_VILLNAME == location))\n\n\nehsa_sig &lt;- tainan_ehsa  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(tainan_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#preparing-a-study-area-layer-with-specific-towns-of-tainan-city-taiwan",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#preparing-a-study-area-layer-with-specific-towns-of-tainan-city-taiwan",
    "title": "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "4.1 Preparing a study area layer with specific towns of Tainan City, Taiwan",
    "text": "4.1 Preparing a study area layer with specific towns of Tainan City, Taiwan\nIn this Take-home Exercise, we are interested in narrowing our focus to specific towns within Tainan City, specifically D01, D02, D04, D06, D07, D08, D32, and D39. To prepare a study area layer focusing on these specific towns, we can do the following:\n\ntowns &lt;- c('D01', 'D02', 'D04', 'D06', 'D07', 'D08', 'D32', 'D39')\ntainan_towns_sf &lt;- tainan_sf %&gt;%\n  select(COUNTYNAME,\n         TOWNID,\n         TOWNNAME,\n         VILLNAME,\n         geometry) %&gt;%\n  mutate(TOWNNAME_VILLNAME = paste(TOWNNAME, VILLNAME, sep=\"_\")) %&gt;%\n  filter(TOWNID %in% towns)\n\n\nfiltered_rows &lt;- tainan_sf[tainan_sf$TOWNID %in% towns, ]\nunique_townnames &lt;- unique(filtered_rows$TOWNNAME)\nprint(unique_townnames)\n\n[1] \"安南區\" \"仁德區\" \"中西區\" \"南區\"   \"永康區\" \"東區\"   \"北區\"   \"安平區\"\n\n\nThe c() function is used to combine the specified towns into a vector (a one dimensional array) named towns. Next, we will filter the Tainan City spatial data frame (tainan_sf) based on the TOWNID column, selecting only those entries that match the towns of interest listed in the towns vector. This refined dataset, named tainan_towns_sf, will serve as our study area layer for further analysis or visualization tasks.\n\n\n\n\n\n\nTip\n\n\n\nTo ensure that the filter() function works properly, we can check the unique values present in the TOWNID field using the unique() function.\n\n\n\nunique(tainan_towns_sf$TOWNID)\n\n[1] \"D06\" \"D32\" \"D08\" \"D02\" \"D39\" \"D01\" \"D04\" \"D07\"\n\n\nAnd here’s how our map for the study area looks like:"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#preparing-a-dengue-fever-layer-with-specific-towns-of-tainan-city-taiwan",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#preparing-a-dengue-fever-layer-with-specific-towns-of-tainan-city-taiwan",
    "title": "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "4.2 Preparing a dengue fever layer with specific towns of Tainan City, Taiwan",
    "text": "4.2 Preparing a dengue fever layer with specific towns of Tainan City, Taiwan\nThe subsequent tasks entail preparing the dengue fever layer for specific towns within Tainan City, Taiwan. This involves:\n\nConfining dengue fever layer with TOWNIDs D01, D02, D04, D06, D07, D08, D32 and D39\nExtracting dengue fever cases within epidemiology week 31-50, 2023\n\nFirstly, we use the colnames() function to see all the column names present in dengue.\n\ncolnames(dengue)\n\n [1] \"發病日\"             \"個案研判日\"         \"通報日\"            \n [4] \"性別\"               \"年齡層\"             \"居住縣市\"          \n [7] \"居住鄉鎮\"           \"居住村里\"           \"最小統計區\"        \n[10] \"最小統計區中心點X\"  \"最小統計區中心點Y\"  \"一級統計區\"        \n[13] \"二級統計區\"         \"感染縣市\"           \"感染鄉鎮\"          \n[16] \"感染村里\"           \"是否境外移入\"       \"感染國家\"          \n[19] \"確定病例數\"         \"居住村里代碼\"       \"感染村里代碼\"      \n[22] \"血清型\"             \"內政部居住縣市代碼\" \"內政部居住鄉鎮代碼\"\n[25] \"內政部感染縣市代碼\" \"內政部感染鄉鎮代碼\"\n\n\nAfter reading in the dengue dataset, we will notice that the dataset contains 26 variables (columns). Similar to tainan_sf, not all columns will be relevant for our investigation. So, let us select the relevant columns from dengue and rename them so that its easier for our analysis later on.\n\n發病日: ONSET_DATE\n最小統計區中心點X: X_COORDINATE (longitude)\n最小統計區中心點Y: Y_COORDINATE (latitude)\n居住縣市: COUNTYNAME\n居住鄉鎮: TOWNNAME\n居住村里: VILLNAME\n\nLet us save the output as a variable called dengue_extracted. Afterwards, we will display the structure of dengue_extracted using str().\n\ndengue_extracted &lt;- dengue %&gt;%\n  select(發病日,\n         最小統計區中心點X,\n         最小統計區中心點Y,\n         居住縣市,\n         居住鄉鎮,\n         居住村里) %&gt;%\n  rename(\"ONSET_DATE\" = 發病日,\n         \"X_COORDINATE\" = 最小統計區中心點X,\n         \"Y_COORDINATE\" = 最小統計區中心點Y,\n         \"COUNTYNAME\" = 居住縣市,\n         \"TOWNNAME\" = 居住鄉鎮,\n         \"VILLNAME\" = 居住村里)\n\n\nstr(dengue_extracted)\n\ntibble [106,861 × 6] (S3: tbl_df/tbl/data.frame)\n $ ONSET_DATE  : Date[1:106861], format: \"1998-01-02\" \"1998-01-03\" ...\n $ X_COORDINATE: chr [1:106861] \"120.505898941\" \"120.453657460\" \"121.751433765\" \"120.338158907\" ...\n $ Y_COORDINATE: chr [1:106861] \"22.464206650\" \"22.466338948\" \"24.749214667\" \"22.630316700\" ...\n $ COUNTYNAME  : chr [1:106861] \"屏東縣\" \"屏東縣\" \"宜蘭縣\" \"高雄市\" ...\n $ TOWNNAME    : chr [1:106861] \"屏東市\" \"東港鎮\" \"宜蘭市\" \"苓雅區\" ...\n $ VILLNAME    : chr [1:106861] \"None\" \"None\" \"None\" \"None\" ...\n\n\nThe dengue_extracted is a tibble data.frame and we are now left with 6 variables.\nWe can also use RStudio’s Data Viewer to view the contents of dengue_extracted.\n\n\n\n\n\nNotice the following after using the str() and viewing the dengue_extracted contents from Data Viewer :\n\nX_COORDINATE and Y_COORDINATE are in chr and contains “None”\nVILLNAME contains “None”\nONSET_DATE includes year such as 1998 (We only want year 2023)\n\n\n\n\n\n\n\nTip\n\n\n\nThe str() function is articularly useful for getting a quick summary of the structure of the data, including the data types of each column and a glimpse of the actual data.\n\n\nWe definitely have to do something about this … Let us fix these issues and also create a new column called EPIWEEK using the code chunk below. The output will be saved in dengue_2023.\n\ndengue_2023 &lt;- dengue_extracted %&gt;%\n  filter(year(ONSET_DATE) == 2023 &\n           X_COORDINATE != \"None\" &\n           Y_COORDINATE != \"None\" &\n           VILLNAME != \"None\") %&gt;%\n  mutate(X_COORDINATE = as.numeric(X_COORDINATE),\n         Y_COORDINATE = as.numeric(Y_COORDINATE),\n         EPIWEEK = epiweek(ONSET_DATE))\n\nstr(dengue_2023)\n\ntibble [24,047 × 7] (S3: tbl_df/tbl/data.frame)\n $ ONSET_DATE  : Date[1:24047], format: \"2023-01-01\" \"2023-01-03\" ...\n $ X_COORDINATE: num [1:24047] 120 120 120 120 121 ...\n $ Y_COORDINATE: num [1:24047] 22.8 22.8 22.7 23 24.2 ...\n $ COUNTYNAME  : chr [1:24047] \"高雄市\" \"屏東縣\" \"高雄市\" \"台南市\" ...\n $ TOWNNAME    : chr [1:24047] \"岡山區\" \"里港鄉\" \"仁武區\" \"東區\" ...\n $ VILLNAME    : chr [1:24047] \"灣裡里\" \"三廍村\" \"文武里\" \"崇文里\" ...\n $ EPIWEEK     : num [1:24047] 1 1 2 5 5 5 5 7 9 12 ...\n\n\nAfter running the code chunk above, we will see that the new column EPIWEEK has been added into dengue_2023. X_COORDINATE and Y_COORDINATE are also now having num data type.\nTo check if the “None” values are still present in X_COORDINATE, Y_COORDINATE and VILLNAME, we can run the following code chunk:\n\ndengue_2023 %&gt;% \n  select(contains(\"None\"))\n\n# A tibble: 24,047 × 0\n\n\nIf we were to look at dengue_2023 from the Data Viewer, we can observe that the COUNTYNAME contains counties besides 台南市, TOWNNAME contains more than the 8 unique towns we want and EPIWEEK is not within 31 to 50.\n\n\n\n\n\nWe can verify this by using the unique() function.\nUnique County names (COUNTYNAME):\n\nunique(dengue_2023$COUNTYNAME)\n\n [1] \"高雄市\" \"屏東縣\" \"台南市\" \"台中市\" \"台東縣\" \"台北市\" \"花蓮縣\" \"雲林縣\"\n [9] \"桃園市\" \"南投縣\" \"彰化縣\" \"新北市\" \"新竹市\" \"宜蘭縣\" \"新竹縣\" \"苗栗縣\"\n[17] \"嘉義縣\" \"基隆市\" \"嘉義市\" \"澎湖縣\" \"金門縣\"\n\n\nUnique Town names (TOWNNAME)\n\nunique(dengue_2023$TOWNNAME)\n\n  [1] \"岡山區\"   \"里港鄉\"   \"仁武區\"   \"東區\"     \"北區\"     \"鳥松區\"  \n  [7] \"歸仁區\"   \"鼓山區\"   \"善化區\"   \"楠梓區\"   \"新化區\"   \"大里區\"  \n [13] \"鳳山區\"   \"北屯區\"   \"大甲區\"   \"西屯區\"   \"永康區\"   \"烏日區\"  \n [19] \"台東市\"   \"萬華區\"   \"壽豐鄉\"   \"中區\"     \"仁德區\"   \"古坑鄉\"  \n [25] \"南屯區\"   \"后里區\"   \"龍潭區\"   \"太平區\"   \"南投市\"   \"安南區\"  \n [31] \"茄萣區\"   \"南區\"     \"斗六市\"   \"中壢區\"   \"沙鹿區\"   \"屏東市\"  \n [37] \"台西鄉\"   \"湖內區\"   \"芳苑鄉\"   \"板橋區\"   \"三民區\"   \"太麻里鄉\"\n [43] \"新營區\"   \"左營區\"   \"大寮區\"   \"路竹區\"   \"大社區\"   \"永和區\"  \n [49] \"三重區\"   \"中西區\"   \"淡水區\"   \"新市區\"   \"阿蓮區\"   \"中山區\"  \n [55] \"深坑區\"   \"壯圍鄉\"   \"新埔鎮\"   \"關廟區\"   \"虎尾鎮\"   \"信義區\"  \n [61] \"西區\"     \"苓雅區\"   \"林內鄉\"   \"前鎮區\"   \"梓官區\"   \"北投區\"  \n [67] \"竹山鎮\"   \"柳營區\"   \"松山區\"   \"樹林區\"   \"八德區\"   \"前金區\"  \n [73] \"旗津區\"   \"萬丹鄉\"   \"左鎮區\"   \"小港區\"   \"楠西區\"   \"七股區\"  \n [79] \"大同區\"   \"頭份市\"   \"汐止區\"   \"大林鎮\"   \"竹崎鄉\"   \"莿桐鄉\"  \n [85] \"安平區\"   \"平鎮區\"   \"清水區\"   \"梅山鄉\"   \"彰化市\"   \"豐原區\"  \n [91] \"中正區\"   \"潮州鎮\"   \"湖口鄉\"   \"桃園區\"   \"竹田鄉\"   \"西港區\"  \n [97] \"花蓮市\"   \"士林區\"   \"安樂區\"   \"文山區\"   \"佳里區\"   \"大安區\"  \n[103] \"大雅區\"   \"南化區\"   \"楊梅區\"   \"彌陀區\"   \"八里區\"   \"麻豆區\"  \n[109] \"溪州鄉\"   \"斗南鎮\"   \"新莊區\"   \"大村鄉\"   \"玉井區\"   \"竹北市\"  \n[115] \"新店區\"   \"外埔區\"   \"蘆洲區\"   \"竹東鎮\"   \"林園區\"   \"大埤鄉\"  \n[121] \"六甲區\"   \"安定區\"   \"西螺鎮\"   \"蘆竹區\"   \"太保市\"   \"香山區\"  \n[127] \"橋頭區\"   \"二林鎮\"   \"官田區\"   \"通霄鎮\"   \"九如鄉\"   \"大樹區\"  \n[133] \"旗山區\"   \"學甲區\"   \"大溪區\"   \"七堵區\"   \"中和區\"   \"大內區\"  \n[139] \"龍崎區\"   \"內門區\"   \"民雄鄉\"   \"新興區\"   \"鹽埕區\"   \"桃源區\"  \n[145] \"大肚區\"   \"南港區\"   \"名間鄉\"   \"田寮區\"   \"長治鄉\"   \"鹿港鎮\"  \n[151] \"山上區\"   \"神岡區\"   \"泰山區\"   \"下營區\"   \"埔里鎮\"   \"水上鄉\"  \n[157] \"佳冬鄉\"   \"燕巢區\"   \"鹽水區\"   \"中埔鄉\"   \"杉林區\"   \"五股區\"  \n[163] \"布袋鎮\"   \"朴子市\"   \"新園鄉\"   \"三峽區\"   \"來義鄉\"   \"內湖區\"  \n[169] \"麥寮鄉\"   \"麟洛鄉\"   \"礁溪鄉\"   \"林口區\"   \"番路鄉\"   \"將軍區\"  \n[175] \"內埔鄉\"   \"龜山區\"   \"二崙鄉\"   \"和美鎮\"   \"甲仙區\"   \"公館鄉\"  \n[181] \"東港鎮\"   \"美濃區\"   \"仁愛鄉\"   \"宜蘭市\"   \"龍井區\"   \"觀音區\"  \n[187] \"恆春鎮\"   \"頭城鎮\"   \"後壁區\"   \"土城區\"   \"綠島鄉\"   \"高樹鄉\"  \n[193] \"新豐鄉\"   \"春日鄉\"   \"萬巒鄉\"   \"埤頭鄉\"   \"員林市\"   \"馬公市\"  \n[199] \"溪湖鎮\"   \"新港鄉\"   \"鹽埔鄉\"   \"三星鄉\"   \"林邊鄉\"   \"五結鄉\"  \n[205] \"潭子區\"   \"北斗鎮\"   \"新埤鄉\"   \"霧峰區\"   \"集集鎮\"   \"東山區\"  \n[211] \"湖西鄉\"   \"蘇澳鎮\"   \"瑪家鄉\"   \"土庫鎮\"   \"崁頂鄉\"   \"牡丹鄉\"  \n[217] \"崙背鄉\"   \"成功鎮\"   \"六龜區\"   \"金城鎮\"   \"伸港鄉\"   \"花壇鄉\"  \n[223] \"四湖鄉\"   \"竹南鎮\"   \"鹿谷鄉\"  \n\n\nUnique Epiweek (EPIWEEK)\n\nunique(dengue_2023$EPIWEEK)\n\n [1]  1  2  5  7  9 12 13 14 15 16 17 19 20 22 23 24 25 26 27 28 29 30 31 32 33\n[26] 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52\n\n\n\n4.2.1 Confining dengue fever layer with TOWNIDs D01, D02, D04, D06, D07, D08, D32 and D39\nWe need to filter COUNTYNAME to contain only 台南市 and TOWNNAME to contain only the 8 specific towns (安南區, 仁德區, 中西區, 南區, 永康區, 東區, 北區, 安平區). We will save the output in dengue_fever_layer_df.\n\ndengue_fever_layer_df &lt;- dengue_2023 %&gt;%\n  mutate(TOWNNAME_VILLNAME = paste(TOWNNAME, VILLNAME, sep=\"_\")) %&gt;%\n  filter(COUNTYNAME == \"台南市\" & TOWNNAME %in% unique_townnames)\n\nNow, let us check COUNTYNAME and TOWNNAME in dengue_fever_layer_df. We should observe that we only have 1 specific county and 8 towns.\n\ncat(\"County:\", unique(dengue_fever_layer_df$COUNTYNAME))\n\nCounty: 台南市\n\ncat(\"Towns:\", unique(dengue_fever_layer_df$TOWNNAME))\n\nTowns: 東區 永康區 仁德區 北區 安南區 南區 中西區 安平區\n\n\n\n\n4.2.2 Extracting dengue fever cases within epidemiology week 31-50, 2023\nLet us visualize the distribution of dengue fever cases across the epidemiology weeks in 2023.\n\nggplot(dengue_fever_layer_df, aes(x = EPIWEEK)) +\n  geom_histogram(binwidth = 1, color = \"grey\") +\n  labs(x = \"EPIWEEK\", y = \"Number of dengue cases\") +\n  ggtitle(\"Distribution of Dengue Cases in 2023 by Epidemiology weeks\") +\n  theme_minimal()\n\n\n\n\nMore than 80% of the reported dengue fever cases occurred in epidemiology week 31-50, 2023. Let us filter out these dengue fever cases that falls within epidemiology week 31 to 50.\n\ndengue_2023_epiweeks_31_50_df &lt;- dengue_fever_layer_df %&gt;%\n  filter(between(EPIWEEK, 31, 50) )\n\nunique(dengue_2023_epiweeks_31_50_df$EPIWEEK)\n\n [1] 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "title": "In-class Exercise 7: Geographic Segmentation with Spatially Constrained Cluster Analysis: sfdep methods",
    "section": "",
    "text": "Installing and loading R packages\n\npacman::p_load(sp, spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)\n\n\n\n\n\n\n\nNote\n\n\n\n\nWe remove rgdal because it is no longer in CRAN\nLoading tidyverse allows us to use other packages such as ggplot, dplyr, tidyr\n\n\n\nData import and preparation\nWe will be using 2 datasets in this exercise:\n\nMyanmar Township Boundary Data (geometric file)\nShan-ICT.csv (attribute file)\n\n\nshan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %&gt;% \n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nFilter: To only include Shan states\nSelect: To select only relevant fields\nNote: Geodetic CRS: WGS 84, we do not have to be particular about the projection here because we are building graphs\n\nict &lt;- read_csv(\"data/aspatial/Shan-ICT.csv\")\n\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\nNotice that the range of each variable varies. We need to perform standardisation.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000,\n         `TV_PR` = `Television`/`Total households`*1000,\n         `LLPHONE_PR` = `Land line phone`/`Total households`*1000,\n         `MPHONE_PR` = `Mobile phone`/`Total households`*1000,\n         `COMPUTER_PR` = `Computer`/`Total households`*1000,\n         `INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;% \n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nPreparing the data for choropleth map\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")\n\n\n\n\n\n\n\nNote\n\n\n\n\nIf we want the output to be a sf data frame, the first argument should be a sf data frame.\nIf we use st_join(), but arguments must be sf data frames.\n\n\n\nReading in data from rds\n\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\n\nPlotting Multiple Histograms\n\nradio &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv &lt;- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone &lt;- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone &lt;- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer &lt;- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet &lt;- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)\n\n\n\n\nCorrelation Analysis\nTo check if the input variables are highly correlated.\n\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nInterpreting the corrplot\n\nSize of Ellipse\n\nNarrow means highly correlated\n\nColor\n\nRed denotes negative correlation\nBlue denotes positive correlation\n\n\nExtracting clustering variables\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nst_set_geometry = dropping away the geometric columns\nNote: even if you don’t select the geometry column, the geometry layer will still be read in\nThe current row names in cluster_vars are labelled as 1, 2, 3 … We need to set the row names as the township name using row.names() function.\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the row number has been replaced into the township name.\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\nwrite_rds(shan_ict, \"data/rds/shan_ict.rds\")\n\nComputing the proximity matrix\n\nshan_ict &lt;- read_rds(\"data/rds/shan_ict.rds\")\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\nInterpreting dendrogram\nOptimal number of clusters are based on local optimization\nComputing hierarchical clustering\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\nplot(hclust_ward, cex = 0.6)\n\n\n\n\nNotes:\n\nas.factor = changing a data type from numerical data type into a factor data type\ncbind() denotes column append: Used instead because there is no unique identifiers between shan_sf and groups.\nIf the data has been sorted, we should not use cbind() because the sequence of data would have changed.\n\nSKATER approach using sfdep\nThis code chunk below will be redundant when we are using sfdep\n\nshan_sp &lt;- as_Spatial(shan_sf)\n\n\nshan.nb &lt;- poly2nb(shan_sf)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\n\nplot(shan_sf,\n     border=grey(.5))\n\n\n\n\n\nplot(st_geometry(shan_sf),\n     border=grey(.5))\n\n\n\n\nNote that if we are using spdep, we can use the coordinates() function. But if we are using sfdep, we need to derive the centroids of each polygon.\n\npts &lt;- st_coordinates(st_centroid(shan_sf))\nplot(st_geometry(shan_sf),\n     border=grey(.5))\nplot(shan.nb,\n     pts,\n     col=\"blue\",\n     add=TRUE)\n\n\n\n\nCluster analysis\n\nLooking at the distribution of clusters based on map\nDissecting cluster membership (to label the clusters) (we need to characterize the clusters based on interpreting the parallel coordinates plots)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-on Exercise 8: Geograpgically Weighted Regression",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on how to Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method.\n\n\n\nGeographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational.\n\n\n\n\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)\n\n\n\n\n\n\n\nA short note about GWmodel\n\n\n\nGWmodel package provides a collection of localised spatial statistical methods, namely: GW summary statistics, GW principal components analysis, GW discriminant analysis and various forms of GW regression; some of which are provided in basic and robust (outlier resistant) forms. Commonly, outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "title": "Hands-on Exercise 8: Geograpgically Weighted Regression",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on how to Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview",
    "title": "Hands-on Exercise 8: Geograpgically Weighted Regression",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#installing-and-loading-r-packages",
    "title": "Hands-on Exercise 8: Geograpgically Weighted Regression",
    "section": "",
    "text": "pacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)\n\n\n\n\n\n\n\nA short note about GWmodel\n\n\n\nGWmodel package provides a collection of localised spatial statistical methods, namely: GW summary statistics, GW principal components analysis, GW discriminant analysis and various forms of GW regression; some of which are provided in basic and robust (outlier resistant) forms. Commonly, outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-geospatial-data",
    "title": "Hands-on Exercise 8: Geograpgically Weighted Regression",
    "section": "3.1 Importing Geospatial Data",
    "text": "3.1 Importing Geospatial Data\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nUpdating CRS information\n\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-aspatial-data",
    "title": "Hands-on Exercise 8: Geograpgically Weighted Regression",
    "section": "3.2 Importing Aspatial Data",
    "text": "3.2 Importing Aspatial Data\nThe condo_resale_2015 file is in .csv format. We will be import it using read_csv function of readr package.\n\ncondo_resale &lt;- read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nConverting aspatial data frame into a sf object\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %&gt;%\n  st_transform(crs=3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#statistical-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#statistical-graphics",
    "title": "Hands-on Exercise 8: Geograpgically Weighted Regression",
    "section": "4.1 Statistical Graphics",
    "text": "4.1 Statistical Graphics\nPlotting the distribution of SELLING_PRICE using histogram.\n\nselling_price_histogram &lt;- ggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\") + \n  labs(title = \"Distribution of Condominium Selling Price\",\n       subtitle = \"Plot of count by selling price\",\n       caption = \"Figure 1.\") +\n  theme(plot.caption = element_text(hjust = 0.5, face = \"italic\"))\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nlog_selling_price_histogram &lt;- ggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\") + \n  labs(title = \"Distribution of Log Condominium Selling Price\",\n       subtitle = \"Plot of count by log selling price\",\n       caption = \"Figure 2.\")+\n  theme(plot.caption = element_text(hjust = 0.5, face = \"italic\"))\n\nggarrange(selling_price_histogram, log_selling_price_histogram, nrow = 1)\n\n\n\n\nInterpretations\n\nFigure 1. reveals a right skewed distribution histogram\nThis means that more condominium units were transacted at relative lower prices\nWe can normalising the skewed distribution histogram using log transformation\nFigure 2. shows the histogram which has been log transformed and the distribution is relatively less skewed"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-histogram-plots-distribution-of-variables",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-histogram-plots-distribution-of-variables",
    "title": "Hands-on Exercise 8: Geograpgically Weighted Regression",
    "section": "4.2 Multiple Histogram Plots distribution of variables",
    "text": "4.2 Multiple Histogram Plots distribution of variables\n\nAREA_SQM &lt;- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE &lt;- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#statistical-point-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#statistical-point-map",
    "title": "Hands-on Exercise 8: Geograpgically Weighted Regression",
    "section": "4.3 Statistical Point Map",
    "text": "4.3 Statistical Point Map\nTo reveal the geospatial distribution of Condominium resale prices in Singapore, we can plot a point map using the tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#simple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#simple-linear-regression-method",
    "title": "Hands-on Exercise 8: Geograpgically Weighted Regression",
    "section": "5.1 Simple Linear Regression Method",
    "text": "5.1 Simple Linear Regression Method\nBuilding a simple linear regression model by using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\n\ncondo.slr &lt;- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.\n\n\nInterpretations\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n\n      *y = -258121.1 + 14719x1*\n\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value (&lt; 2e-16) is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\n\nVisualising best fit curve on scatterplot\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\nInterpretations\n\nFigure above reveals that there are a few statistical outliers with relatively high selling prices."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-linear-regression-method",
    "title": "Hands-on Exercise 8: Geograpgically Weighted Regression",
    "section": "5.2 Multiple Linear Regression Method",
    "text": "5.2 Multiple Linear Regression Method\n\n\n\n\n\n\nNote\n\n\n\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\n\n\nUsing Correlation matrix\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. The code chunk below is used to plot a scatterplot matrix of the relationship between indedepent variables in condo_resale.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\n\n\nInterpretations\n\nFreehold is highly correlated to LEASE_99YEAR\nIt is wiser to only include either one of them in the subsequent model building\nAs a result, LEASE_99YEAR is excluded in the subsequent model building.\n\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16\n\n\n\n5.2.1 Preparing Publication Quality Table\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.\n\n5.2.1.1 olsrr method\nNow, we are ready to calibrate the revised model by using the code chunk below.\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n\n5.2.1.2 gtsummary method\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression report.\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %&gt;% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nMulticollinearity\n\n\n\n\n\n\nNote\n\n\n\nThe olsrr package provides a collection of useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\n\n\nWe can use ols_vif_total() of olsrr package to test if there are signs of multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nInterpretations\nSince the VIF of the independent variables are less than 10, we can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\n\n5.2.2 Test Assumptions\n\n5.2.2.1 Test for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\nInterpretations\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n5.2.2.2 Test for Normality Assumptions\nTo perform normality assumption test, we use ols_plot_resid_hist().\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\nInterpretations\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\n\nols_test_normality(condo.mlr1)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nInterpretations\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\n5.2.2.3 Test for Spatial Autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nIn order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\n\ntmap_mode(\"view\")\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\ntmap_mode(\"plot\")\n\nInterpretations\n\nThe figure above reveal that there is sign of spatial autocorrelation.\n\nTo proof that our observation is indeed true, the Moran’s I test will be performed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#gwr-model-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#gwr-model-method",
    "title": "Hands-on Exercise 8: Geograpgically Weighted Regression",
    "section": "5.3 GWR Model Method",
    "text": "5.3 GWR Model Method\n\n5.3.1 Building fixed bandwidth GWR Model\nComputing the optimal fixed bandwidth\n\nbw.fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\n\n\n\n\n\n\nNote\n\n\n\nTo compute the fixed bandwidth,\n\nadaptive = FALSE\n\nhere are two approaches for stopping rule:\n\nCV cross validation\nAIC corrected\n\n\n\nInterpretations\n\nThe result shows that the recommended bandwidth is 971.3405 metres\n\nCalibrate the GWR model using fixed bandwidth\n\ngwr.fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-03-11 10:34:26.842018 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2024-03-11 10:34:28.131496 \n\n\nInterpretations\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1.\n\n\n5.3.2 Building adaptive bandwidth GWR Model\nComputing the adaptive bandwidth bandwidth\n\nbw.adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nInterpretations\n\nThe result shows that the 30 is the recommended data points to be used.\n\nCalibrate the GWR model using adaptive bandwidth\n\ngwr.adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-03-11 10:34:35.546431 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-03-11 10:34:36.788526 \n\n\nInterpretations\n\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61.\n\nVisualising GWR Output\nTo visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.\n\ncondo_resale.sf.adaptive &lt;- st_as_sf(gwr.adaptive$SDF) %&gt;%\n  st_transform(crs=3414)\n\ncondo_resale.sf.adaptive.svy21 &lt;- st_transform(condo_resale.sf.adaptive, 3414)\n\ngwr.adaptive.output &lt;- as.data.frame(gwr.adaptive$SDF)\n\ncondo_resale.sf.adaptive &lt;- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\nNext, glimpse() is used to display the content of condo_resale.sf.adaptive sf data frame.\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       &lt;dbl&gt; 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              &lt;dbl&gt; 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   &lt;dbl&gt; -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              &lt;dbl&gt; -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        &lt;dbl&gt; 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      &lt;dbl&gt; -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  &lt;dbl&gt; -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              &lt;dbl&gt; -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             &lt;dbl&gt; -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      &lt;dbl&gt; 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    &lt;dbl&gt; 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         &lt;dbl&gt; 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           &lt;dbl&gt; 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       &lt;dbl&gt; -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              &lt;dbl&gt; 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               &lt;dbl&gt; 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               &lt;dbl&gt; 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\n\n\n\nVisualising local R2\n\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\ntmap_mode(\"plot\")\n\nVisualising coefficient estimates\n\ntmap_mode(\"view\")\nAREA_SQM_SE &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nVisualising Local R2 by URA Planning Region\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)\n\n\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "title": "In-class Exercise 8: Geograpgically Weighted Regression",
    "section": "",
    "text": "In this In-class exercise, you will gain hands-on experience on how to Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method.\n\n\n\nGeographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational.\n\n\n\n\npacman::p_load(olsrr, ggstatsplot, corrplot, ggpubr, sf, spdep, GWmodel,\n               tmap, tidyverse, gtsummary)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#getting-started",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#getting-started",
    "title": "In-class Exercise 8: Geograpgically Weighted Regression",
    "section": "",
    "text": "In this In-class exercise, you will gain hands-on experience on how to Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#overview",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#overview",
    "title": "In-class Exercise 8: Geograpgically Weighted Regression",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#installing-and-loading-r-packages",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#installing-and-loading-r-packages",
    "title": "In-class Exercise 8: Geograpgically Weighted Regression",
    "section": "",
    "text": "pacman::p_load(olsrr, ggstatsplot, corrplot, ggpubr, sf, spdep, GWmodel,\n               tmap, tidyverse, gtsummary)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#importing-geospatial-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#importing-geospatial-data",
    "title": "In-class Exercise 8: Geograpgically Weighted Regression",
    "section": "3.1 Importing Geospatial Data",
    "text": "3.1 Importing Geospatial Data\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\kt526\\IS415-GAA\\In-class_Ex\\In-class_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nUpdating CRS information\n\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#importing-aspatial-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#importing-aspatial-data",
    "title": "In-class Exercise 8: Geograpgically Weighted Regression",
    "section": "3.2 Importing Aspatial Data",
    "text": "3.2 Importing Aspatial Data\nThe condo_resale_2015 file is in .csv format. We will be import it using read_csv function of readr package.\n\ncondo_resale &lt;- read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nConverting aspatial data frame into a sf object\nNotice that st_transform() of sf package is used to convert the coordinates from WGS84.\nTake note that LONGITUDE and LATITUDE from coords = c(\"LONGITUDE\", \"LATITUDE\") are referring to the field names.\n\nProjected system = unit of measurements is in meters\n\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %&gt;%\n  st_transform(crs=3414)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#statistical-graphics",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#statistical-graphics",
    "title": "In-class Exercise 8: Geograpgically Weighted Regression",
    "section": "4.1 Statistical Graphics",
    "text": "4.1 Statistical Graphics\nPlotting the distribution of SELLING_PRICE using histogram.\n\nselling_price_histogram &lt;- ggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\") + \n  labs(title = \"Distribution of Condominium Selling Price\",\n       subtitle = \"Plot of count by selling price\",\n       caption = \"Figure 1.\") +\n  theme(plot.caption = element_text(hjust = 0.5, face = \"italic\"))\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nlog_selling_price_histogram &lt;- ggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\") + \n  labs(title = \"Distribution of Log Condominium Selling Price\",\n       subtitle = \"Plot of count by log selling price\",\n       caption = \"Figure 2.\")+\n  theme(plot.caption = element_text(hjust = 0.5, face = \"italic\"))\n\nggarrange(selling_price_histogram, log_selling_price_histogram, nrow = 1)\n\n\n\n\nInterpretations\n\nFigure 1. reveals a right skewed distribution histogram\nThis means that more condominium units were transacted at relative lower prices\nWe can normalising the skewed distribution histogram using log transformation\nFigure 2. shows the histogram which has been log transformed and the distribution is relatively less skewed"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#multiple-histogram-plots-distribution-of-variables",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#multiple-histogram-plots-distribution-of-variables",
    "title": "In-class Exercise 8: Geograpgically Weighted Regression",
    "section": "4.2 Multiple Histogram Plots distribution of variables",
    "text": "4.2 Multiple Histogram Plots distribution of variables\n\nAREA_SQM &lt;- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE &lt;- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#statistical-point-map",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#statistical-point-map",
    "title": "In-class Exercise 8: Geograpgically Weighted Regression",
    "section": "4.3 Statistical Point Map",
    "text": "4.3 Statistical Point Map\nTo reveal the geospatial distribution of Condominium resale prices in Singapore, we can plot a point map using the tmap package."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#simple-linear-regression-method",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#simple-linear-regression-method",
    "title": "In-class Exercise 8: Geograpgically Weighted Regression",
    "section": "5.1 Simple Linear Regression Method",
    "text": "5.1 Simple Linear Regression Method\nBuilding a simple linear regression model by using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\n\ncondo.slr &lt;- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.\n\n\nInterpretations\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n\n      *y = -258121.1 + 14719x1*\n\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value (&lt; 2e-16) is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\n\nVisualising best fit curve on scatterplot\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\nInterpretations\n\nFigure above reveals that there are a few statistical outliers with relatively high selling prices."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#multiple-linear-regression-method",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#multiple-linear-regression-method",
    "title": "In-class Exercise 8: Geograpgically Weighted Regression",
    "section": "5.2 Multiple Linear Regression Method",
    "text": "5.2 Multiple Linear Regression Method\n\n\n\n\n\n\nNote\n\n\n\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\n\n\nUsing Correlation matrix\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. The code chunk below is used to plot a scatterplot matrix of the relationship between indedepent variables in condo_resale.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\n# ggcorrmat(condo_resale[, 5:23]) # alternative for corrplot\n\n#| fig-width: 12\n#| fig-height: 10\n#| fig-cap: \"Correlation matrix\"\n\n\n\n\n\n\nNote\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\n\n\nInterpretations\n\nFreehold is highly correlated to LEASE_99YEAR\nIt is wiser to only include either one of them in the subsequent model building\nAs a result, LEASE_99YEAR is excluded in the subsequent model building.\n\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\n\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16\n\n\n\n5.2.1 Preparing Publication Quality Table\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.\n\n5.2.1.1 olsrr method\nNow, we are ready to calibrate the revised model by using the code chunk below.\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\n\nols_regress(condo.mlr1)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n\n5.2.1.2 gtsummary method\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression report.\n\ntbl_regression(condo.mlr1,\n               intercept = TRUE)\n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %&gt;% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nVisualising model parameters\n\nmlr.p &lt;- ggcoefstats(condo.mlr1,\n                     sort = \"ascending\")\n\nmlr.p\n\n\n\n\nInterpretation:\n\nPROX_BUS_STOP - confidence interval is longer = you are relatively less confident\nPROX_SHOPPING_MALL - confidence interval is shorter = you are relatively more confident\nRelationship = Positive (direct relationship), Negative (inverse relationship)\nIf the AGE is by year, for every one year increase of the age of the property, the property price will drop by $24687.74\n\nMulticollinearity\n\n\n\n\n\n\nNote\n\n\n\nThe olsrr package provides a collection of useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\n\n\nWe can use ols_vif_total() of olsrr package to test if there are signs of multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nInterpretations\nSince the VIF of the independent variables are less than 10, we can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\n\n5.2.2 Test Assumptions\n\n5.2.2.1 Test for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\nInterpretations\nThe figure above reveals that most of the data points are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n5.2.2.2 Test for Normality Assumptions\nTo perform normality assumption test, we use ols_plot_resid_hist().\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\nInterpretations\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\n\nols_test_normality(condo.mlr1)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nInterpretations\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\n5.2.2.3 Test for Spatial Autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nIn order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\n\ntmap_mode(\"view\")\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\ntmap_mode(\"plot\")\n\nInterpretations\n\nThe figure above reveal that there is sign of spatial autocorrelation.\n\nTo proof that our observation is indeed true, the Moran’s I test will be performed."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#gwr-model-method",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#gwr-model-method",
    "title": "In-class Exercise 8: Geograpgically Weighted Regression",
    "section": "5.3 GWR Model Method",
    "text": "5.3 GWR Model Method\nTwo steps:\n\nFind the bandwidth\nCalibrate the bandwidth into the GWR model\n\n\n5.3.1 Building fixed bandwidth GWR Model\nComputing the optimal fixed bandwidth\n\nbw.fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\n\n\n\n\n\n\nNote\n\n\n\nTo compute the fixed bandwidth,\n\nadaptive = FALSE\n\nhere are two approaches for stopping rule:\n\nCV cross validation\nAIC corrected\n\n\n\nInterpretations\n\nThe result shows that the recommended bandwidth is 971.3405 metres\nHow do we know if its in metres? Because we are using projected system\n\nCalibrate the GWR model using fixed bandwidth\n\nIf the data is in decimal degree, we need to set longlat = TRUE\nIf the data is already projected, we need to set longlat = FALSE\nNote that the bw.fixed is derived from previous code chunk\nNote: Results of global regression treats all weights as the same (=1)\nMultiple models are built using GWR, represented with each data point\nComparing Non geographical weighted model (Base model) with geographical weighted model:\n\nAdjusted r squared = 0.6472 (Non geographical weighted model) and Adjusted r squared = 0.84 (geographical weighted model)\nThe geographical weighted model is able to account 84% of the variance\nAICc = 4296.74 (Non geographical weighted model) and AICc = 42263.61 (geographical weighted model)\n\n\n\ngwr.fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-03-11 11:28:39.624894 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2024-03-11 11:28:40.586305 \n\n\nInterpretations\nThe report shows that the AICc (AIC corrected) of the GWR is 42263.61 which is significantly smaller than the global multiple linear regression model of 42967.1.\n\n\n5.3.2 Building adaptive bandwidth GWR Model\nComputing the adaptive bandwidth bandwidth\n\nbw.adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nInterpretations\n\nThe result shows that the 30 is the recommended data points (neighbors) to be used.\nNote that the distance may be bigger than 970 meters as it needs to get 30 neighbours (the closest neighbor may be located 970 meters away)\nNote: CV is used here, but we can also use AICc\n\nCalibrate the GWR model using adaptive bandwidth\n\ngwr.adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-03-11 11:28:49.958819 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-03-11 11:28:51.465137 \n\n\nInterpretations\n\nThe report shows that the AICc the adaptive distance GWR is 41982.22 which is even smaller than the AICc of the fixed distance GWR of 42263.61.\n\nVisualising GWR Output\nTo visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.\n\nEach row represents a model\n\n\ncondo_resale.sf.adaptive &lt;- st_as_sf(gwr.adaptive$SDF) %&gt;%\n  st_transform(crs=3414)\n\ncondo_resale.sf.adaptive.svy21 &lt;- st_transform(condo_resale.sf.adaptive, 3414)\n\ngwr.adaptive.output &lt;- as.data.frame(gwr.adaptive$SDF)\n\ncondo_resale.sf.adaptive &lt;- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\nNext, glimpse() is used to display the content of condo_resale.sf.adaptive sf data frame.\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       &lt;dbl&gt; 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              &lt;dbl&gt; 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   &lt;dbl&gt; -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              &lt;dbl&gt; -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        &lt;dbl&gt; 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      &lt;dbl&gt; -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  &lt;dbl&gt; -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              &lt;dbl&gt; -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             &lt;dbl&gt; -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      &lt;dbl&gt; 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    &lt;dbl&gt; 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         &lt;dbl&gt; 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           &lt;dbl&gt; 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       &lt;dbl&gt; -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              &lt;dbl&gt; 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               &lt;dbl&gt; 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               &lt;dbl&gt; 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\n\n\n\nVisualising local R2\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\ntmap_mode(\"plot\")\n\nInterpretations\n\nLower than the global (base) model 0.718\nEach data point is a regression model that explains the variation of that property price. This allows you to give a better estimate\n\nVisualising coefficient estimates\n\nsync = TRUE (both views from the two maps will be synchronised)\n\n\ntmap_mode(\"view\")\nAREA_SQM_SE &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nVisualising Local R2 by URA Planning Region\n\nZooming into central region\n\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)\n\n\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "",
    "text": "1st Order Spatial Point Patterns Analysis\n\nKernel Density Estimation (KDE) Maps\nNearest Neighbor Analysis using Clark-Evans Test\n\n2nd Order Spatial Point Patterns Analysis\n\nComplete Spatial Randomness (CSR) Test using G, F, K and L functions"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-geospatial-data",
    "title": "Take-home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "2.1 Importing Geospatial Data",
    "text": "2.1 Importing Geospatial Data\nThe Thailand Subnational Administrative Boundaries dataset is available in ESRI shapefile format. It comprises the administrative boundaries at various levels within Thailand.\n\nLevel 0: country\nLevel 1: province\nLevel 2: district\nLevel 3: sub-district or tambon\n\n\nthailand_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"tha_admbnda_adm0_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm0_rtsd_20220121' from data source \n  `C:\\kt526\\IS415-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 13 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\n\nthailand_province_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\kt526\\IS415-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nThere are a total of 77 provinces in Thailand.\n\ntmap_mode(\"plot\")\n\nthailand_map &lt;- tm_shape(thailand_sf) + \n  tm_borders(alpha = 0.8)\n\nthailand_province_map &lt;- tm_shape(thailand_province_sf) + \n  tm_polygons(\"ADM1_EN\") + \n  tm_borders(alpha = 0.8) +\n  tm_legend(show=FALSE)\n\ntmap_arrange(thailand_map, thailand_province_map, ncol = 2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-aspatial-data",
    "title": "Take-home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "2.2 Importing Aspatial Data",
    "text": "2.2 Importing Aspatial Data\n\naccidents &lt;- read_csv(\"data/aspatial/thai_road_accident_2019_2022.csv\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#preparing-a-study-area-layer-by-provinces",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#preparing-a-study-area-layer-by-provinces",
    "title": "Take-home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "3.1 Preparing a study area layer by provinces",
    "text": "3.1 Preparing a study area layer by provinces\n\n3.1.1 Extract relevant columns\nFirstly, we use the colnames() to see all the column names present in thailand_province_sf.\n\ncolnames(thailand_province_sf)\n\n [1] \"Shape_Leng\" \"Shape_Area\" \"ADM1_EN\"    \"ADM1_TH\"    \"ADM1_PCODE\"\n [6] \"ADM1_REF\"   \"ADM1ALT1EN\" \"ADM1ALT2EN\" \"ADM1ALT1TH\" \"ADM1ALT2TH\"\n[11] \"ADM0_EN\"    \"ADM0_TH\"    \"ADM0_PCODE\" \"date\"       \"validOn\"   \n[16] \"validTo\"    \"geometry\"  \n\n\nNext, from thailand_province_sf, we will select the following relevant columns so that its easier for our analysis later on.\n\nADM1_EN\nADM1_PCODE\ngeometry\n\n\nthailand_sf_extracted &lt;- thailand_province_sf %&gt;%\n  select(ADM1_EN,\n         ADM1_PCODE,\n         geometry)\n\n\n\n3.1.2 Check coordinate system\n\n\n3.1.3 Transform geographic coordinate system (GCS) and a projected coordinate system (PCS)\n\n\n3.1.4 Create OWIN object\n\n\n3.1.5 Plot OWIN object"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#preparing-a-road-accident-layer",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#preparing-a-road-accident-layer",
    "title": "Take-home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "3.2 Preparing a road accident layer",
    "text": "3.2 Preparing a road accident layer\n\n3.2.1 Extract relevant columns\n\ncolnames(accidents)\n\n [1] \"acc_code\"                    \"incident_datetime\"          \n [3] \"report_datetime\"             \"province_th\"                \n [5] \"province_en\"                 \"agency\"                     \n [7] \"route\"                       \"vehicle_type\"               \n [9] \"presumed_cause\"              \"accident_type\"              \n[11] \"number_of_vehicles_involved\" \"number_of_fatalities\"       \n[13] \"number_of_injuries\"          \"weather_condition\"          \n[15] \"latitude\"                    \"longitude\"                  \n[17] \"road_description\"            \"slope_description\"          \n\n\nSimilar to thailand_province_sf, we will select the following relevant columns from accidents.\n\nlatitude\nlongtitude\nincident_datetime\nprovince_en\npresumed_cause\nweather_condition\nnumber_of_fatalities\nnumber_of_injuries\n\n\naccidents_extracted &lt;- accidents %&gt;%\n  select(latitude,\n         longitude,\n         incident_datetime,\n         province_en,\n         presumed_cause,\n         weather_condition,\n         number_of_fatalities,\n         number_of_injuries)\n\n\nstr(accidents_extracted)\n\ntibble [81,735 × 8] (S3: tbl_df/tbl/data.frame)\n $ latitude            : num [1:81735] 15 15.2 12.4 18.6 15.9 ...\n $ longitude           : num [1:81735] 100.9 104.9 99.9 98.8 100.6 ...\n $ incident_datetime   : POSIXct[1:81735], format: \"2019-01-01 00:00:00\" \"2019-01-01 00:03:00\" ...\n $ province_en         : chr [1:81735] \"Loburi\" \"Ubon Ratchathani\" \"Prachuap Khiri Khan\" \"Chiang Mai\" ...\n $ presumed_cause      : chr [1:81735] \"driving under the influence of alcohol\" \"speeding\" \"speeding\" \"driving under the influence of alcohol\" ...\n $ weather_condition   : chr [1:81735] \"clear\" \"clear\" \"clear\" \"clear\" ...\n $ number_of_fatalities: num [1:81735] 0 0 1 0 0 0 0 1 3 0 ...\n $ number_of_injuries  : num [1:81735] 2 2 0 1 0 2 2 0 0 1 ...\n\n\n\ncolSums(is.na(accidents_extracted))\n\n            latitude            longitude    incident_datetime \n                 359                  359                    0 \n         province_en       presumed_cause    weather_condition \n                   0                    0                    0 \nnumber_of_fatalities   number_of_injuries \n                   0                    0 \n\n\n\naccidents_extracted &lt;- na.omit(accidents_extracted)\n\n\ncolSums(is.na(accidents_extracted))\n\n            latitude            longitude    incident_datetime \n                   0                    0                    0 \n         province_en       presumed_cause    weather_condition \n                   0                    0                    0 \nnumber_of_fatalities   number_of_injuries \n                   0                    0 \n\n\n\n\n3.2.2 Converting aspatial data into geospatial data\n\naccidents_extracted &lt;- st_as_sf(accidents_extracted, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 32648)\n\nChecking the number of unique provinces in accidents_extracted\n\nunique(accidents_extracted$province_en)\n\n [1] \"Loburi\"                   \"Ubon Ratchathani\"        \n [3] \"Prachuap Khiri Khan\"      \"Chiang Mai\"              \n [5] \"Nakhon Sawan\"             \"Mae Hong Son\"            \n [7] \"Chumphon\"                 \"Sing Buri\"               \n [9] \"Songkhla\"                 \"Trat\"                    \n[11] \"Lamphun\"                  \"Phuket\"                  \n[13] \"Saraburi\"                 \"Ratchaburi\"              \n[15] \"Phra Nakhon Si Ayutthaya\" \"Nakhon Ratchasima\"       \n[17] \"Nakhon Si Thammarat\"      \"Kalasin\"                 \n[19] \"Chaiyaphum\"               \"Suphan Buri\"             \n[21] \"Phetchaburi\"              \"Chai Nat\"                \n[23] \"Phrae\"                    \"Prachin Buri\"            \n[25] \"Nakhon Pathom\"            \"Phetchabun\"              \n[27] \"Ang Thong\"                \"Kanchanaburi\"            \n[29] \"Nonthaburi\"               \"Samut Prakan\"            \n[31] \"Bangkok\"                  \"Phayao\"                  \n[33] \"Phatthalung\"              \"Yala\"                    \n[35] \"Maha Sarakham\"            \"Surat Thani\"             \n[37] \"Amnat Charoen\"            \"Nong Khai\"               \n[39] \"Nan\"                      \"Phangnga\"                \n[41] \"Narathiwat\"               \"Chanthaburi\"             \n[43] \"Samut Sakhon\"             \"Samut Songkhram\"         \n[45] \"Phitsanulok\"              \"Pathum Thani\"            \n[47] \"Tak\"                      \"Loei\"                    \n[49] \"Chiang Rai\"               \"Chachoengsao\"            \n[51] \"Buri Ram\"                 \"Uthai Thani\"             \n[53] \"Krabi\"                    \"Surin\"                   \n[55] \"Udon Thani\"               \"Si Sa Ket\"               \n[57] \"Uttaradit\"                \"Khon Kaen\"               \n[59] \"Kamphaeng Phet\"           \"Yasothon\"                \n[61] \"Satun\"                    \"Nakhon Nayok\"            \n[63] \"Rayong\"                   \"Chon Buri\"               \n[65] \"buogkan\"                  \"Sa Kaeo\"                 \n[67] \"Nong Bua Lam Phu\"         \"Roi Et\"                  \n[69] \"Sakon Nakhon\"             \"Mukdahan\"                \n[71] \"Nakhon Phanom\"            \"Phichit\"                 \n[73] \"Pattani\"                  \"Sukhothai\"               \n[75] \"Trang\"                    \"Lampang\"                 \n[77] \"Ranong\"                   \"unknown\"                 \n\n\nThere are a total of 78 provinces? An unknown province is present in the unique list.\nRemove unknown province.\n\naccidents_extracted &lt;- accidents_extracted %&gt;% \n  filter(province_en != \"unknown\")\n\n\n\n3.2.3 Check coordinate system\n\n\n3.2.4 Create ppp objects using sf method\n\naccidents_extracted_ppp &lt;- as.ppp(accidents_extracted)\nsummary(accidents_extracted_ppp)\n\nMarked planar point pattern:  81351 points\nAverage intensity 6.160696e-08 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nmarks are of type 'double'\nSummary:\n                      Min.                    1st Qu. \n\"2019-01-01 00:00:00.0000\" \"2020-01-16 14:40:00.0000\" \n                    Median                       Mean \n\"2021-01-02 18:30:00.0000\" \"2021-01-08 10:38:03.3506\" \n                   3rd Qu.                       Max. \n\"2022-01-02 19:17:00.0000\" \"2022-12-31 23:55:00.0000\" \n\nWindow: rectangle = [-255162.2, 555471.8] x [639404.8, 2268356.6] units\n                    (810600 x 1629000 units)\nWindow area = 1.32048e+12 square units\n\n\n\n\n3.2.5 Check for duplicated point events\n\nany(duplicated(accidents_extracted_ppp))\n\n[1] TRUE\n\n\n\nsum(multiplicity(accidents_extracted_ppp) &gt; 1)\n\n[1] 15\n\n\nThe output shows that there are 15 duplicated point events.\n\n\n3.2.6 Removing duplicated point events using jittering approach"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "title": "Hands-on Exercise 9: Geographically Weighted Predictive Models",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to build predictive model by using geographical random forest method.\n\n\n\nPredictive modelling uses statistical learning or machine learning techniques to predict outcomes. By and large, the event one wants to predict is in the future. However, a set of known outcome and predictors (also known as variables) will be used to calibrate the predictive models.\nGeospatial predictive modelling is conceptually rooted in the principle that the occurrences of events being modeled are limited in distribution. When geographically referenced data are used, occurrences of events are neither uniform nor random in distribution over space. There are geospatial factors (infrastructure, sociocultural, topographic, etc.) that constrain and influence where the locations of events occur. Geospatial predictive modeling attempts to describe those constraints and influences by spatially correlating occurrences of historical geospatial locations with environmental factors that represent those constraints and influences.\n\n\n\n\npacman::p_load(sf, spdep, GWmodel, SpatialML, \n               tmap, rsample, Metrics, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#getting-started",
    "title": "Hands-on Exercise 9: Geographically Weighted Predictive Models",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to build predictive model by using geographical random forest method."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview",
    "title": "Hands-on Exercise 9: Geographically Weighted Predictive Models",
    "section": "",
    "text": "Predictive modelling uses statistical learning or machine learning techniques to predict outcomes. By and large, the event one wants to predict is in the future. However, a set of known outcome and predictors (also known as variables) will be used to calibrate the predictive models.\nGeospatial predictive modelling is conceptually rooted in the principle that the occurrences of events being modeled are limited in distribution. When geographically referenced data are used, occurrences of events are neither uniform nor random in distribution over space. There are geospatial factors (infrastructure, sociocultural, topographic, etc.) that constrain and influence where the locations of events occur. Geospatial predictive modeling attempts to describe those constraints and influences by spatially correlating occurrences of historical geospatial locations with environmental factors that represent those constraints and influences."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-loading-r-packages",
    "title": "Hands-on Exercise 9: Geographically Weighted Predictive Models",
    "section": "",
    "text": "pacman::p_load(sf, spdep, GWmodel, SpatialML, \n               tmap, rsample, Metrics, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#computing-correlation-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#computing-correlation-matrix",
    "title": "Hands-on Exercise 9: Geographically Weighted Predictive Models",
    "section": "4.0 Computing Correlation Matrix",
    "text": "4.0 Computing Correlation Matrix\nTo examine if there are signs of multicollinearity, we can plot a correlation matrix\n\nmdata_nogeo &lt;- mdata %&gt;%\n  st_drop_geometry()\ncorrplot::corrplot(cor(mdata_nogeo[, 2:17]), \n                   diag = FALSE, \n                   order = \"AOE\",\n                   tl.pos = \"td\", \n                   tl.cex = 0.5, \n                   method = \"number\", \n                   type = \"upper\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-a-non-spatial-multiple-linear-regression",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-a-non-spatial-multiple-linear-regression",
    "title": "Hands-on Exercise 9: Geographically Weighted Predictive Models",
    "section": "5.0 Building a non-spatial multiple linear regression",
    "text": "5.0 Building a non-spatial multiple linear regression\n\ntrain_data &lt;- read_rds(\"data/rds/train_data.rds\")\ntest_data &lt;- read_rds(\"data/rds/test_data.rds\")\n\nprice_mlr &lt;- lm(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                data=train_data)\nsummary(price_mlr)\n\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + \n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + \n    PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\nfloor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\nstorey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\nremaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\nPROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\nPROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\nPROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\nPROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\nPROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\nPROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\nPROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\nWITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\nWITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\nWITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\nWITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 61650 on 10320 degrees of freedom\nMultiple R-squared:  0.7373,    Adjusted R-squared:  0.737 \nF-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/data/geospatial/MPSZ-2019.html",
    "title": "IS415 Geospatial Analytics and Applications",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#reading-data-file-to-rds",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#reading-data-file-to-rds",
    "title": "Hands-on Exercise 9: Geographically Weighted Predictive Models",
    "section": "3.1 Reading data file to rds",
    "text": "3.1 Reading data file to rds\n\nmdata &lt;- read_rds(\"data/aspatial/mdata.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#data-sampling",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#data-sampling",
    "title": "Hands-on Exercise 9: Geographically Weighted Predictive Models",
    "section": "3.1 Data Sampling",
    "text": "3.1 Data Sampling\n\nset.seed(1234)\nresale_split &lt;- initial_split(mdata, \n                              prop = 6.5/10,)\ntrain_data &lt;- training(resale_split)\ntest_data &lt;- testing(resale_split)\n\n\nwrite_rds(train_data, \"data/rds/train_data.rds\")\nwrite_rds(test_data, \"data/rds/test_data.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#loading-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#loading-packages",
    "title": "Take-home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "1.0 Loading Packages",
    "text": "1.0 Loading Packages\n\npacman::p_load(raster, sf, st, lubridate, tidyverse, tmap, spatstat)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-datasets-into-r-environment",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-datasets-into-r-environment",
    "title": "Take-home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "2.0 Importing Datasets into R Environment",
    "text": "2.0 Importing Datasets into R Environment\nIn this exercise, we will be using the following datasets:\n\n\n\n\n\n\n\n\nData\nType\nFormat\n\n\n\n\n➡️Thailand Road Accident [2019-2022] | Aspatial | .csv |\n\n\n➡️Thailand Subnational Administrative Boundaries | Geospatial | .shp |\n\n\nGeofabrik’s OpenStreetMap road data for Thailand\nGeospatial\n.shp\n\n\n\n\n2.1 Importing Geospatial Data\nThe Thailand Subnational Administrative Boundaries dataset is available in ESRI shapefile format. It comprises the administrative boundaries at various levels within Thailand.\n\nLevel 0: country\nLevel 1: province\nLevel 2: district\nLevel 3: sub-district or tambon\n\n\nthailand_sf &lt;- st_read(dsn = \"data/geospatial\",\n                        layer = \"tha_admbnda_adm0_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm0_rtsd_20220121' from data source \n  `C:\\kt526\\IS415-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 13 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\n\nthailand_province_sf &lt;- st_read(dsn = \"data/geospatial\",\n                                layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\kt526\\IS415-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nThere are a total of 77 provinces in Thailand.\n\ntmap_mode(\"plot\")\nthailand_map &lt;- tm_shape(thailand_sf) +\n  tm_borders(alpha = 0.8)\n\nthailand_province_map &lt;- tm_shape(thailand_province_sf) + \n  tm_polygons(\"ADM1_EN\") +\n  tm_borders(alpha = 0.8) + \n  tm_legend(show=FALSE)\n\ntmap_arrange(thailand_map, thailand_province_map, ncol = 2)\n\n\n\n\n\n\n2.2 Importing Aspatial Data\n\naccidents &lt;- read_csv(\"data/aspatial/thai_road_accident_2019_2022.csv\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-wrangling",
    "title": "Take-home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "3.0 Data Wrangling",
    "text": "3.0 Data Wrangling\n\n3.1 Preparing a study area layer\n\n3.1.1 Extract relevant columns\nFirstly, we use the colnames() to see all the column names present in thailand_province_sf.\n\ncolnames(thailand_province_sf)\n\n [1] \"Shape_Leng\" \"Shape_Area\" \"ADM1_EN\"    \"ADM1_TH\"    \"ADM1_PCODE\"\n [6] \"ADM1_REF\"   \"ADM1ALT1EN\" \"ADM1ALT2EN\" \"ADM1ALT1TH\" \"ADM1ALT2TH\"\n[11] \"ADM0_EN\"    \"ADM0_TH\"    \"ADM0_PCODE\" \"date\"       \"validOn\"   \n[16] \"validTo\"    \"geometry\"  \n\n\nNext, from thailand_province_sf, we will select the following relevant columns so that its easier for our analysis later on.\n\nADM1_EN\nADM1_PCODE\ngeometry\n\n\nthailand_province_sf_extracted &lt;- thailand_province_sf %&gt;%\n  select(ADM1_EN,\n         ADM1_PCODE,\n         geometry)\n\n\n\n3.1.2 Check coordinate system\n\nst_crs(thailand_province_sf_extracted)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\n3.1.3 Transform geographic coordinate system (GCS) and a projected coordinate system (PCS)\n\nthailand_province_sf_extracted &lt;- st_transform(thailand_province_sf_extracted,                                crs = 32648)\n\nst_geometry(thailand_province_sf_extracted)\n\nGeometry set for 77 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -313055.3 ymin: 621843.5 xmax: 568269.6 ymax: 2271054\nProjected CRS: WGS 84 / UTM zone 48N\nFirst 5 geometries:\n\n\n\nst_crs(thailand_province_sf_extracted)\n\nCoordinate Reference System:\n  User input: EPSG:32648 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 48N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 48N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",105,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 102°E and 108°E, northern hemisphere between equator and 84°N, onshore and offshore. Cambodia. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Russian Federation. Singapore. Thailand. Vietnam.\"],\n        BBOX[0,102,84,108]],\n    ID[\"EPSG\",32648]]\n\n\n\n\n3.1.4 Create OWIN object\n\nthailand_owin &lt;- as.owin(thailand_province_sf_extracted)\n\n\n\n3.1.5 Plot OWIN object\n\nplot(thailand_owin)\n\n\n\n\n\n\n\n3.2 Preparing a road accident layer\n\n3.2.1 Extract relevant columns\n\ncolnames(accidents)\n\n [1] \"acc_code\"                    \"incident_datetime\"          \n [3] \"report_datetime\"             \"province_th\"                \n [5] \"province_en\"                 \"agency\"                     \n [7] \"route\"                       \"vehicle_type\"               \n [9] \"presumed_cause\"              \"accident_type\"              \n[11] \"number_of_vehicles_involved\" \"number_of_fatalities\"       \n[13] \"number_of_injuries\"          \"weather_condition\"          \n[15] \"latitude\"                    \"longitude\"                  \n[17] \"road_description\"            \"slope_description\"          \n\n\nSimilar to thailand_province_sf, we will select the following relevant columns from accidents.\n\nlatitude\nlongtitude\nincident_datetime\nprovince_en\npresumed_cause\nweather_condition\nnumber_of_fatalities\nnumber_of_injuries\n\n\naccidents_extracted &lt;- accidents %&gt;%   select(latitude,\n                                              longitude,\n                                              incident_datetime,\n                                              province_en,\n                                              presumed_cause,\n                                              weather_condition,\n                                              number_of_fatalities,\n                                              number_of_injuries)\n\n\nstr(accidents_extracted)\n\ntibble [81,735 × 8] (S3: tbl_df/tbl/data.frame)\n $ latitude            : num [1:81735] 15 15.2 12.4 18.6 15.9 ...\n $ longitude           : num [1:81735] 100.9 104.9 99.9 98.8 100.6 ...\n $ incident_datetime   : POSIXct[1:81735], format: \"2019-01-01 00:00:00\" \"2019-01-01 00:03:00\" ...\n $ province_en         : chr [1:81735] \"Loburi\" \"Ubon Ratchathani\" \"Prachuap Khiri Khan\" \"Chiang Mai\" ...\n $ presumed_cause      : chr [1:81735] \"driving under the influence of alcohol\" \"speeding\" \"speeding\" \"driving under the influence of alcohol\" ...\n $ weather_condition   : chr [1:81735] \"clear\" \"clear\" \"clear\" \"clear\" ...\n $ number_of_fatalities: num [1:81735] 0 0 1 0 0 0 0 1 3 0 ...\n $ number_of_injuries  : num [1:81735] 2 2 0 1 0 2 2 0 0 1 ...\n\n\n\ncolSums(is.na(accidents_extracted))\n\n            latitude            longitude    incident_datetime \n                 359                  359                    0 \n         province_en       presumed_cause    weather_condition \n                   0                    0                    0 \nnumber_of_fatalities   number_of_injuries \n                   0                    0 \n\n\n\naccidents_extracted &lt;- na.omit(accidents_extracted)\n\n\ncolSums(is.na(accidents_extracted))\n\n            latitude            longitude    incident_datetime \n                   0                    0                    0 \n         province_en       presumed_cause    weather_condition \n                   0                    0                    0 \nnumber_of_fatalities   number_of_injuries \n                   0                    0 \n\n\n\n\n3.2.2 Converting aspatial data into geospatial data\n\naccidents_extracted &lt;- st_as_sf(accidents_extracted,\n                                coords = c(\"longitude\", \"latitude\"),\n                                crs=4326) %&gt;%\n  st_transform(crs = 32648)\n\nChecking the number of unique provinces in accidents_extracted.\n\nunique(accidents_extracted$province_en)\n\n [1] \"Loburi\"                   \"Ubon Ratchathani\"        \n [3] \"Prachuap Khiri Khan\"      \"Chiang Mai\"              \n [5] \"Nakhon Sawan\"             \"Mae Hong Son\"            \n [7] \"Chumphon\"                 \"Sing Buri\"               \n [9] \"Songkhla\"                 \"Trat\"                    \n[11] \"Lamphun\"                  \"Phuket\"                  \n[13] \"Saraburi\"                 \"Ratchaburi\"              \n[15] \"Phra Nakhon Si Ayutthaya\" \"Nakhon Ratchasima\"       \n[17] \"Nakhon Si Thammarat\"      \"Kalasin\"                 \n[19] \"Chaiyaphum\"               \"Suphan Buri\"             \n[21] \"Phetchaburi\"              \"Chai Nat\"                \n[23] \"Phrae\"                    \"Prachin Buri\"            \n[25] \"Nakhon Pathom\"            \"Phetchabun\"              \n[27] \"Ang Thong\"                \"Kanchanaburi\"            \n[29] \"Nonthaburi\"               \"Samut Prakan\"            \n[31] \"Bangkok\"                  \"Phayao\"                  \n[33] \"Phatthalung\"              \"Yala\"                    \n[35] \"Maha Sarakham\"            \"Surat Thani\"             \n[37] \"Amnat Charoen\"            \"Nong Khai\"               \n[39] \"Nan\"                      \"Phangnga\"                \n[41] \"Narathiwat\"               \"Chanthaburi\"             \n[43] \"Samut Sakhon\"             \"Samut Songkhram\"         \n[45] \"Phitsanulok\"              \"Pathum Thani\"            \n[47] \"Tak\"                      \"Loei\"                    \n[49] \"Chiang Rai\"               \"Chachoengsao\"            \n[51] \"Buri Ram\"                 \"Uthai Thani\"             \n[53] \"Krabi\"                    \"Surin\"                   \n[55] \"Udon Thani\"               \"Si Sa Ket\"               \n[57] \"Uttaradit\"                \"Khon Kaen\"               \n[59] \"Kamphaeng Phet\"           \"Yasothon\"                \n[61] \"Satun\"                    \"Nakhon Nayok\"            \n[63] \"Rayong\"                   \"Chon Buri\"               \n[65] \"buogkan\"                  \"Sa Kaeo\"                 \n[67] \"Nong Bua Lam Phu\"         \"Roi Et\"                  \n[69] \"Sakon Nakhon\"             \"Mukdahan\"                \n[71] \"Nakhon Phanom\"            \"Phichit\"                 \n[73] \"Pattani\"                  \"Sukhothai\"               \n[75] \"Trang\"                    \"Lampang\"                 \n[77] \"Ranong\"                   \"unknown\"                 \n\n\nThere are a total of 78 provinces? An unknown province is present in the unique list.\nRemove unknown province.\n\naccidents_extracted &lt;- accidents_extracted %&gt;%\n  filter(province_en != \"unknown\")\n\n\n\n3.2.3 Check coordinate system\n\nst_crs(accidents_extracted)\n\nCoordinate Reference System:\n  User input: EPSG:32648 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 48N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 48N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",105,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 102°E and 108°E, northern hemisphere between equator and 84°N, onshore and offshore. Cambodia. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Russian Federation. Singapore. Thailand. Vietnam.\"],\n        BBOX[0,102,84,108]],\n    ID[\"EPSG\",32648]]\n\n\n\n\n3.2.4 Create ppp objects using sf method\n\naccidents_extracted_ppp &lt;- as.ppp(accidents_extracted)\nsummary(accidents_extracted_ppp)\n\nMarked planar point pattern:  81351 points\nAverage intensity 6.160696e-08 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nmarks are of type 'double'\nSummary:\n                      Min.                    1st Qu. \n\"2019-01-01 00:00:00.0000\" \"2020-01-16 14:40:00.0000\" \n                    Median                       Mean \n\"2021-01-02 18:30:00.0000\" \"2021-01-08 10:38:03.3506\" \n                   3rd Qu.                       Max. \n\"2022-01-02 19:17:00.0000\" \"2022-12-31 23:55:00.0000\" \n\nWindow: rectangle = [-255162.2, 555471.8] x [639404.8, 2268356.6] units\n                    (810600 x 1629000 units)\nWindow area = 1.32048e+12 square units\n\n\n\n\n3.2.5 Check for duplicated point events\n\nany(duplicated(accidents_extracted_ppp))\n\n[1] TRUE\n\n\n\nsum(multiplicity(accidents_extracted_ppp) &gt; 1)\n\n[1] 15\n\n\nThe output shows that there are 15 duplicated point events.\n\n\n3.2.6 Removing duplicated point events using jittering approach\n\naccidents_ppp_jit &lt;- rjitter(accidents_extracted_ppp,\n                             retry=TRUE,\n                             nsim=1,\n                             drop=TRUE)\n\nany(duplicated(accidents_ppp_jit))\n\n[1] FALSE\n\n\n\n\n\n3.3 Combine point events with OWIN object\n\naccidentsTHAI_ppp = accidents_extracted_ppp[thailand_owin]\n\n\n3.3.1 Visualising Point Symbol Map\n\ntmap_mode(\"plot\")\ntm_shape(accidents_extracted) +\n  tm_dots()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#st-order-spatial-point-patterns-analysis",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#st-order-spatial-point-patterns-analysis",
    "title": "Take-home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "4.0 1st Order Spatial Point Patterns Analysis",
    "text": "4.0 1st Order Spatial Point Patterns Analysis\n\n4.1 Kernel Density Estimation (KDE) Maps\n\naccidentsTHAI_ppp_km &lt;- rescale(accidentsTHAI_ppp, 1000, \"km\")\n\nkde_accidentsTHAI_diggle &lt;- density(accidentsTHAI_ppp_km,\n                                sigma=bw.diggle,\n                                edge=TRUE,\n                                kernel=\"gaussian\")\nplot(kde_accidentsTHAI_diggle,\n     main = \"Automatic-Bandwidth KDE for Road Accident Points (Using bw_diggle)\")\n\n\n\n\nPlotting Interactive KDE Maps\n\nraster_kde_auto_diggle &lt;- raster(kde_accidentsTHAI_diggle)\nprojection(raster_kde_auto_diggle) &lt;- CRS(\"+init=EPSG:32648 +units=km\")\n\n\ntmap_mode('view')\nkde_adaptive_kernel &lt;- tm_basemap(server = \"OpenStreetMap.DE\") +\n  tm_shape(raster_kde_auto_diggle) +\n  tm_raster(\"layer\",\n            n = 7,\n            title = \"KDE_Adaptive_Kernel\",\n            style = \"pretty\",\n            alpha = 0.6) +\n  tm_shape(thailand_province_sf_extracted) +\n  tm_polygons(alpha=0.1,id=\"ADM1_EN\") +\n  tmap_options(check.and.fix = TRUE)\n\nkde_adaptive_kernel\n\n\n\n\n\ntmap_mode('plot')\n\nWrite data to rds\n\nwrite_rds(thailand_province_sf_extracted, \"data/rds/thailand_province_sf_extracted.rds\")\nwrite_rds(raster_kde_auto_diggle, \"data/rds/raster_kde_auto_diggle.rds\")\nwrite_rds(accidentsTHAI_ppp_km, \"data/rds/accidentsTHAI_ppp_km.rds\")\n\n\n\n4.2 Nearest Neighbour Analysis using Clark-Evans Test\nThe test hypotheses are:\n\nH0 = The spatial distribution of accident points are randomly distributed.\nH1= The spatial distribution of accident points are not randomly distributed.\n\nThe 95% confidence interval will be used.\n\nclarkevans.test(accidentsTHAI_ppp,\n                correction=\"none\",\n                clipregion=\"thailand_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  accidentsTHAI_ppp\nR = 0.24639, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nInterpretations\n\nR-value (0.29484) &lt; 1 indicates clustered distribution\np-value (&lt; 2.2e-16) &lt; 0.05 (critical value)\nReject the null hypothesis (H0) that the spatial distribution of accident points are randomly distributed, signs of clusterings observed"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#nd-order-spatial-point-patterns-analysis",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#nd-order-spatial-point-patterns-analysis",
    "title": "Take-home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "5.0 2nd Order Spatial Point Patterns Analysis",
    "text": "5.0 2nd Order Spatial Point Patterns Analysis\n\n5.1 Complete Spatial Randomness (CSR) Test\n\nG function\nF function\nK function\nL function"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#notes",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#notes",
    "title": "Take-home Exercise 3: Prototyping Modules for Geospatial Analytics Shiny Application",
    "section": "6.0 Notes",
    "text": "6.0 Notes\nNecessary R packages: raster, sf, st, lubridate, tidyverse, tmap, spatstat\n\n\n\n\n\n\n\n\n\nAnalysis\nParameters / Inputs\nOutputs\nShiny UI components\n\n\nKernel Density Estimation Maps\n\nBandwidths: Automatic, Fixed, Adaptive\nKernels: gaussian, epanechnikov, quartic, disc\n\nPlot interactive KDE map(s) given inputs\nParameters / Inputs\n\nselectInput()\nsliderInput()\n\nOutputs\n\nplotOutput()\n\n\n\nNearest Neighbour Analysis using Clark-Evans Test\n\nnsim: 99 to 999\n\nStatistics results\nParameters / Inputs\n\nsliderInput()\n\nOutputs\n\ntext for interpretation\n\n\n\nComplete Spatial Randomness (CSR) Test\n\nnsim: 99 to 999\nType of test: G, F, K, L\n\nPlot interactive chart given inputs\nParameters / Inputs\n\nselectInput()\nsliderInput() for nsim\n\nOutputs\n\nplotOutput()\ntext for interpretation"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to build predictive model by using geographical random forest method.\n\n\n\nPredictive modelling uses statistical learning or machine learning techniques to predict outcomes. By and large, the event one wants to predict is in the future. However, a set of known outcome and predictors (also known as variables) will be used to calibrate the predictive models.\nGeospatial predictive modelling is conceptually rooted in the principle that the occurrences of events being modeled are limited in distribution. When geographically referenced data are used, occurrences of events are neither uniform nor random in distribution over space. There are geospatial factors (infrastructure, sociocultural, topographic, etc.) that constrain and influence where the locations of events occur. Geospatial predictive modeling attempts to describe those constraints and influences by spatially correlating occurrences of historical geospatial locations with environmental factors that represent those constraints and influences.\n\n\n\n\npacman::p_load(sf, spdep, GWmodel, SpatialML, \n               tmap, tidymodels, tidyverse, gtsummary,\n               rpart, rpart.plot, ggstatplot, performance)\n\nNote: Tidymodel is a collection of machine learning libraries."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#getting-started",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#getting-started",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to build predictive model by using geographical random forest method."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#overview",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#overview",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "",
    "text": "Predictive modelling uses statistical learning or machine learning techniques to predict outcomes. By and large, the event one wants to predict is in the future. However, a set of known outcome and predictors (also known as variables) will be used to calibrate the predictive models.\nGeospatial predictive modelling is conceptually rooted in the principle that the occurrences of events being modeled are limited in distribution. When geographically referenced data are used, occurrences of events are neither uniform nor random in distribution over space. There are geospatial factors (infrastructure, sociocultural, topographic, etc.) that constrain and influence where the locations of events occur. Geospatial predictive modeling attempts to describe those constraints and influences by spatially correlating occurrences of historical geospatial locations with environmental factors that represent those constraints and influences."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#installing-and-loading-r-packages",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#installing-and-loading-r-packages",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "",
    "text": "pacman::p_load(sf, spdep, GWmodel, SpatialML, \n               tmap, tidymodels, tidyverse, gtsummary,\n               rpart, rpart.plot, ggstatplot, performance)\n\nNote: Tidymodel is a collection of machine learning libraries."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#reading-data-file-to-rds",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#reading-data-file-to-rds",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "3.1 Reading data file to rds",
    "text": "3.1 Reading data file to rds\n\nrs_sf &lt;- read_rds(\"data/rds/HDB_resale.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#data-sampling",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#data-sampling",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "3.2 Data Sampling",
    "text": "3.2 Data Sampling\n\nset.seed(1234)\nresale_split &lt;- initial_split(rs_sf, \n                              prop = 6.5/10,)\ntrain_data &lt;- training(resale_split)\ntest_data &lt;- testing(resale_split)\n\n\nwrite_rds(train_data, \"data/rds/train_data.rds\")\nwrite_rds(test_data, \"data/rds/test_data.rds\")\n\nNote: After observing out dataset, we tend to split the data. THe resale data is splitted into 50%-50%.\n\nset.seed(1234)\nresale_split &lt;- initial_split(\n  rs_sf,\n  prop = 5/10,\n)\ntrain_sf &lt;- training(resale_split)\ntest_sf &lt;- testing(resale_split)\n\nNote: If we want to stop the splitting, we can set #| eval: false. However, we need to write and read the rds so that the training and testing object an be used for subsequent analysis.\n\nwrite_rds(train_sf, \"data/rds/train_sf.rds\")\nwrite_rds(test_sf, \"data/rds/test_sf.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#retriving-the-stored-data",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#retriving-the-stored-data",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "Retriving the stored data",
    "text": "Retriving the stored data\n\ntrain_sf &lt;- read_rds(\"data/rds/train_sf.rds\")\ntest_sf &lt;- read_rds(\"data/rds/test_sf.rds\")\n\n\ntrain_df &lt;- train_sf %&gt;%\n  st_drop_geometry() %&gt;% \n  as.data.frame()\n\ntest_df &lt;- test_sf %&gt;%\n  st_drop_geometry() %&gt;%\n  as.data.frame()\n\nNote: There is a difference between tibble data frame (from tidyverse) and data frame (from base R).\nWhy do we convert sf into df? If we refer to the documentation for spatialML, the input requires df.\n\nclass(train_sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\nclass(train_df)\n\n[1] \"data.frame\""
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#saving-the-output",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#saving-the-output",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "Saving the output",
    "text": "Saving the output\n\nwrite_rds(train_df, \"data/rds/train_df.rds\")\nwrite_rds(test_df, \"data/rds/test_df.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#retriving-the-stored-data-1",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#retriving-the-stored-data-1",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "Retriving the stored data",
    "text": "Retriving the stored data\n\ntrain_df &lt;- read_rds(\"data/rds/train_df.rds\")\ntest_df &lt;- read_rds(\"data/rds/test_df.rds\")\n\nNote: If we are looking machine learning techniques, correlation matrix is not that important."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#revising-mlr-model",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#revising-mlr-model",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "Revising mlr model",
    "text": "Revising mlr model\n\ntrain_df &lt;- train_df %&gt;%\n  select(-c(PROX_CHAS))\n\ntrain_sf &lt;- train_sf %&gt;%\n  select(-c(PROX_CHAS))\n\ntest_df &lt;- test_df %&gt;%\n  select(-c(PROX_CHAS))\n\ntest_sf &lt;- test_sf %&gt;%\n  select(-c(PROX_CHAS))\n\nThe code chunk below extract x and y coordinates of the full, training and test data sets.\n\ncoords &lt;- st_coordinates(rs_sf)\ncoords_train &lt;- st_coordinates(train_sf)\ncoords_test &lt;- st_coordinates(test_sf)\n\n\nwrite_rds(coords_train, \"data/rds/coords_train.rds\")\nwrite_rds(coords_test, \"data/rds/coords_test.rds\")\n\n\nset.seed(1234)\nrs_rp &lt;- rpart(formula = RESALE_PRICE ~ FLOOR_AREA_SQM +\n               STOREY_ORDER +\n               REMAINING_LEASE_MTHS +\n               PROX_CBD +\n               PROX_ELDERLYCARE +\n               PROX_HAWKER +\n               PROX_MRT  +\n               PROX_PARK +\n               PROX_GOOD_PRISCH +\n               PROX_MALL +\n               PROX_SUPERMARKET + \n               WITHIN_350M_KINDERGARTEN +\n               WITHIN_350M_CHILDCARE +\n               WITHIN_350M_BUS +\n               WITHIN_1KM_PRISCH,\n               data = train_df)\n\n\nrpart.plot(rs_rp)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#calibrating-random-forest-model",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#calibrating-random-forest-model",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "Calibrating Random Forest Model",
    "text": "Calibrating Random Forest Model\nhttps://cran.r-project.org/web/packages/SpatialML/SpatialML.pdf\n\nset.seed(1234)\nrs_rf &lt;- ranger(formula = RESALE_PRICE ~ FLOOR_AREA_SQM +\n               STOREY_ORDER +\n               REMAINING_LEASE_MTHS +\n               PROX_CBD +\n               PROX_ELDERLYCARE +\n               PROX_HAWKER +\n               PROX_MRT  +\n               PROX_PARK +\n               PROX_GOOD_PRISCH +\n               PROX_MALL +\n               PROX_SUPERMARKET + \n               WITHIN_350M_KINDERGARTEN +\n               WITHIN_350M_CHILDCARE +\n               WITHIN_350M_BUS +\n               WITHIN_1KM_PRISCH,\n               data = train_df,\n               importance = \"impurity\")\n\n\nwrite_rds(rs_rf, \"data/models/rs_rf.rds\")\n\n\nrs_rf &lt;- read_rds(\"data/models/rs_rf.rds\")\n\n\nvi &lt;- as.data.frame(rs_rf$variable.importance)\nvi$variables &lt;- rownames(vi)\nvi &lt;- vi %&gt;%\n  rename(vi = \"rs_rf$variable.importance\")\n\n\nggplot(data = vi,\n       aes(x = vi,\n           y = reorder(variables, vi))) +\n  geom_bar(stat = \"identity\")\n\n\n\n\nNote: vi denotes variable importance value\nInterpretations - PROX_CBD, REMAINING_LEASE_MTHS and STOREY_ORDER are the top 3 importance variables - Explains the relative importance of variables - Helps you to tell if your model is performing - If the bar chart shows drastic differences, it means that the model has some issues due to data (complete separation / quasi complete separation issues) https://www.bookdown.org/rwnahhas/RMPH/blr-separation.html"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#retriving-the-stored-data-2",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#retriving-the-stored-data-2",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "Retriving the stored data",
    "text": "Retriving the stored data\n\nrs_grf &lt;- read_rds(\"data/models/rs_grf.rds\")\n\n\ngrf_pred &lt;- predict.grf(rs_grf,\n                        test_data,\n                        x.var.name=\"X\",\n                        y.var.name=\"Y\",\n                        local.w=1,\n                        global.w=0)\n\n\nwrite_rds(grf_pred, \"data/models/grf_pred.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#retriving-the-stored-data-3",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#retriving-the-stored-data-3",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "Retriving the stored data",
    "text": "Retriving the stored data\n\ngrf_pred &lt;- read_rds(\"data/models/grf_pred.rds\")\ngrf_pred_df &lt;- as.data.frame(grf_pred)\n\nThe cbind() is used to append the predicted values onto the test_df\n\ntest_pred &lt;- test_df %&gt;%\n  select(RESALE_PRICE) %&gt;%\n  cbind(grf_pred)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#saving-predicted-output-of-random-forest-and-preparing-final-data-table",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#saving-predicted-output-of-random-forest-and-preparing-final-data-table",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "Saving predicted output of random forest and preparing final data table",
    "text": "Saving predicted output of random forest and preparing final data table\n\nrf_pred &lt;- predict(rs_rf, test_df)\nrf_pred_df &lt;- as.data.frame(rf_pred$predictions) %&gt;%\n  rename(rfpred = \"rf_pred$predictions\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#saving-predicted-output-of-mulitple-linear-regression-and-preparing-final-data-table",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#saving-predicted-output-of-mulitple-linear-regression-and-preparing-final-data-table",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "Saving predicted output of mulitple linear regression and preparing final data table",
    "text": "Saving predicted output of mulitple linear regression and preparing final data table"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#model-comparison",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#model-comparison",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "Model Comparison",
    "text": "Model Comparison\nThe root mean square error\n\nyardstick::rmse(test_pred,\n                RESALE_PRICE,\n                grf_pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard      28745.\n\n\nPivoting\n\n#mc &lt;- test_pred %&gt;%\n#  pivot_longer(cols = c(2,4),\n#               names_to = \"models\",\n#               values_to = \"predicted\")\n\nNote: Table output will be in a long table format."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#comparison-matrix",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#comparison-matrix",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "Comparison matrix",
    "text": "Comparison matrix\n.estimate measures the error, grf_pred model perform better"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#visualising-the-predicted-values",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#visualising-the-predicted-values",
    "title": "In-class Exercise 9: Geographically Weighted Predictive Models",
    "section": "Visualising the predicted values",
    "text": "Visualising the predicted values\nUsing scatterplot (the ml model assumes the relationship to be linear, which result in high errors as compared to grf model) ML model has higher variation (~2 sub markets identified) compared to gfr model"
  }
]