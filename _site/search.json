[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Preface",
    "section": "",
    "text": "Welcome to Geospatial Data Science and Analytics with R. This book aims to share with you the theory, the methods and the R tools specially designed to meet the challenges of analysing geographic problems and data.\n\nLesson Plan\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nHands-on Exercise 1: Geospatial Data Handling and Wrangling with R\n\n\n\n\n\n\n\n\n\n10 min\n\n\n\n\n\n\n  \n\n\n\n\nHands-on Exercise 2: Thematic Mapping and GeoVisualisation with R\n\n\n\n\n\n\n\n\n\n15 min\n\n\n\n\n\n\n  \n\n\n\n\nHands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods\n\n\n\n\n\n\n\n\n\n24 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "In this hands-on exercise, we will be using the following packages:\n\nmaptools for manipulating geographic data\n(Note: We will use maptools to convert Spatial objects into ppp format of spatstat)\nraster for reading, writing, manipulating, analyzing and modelling of gridded spatial data\n(Note: We will use raster to convert image output generated by spatstat into raster format)\nsf for handling geospatial data\nspatstat for point pattern analysis\n(Note: We will use spatstat to perform 1st and 2nd order spatial point patterns analysis and derive kernel density estimation (KDE) layer)\ntmap for creating thematic maps such as choropleth and proportional symbol maps,\n\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\npackage 'maptools' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\user\\AppData\\Local\\Temp\\Rtmpmm070D\\downloaded_packages\n\n\n\npacman::p_load(maptools, raster, sf, spatstat, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "In this hands-on exercise, we will be using the following packages:\n\nmaptools for manipulating geographic data\n(Note: We will use maptools to convert Spatial objects into ppp format of spatstat)\nraster for reading, writing, manipulating, analyzing and modelling of gridded spatial data\n(Note: We will use raster to convert image output generated by spatstat into raster format)\nsf for handling geospatial data\nspatstat for point pattern analysis\n(Note: We will use spatstat to perform 1st and 2nd order spatial point patterns analysis and derive kernel density estimation (KDE) layer)\ntmap for creating thematic maps such as choropleth and proportional symbol maps,\n\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\npackage 'maptools' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\user\\AppData\\Local\\Temp\\Rtmpmm070D\\downloaded_packages\n\n\n\npacman::p_load(maptools, raster, sf, spatstat, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#extracting-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#extracting-geospatial-data-sets",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.1 Extracting Geospatial Data Sets",
    "text": "2.1 Extracting Geospatial Data Sets\nFollowing a structure similar to Hands-on Exercise 01, start by creating a new folder labeled Hands-on_Ex03. Within this folder, create a sub-folder named data. Inside the data sub-folder, create one additional sub-folders and rename them geospatial.\nUnzip MasterPlan2014SubzoneBoundaryWebSHP.zip and place all the unzipped files, PreSchoolsLocation.geojson into the geospatial sub-folder."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-geospatial-data",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "3.1 Importing Geospatial Data",
    "text": "3.1 Importing Geospatial Data\nIn the previous exercises, we have learnt to import geospatial data into RStudio by using st_read() of sf package. Let’s try it now!\n\nchildcare_sf &lt;- st_read(\"data/geospatial/PreSchoolsLocation.geojson\")\n\nReading layer `PreSchoolsLocation' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\geospatial\\PreSchoolsLocation.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\ncoastaloutline_sf &lt;- st_union(mpsz_sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#checking-the-contents-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#checking-the-contents-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "3.2 Checking the Contents of A Simple Feature Data Frame",
    "text": "3.2 Checking the Contents of A Simple Feature Data Frame\n\n3.2.1 Using st_geometry() to check for inappropriate coordinate systems\n\nst_geometry(childcare_sf)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\n\nst_geometry(mpsz_sf)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\n\nst_geometry(coastaloutline_sf)\n\nGeometry set for 1 feature \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou might have observed variations in the coordinate systems among the data frames. Recall in Hands-on Exercise 01, it is a common practice to transform original data from geographical coordinate system to projected coordinate system.\n\nchildcare_sf uses WGS 84 (geographic coordinate system)\nmpsz_sf and coastal_outline_sf uses uses SVY21 (projected coordinate system)\n\nLet’s perform projection transformation on childcare_sf and sgsz_sf using st_transform() of sf package.\n\nchildcare3414 &lt;- st_transform(childcare_sf, \n                              crs = 3414)\n\nNow, we will display the contents of childcare3414.\n\nst_geometry(childcare3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nNotice that childcare3414 is now in SVY21 projected coordinate system.\n\n\n3.2.2 Using st_crs() to check for missing/inaccurate coordinate systems\n\nDIY: Using the appropriate sf function you learned in Hands-on Exercise 2, retrieve the referencing system information of these geospatial data.\n\nTo retrieve coordinate reference system from sf object, we need to use st_crs() from sf package.\n\nst_crs(childcare3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nst_crs(coastaloutline_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz_sf and coastaloutline_sf are projected in SVY21, the output near the end indicates that EPSG is 9001. This is a wrong EPSG code. The correct EPSG code for SVY21 should be 3414. Let’s change it using st_transform() of sf package.\n\nDIY: Using the method you learned in Lesson 2, assign the correct crs to mpsz_sf and coastaloutline_sf.\n\n\nmpsz3414 &lt;- st_transform(mpsz_sf, 3414)\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\ncoastaloutline3414 &lt;- st_transform(coastaloutline_sf, 3414)\nst_crs(coastaloutline3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG code are in 3414 now."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-sf-data-frames-to-sps-spatial-class",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-sf-data-frames-to-sps-spatial-class",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.1 Converting sf data frames to sp’s Spatial* class",
    "text": "5.1 Converting sf data frames to sp’s Spatial* class\nLet’s convert sf data frames into sp’s Spatial* class using as_Spatial() of sf package.\n\nchildcare &lt;- as_Spatial(childcare3414)\nmpsz &lt;- as_Spatial(mpsz3414)\ncoastaloutline &lt;- as_Spatial(coastaloutline3414)\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 2290 \nextent      : 11810.03, 45404.24, 25596.33, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                       Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;3-IN-1 FAMILY CENTRE&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;ST0027&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;DF7EC9C2478FA5A5&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,   &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;Zulfa Kindergarten&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT9603&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;527C1231DDD0FA64&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093632&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\ncoastaloutline\n\nclass       : SpatialPolygons \nfeatures    : 1 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\nNotice that the geospatial data have been converted into their respective sp’s Spatial* classes now."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.2 Converting the Spatial* class into generic sp format",
    "text": "5.2 Converting the Spatial* class into generic sp format\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nmpsz_sp &lt;- as(mpsz, \"SpatialPolygons\")\ncoastaloutline_sp &lt;- as(coastaloutline, \"SpatialPolygons\")\n\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 2290 \nextent      : 11810.03, 45404.24, 25596.33, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nmpsz_sp\n\nclass       : SpatialPolygons \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\ncoastaloutline_sp\n\nclass       : SpatialPolygons \nfeatures    : 1 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.3 Converting the generic sp format into spatstat’s ppp format",
    "text": "5.3 Converting the generic sp format into spatstat’s ppp format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp &lt;- as(childcare_sp, \"ppp\")\n\nNow, let us plot childcare_ppp and examine the different.\n\nplot(childcare_ppp)\n\n\n\n\nWe can take a quick look at the summary statistics of the newly created ppp object by using summary().\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  2290 points\nAverage intensity 2.875673e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis, an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#handling-duplicated-points",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.4 Handling Duplicated Points",
    "text": "5.4 Handling Duplicated Points\nTo check for duplication in a ppp object, we can do the following:\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of co-incidence point, we will use multiplicity().\n\nmultiplicity(childcare_ppp)\n\nTo know the total number of locations that have more than one point event, we can use sum():\n\nsum(multiplicity(childcare_ppp))\n\n[1] 3676\n\n\nThe output shows that there are 2451 duplicated point events.\nTo view the locations of these duplicate point events, we will plot the childcare data.\n\ntmap_mode(\"view\")\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nThere are 3 ways to handle duplicated points:\n\nDelete the duplicates\nUse jittering\nMake each point “unique” and then attach the duplicates of the points to the patterns as marks\n\nIn this hands-on exercise, we will implement the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp,\n                             retry=TRUE,\n                             nsim=1,\n                             drop=TRUE)\n\n\nDIY: Using the method you learned in previous section, check if any duplicated point in this geospatial data.\n\nTo check for any duplicated point, recall any(duplicated()).\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.5 Creating owin object",
    "text": "5.5 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nTo convert sg SpatialPolygon object into owin object of spatstat, run the following:\n\nsg_owin &lt;- as(coastaloutline_sp, \"owin\")\n\nThe ouput object can be displayed by using plot() and summary():\n\nplot(sg_owin)\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n80 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1                4  9.47108e+01      1.21e-07\npolygon 2               37  1.29481e+04      1.66e-05\npolygon 3               30  4.28933e+03      5.49e-06\npolygon 4              145  9.61782e+05      1.23e-03\npolygon 5              227  1.10308e+06      1.41e-03\npolygon 6               19  3.09221e+04      3.95e-05\npolygon 7               10  6.60195e+03      8.44e-06\npolygon 8              234  2.08755e+06      2.67e-03\npolygon 9               22  6.74651e+03      8.63e-06\npolygon 10              71  5.63061e+03      7.20e-06\npolygon 11              10  1.99717e+02      2.55e-07\npolygon 12           14663  6.97996e+08      8.93e-01\npolygon 13 (hole)        3 -2.05920e-03     -2.63e-12\npolygon 14 (hole)        3 -2.89050e-05     -3.70e-14\npolygon 15 (hole)        3 -2.83151e-01     -3.62e-10\npolygon 16 (hole)        3 -3.99521e-02     -5.11e-11\npolygon 17 (hole)        3 -4.95057e-02     -6.33e-11\npolygon 18 (hole)        3 -3.65501e-03     -4.67e-12\npolygon 19 (hole)        4 -2.05611e-02     -2.63e-11\npolygon 20 (hole)        3 -1.68316e-04     -2.15e-13\npolygon 21 (hole)       26 -1.25665e+03     -1.61e-06\npolygon 22 (hole)        3 -2.18000e-06     -2.79e-15\npolygon 23 (hole)        3 -6.62377e-01     -8.47e-10\npolygon 24 (hole)        3 -2.09065e-03     -2.67e-12\npolygon 25 (hole)       36 -7.79904e+03     -9.97e-06\npolygon 26 (hole)        3 -8.83647e-03     -1.13e-11\npolygon 27 (hole)        3 -2.21090e+00     -2.83e-09\npolygon 28 (hole)       40 -6.00381e+03     -7.68e-06\npolygon 29 (hole)        7 -1.40545e-01     -1.80e-10\npolygon 30 (hole)       20 -4.39069e+00     -5.62e-09\npolygon 31 (hole)       28 -1.99862e+01     -2.56e-08\npolygon 32 (hole)       48 -1.38338e+02     -1.77e-07\npolygon 33 (hole)      351 -1.21433e+03     -1.55e-06\npolygon 34 (hole)       12 -8.36709e+01     -1.07e-07\npolygon 35 (hole)      317 -5.11280e+04     -6.54e-05\npolygon 36 (hole)       36 -4.01660e+04     -5.14e-05\npolygon 37              30  2.80002e+04      3.58e-05\npolygon 38              27  1.50315e+04      1.92e-05\npolygon 39              15  4.03300e+04      5.16e-05\npolygon 40            1045  4.44510e+06      5.68e-03\npolygon 41 (hole)       13 -3.91907e+02     -5.01e-07\npolygon 42              47  3.82087e+04      4.89e-05\npolygon 43              65  8.42861e+04      1.08e-04\npolygon 44             478  2.06120e+06      2.64e-03\npolygon 45             266  1.50631e+06      1.93e-03\npolygon 46             234  4.72886e+05      6.05e-04\npolygon 47              14  5.86546e+03      7.50e-06\npolygon 48              83  5.28920e+03      6.76e-06\npolygon 49              75  1.73526e+04      2.22e-05\npolygon 50             148  3.10395e+03      3.97e-06\npolygon 51             142  3.22293e+03      4.12e-06\npolygon 52              45  2.51218e+03      3.21e-06\npolygon 53              40  1.38607e+04      1.77e-05\npolygon 54              10  4.90942e+02      6.28e-07\npolygon 55              95  5.96187e+04      7.62e-05\npolygon 56 (hole)        4 -1.86410e-02     -2.38e-11\npolygon 57              64  3.43149e+04      4.39e-05\npolygon 58 (hole)        3 -1.98390e-03     -2.54e-12\npolygon 59 (hole)        3 -5.55856e-03     -7.11e-12\npolygon 60 (hole)        3 -5.12482e-03     -6.55e-12\npolygon 61 (hole)        3 -1.96410e-03     -2.51e-12\npolygon 62 (hole)        4 -1.13774e-02     -1.46e-11\npolygon 63             155  2.67502e+05      3.42e-04\npolygon 64             106  3.04104e+03      3.89e-06\npolygon 65            1027  1.27782e+06      1.63e-03\npolygon 66 (hole)        3 -3.23310e-04     -4.13e-13\npolygon 67 (hole)        3 -1.16959e-03     -1.50e-12\npolygon 68 (hole)        3 -1.46474e-03     -1.87e-12\npolygon 69             211  4.70521e+05      6.02e-04\npolygon 70               4  2.69313e+02      3.44e-07\npolygon 71             132  9.53357e+04      1.22e-04\npolygon 72               6  4.50259e+02      5.76e-07\npolygon 73             285  1.61128e+06      2.06e-03\npolygon 74              91  1.49663e+04      1.91e-05\npolygon 75              71  8.18750e+03      1.05e-05\npolygon 76             668  5.40368e+07      6.91e-02\npolygon 77              77  3.29939e+05      4.22e-04\npolygon 78             711  1.28815e+07      1.65e-02\npolygon 79 (hole)        3 -3.41405e-01     -4.37e-10\npolygon 80              44  2.26577e+03      2.90e-06\nenclosing rectangle: [2667.54, 56396.44] x [15748.72, 50256.33] units\n                     (53730 x 34510 units)\nWindow area = 781945000 square units\nFraction of frame area: 0.422"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#combining-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#combining-point-events-object-and-owin-object",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.6 Combining point events object and owin object",
    "text": "5.6 Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore.\n\nchildcareSG_ppp &lt;- childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class.\n\nsummary(childcareSG_ppp)\n\n\nDIY: Using the method you learned in previous exercise, plot the newly derived childcareSG_ppp as shown below.\n\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#kernel-density-estimation-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#kernel-density-estimation-kde",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "6.1 Kernel Density Estimation (KDE)",
    "text": "6.1 Kernel Density Estimation (KDE)\nWhat is Kernel Density Estimation? Kernel Density Estimation, KDE, is a non-parametric technique that estimates the probability density function of a continuous variable. In simple terms, it smooths out your data by placing a kernel (usually a Gaussian kernel is used as default) at each data point and then summing up these kernels to create a continuous curve. This curve offers a more refined view of how data points are distributed across the variable’s range\nRead more about KDE here.\nHow does KDE actually works?\n\n\n\nFig 1. Equation for Gaussian kernel\n\n\nRead more about how KDE works here.\n\n6.1.1 Computing KDE using Automatic Bandwidth Selection method\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                              kernel=\"gaussian\") \n\n\nplot(kde_childcareSG_bw)\n\n\n\n\nNotice how the density values of the legend range from 0 to 0.000035. This is way too small to comprehend ! 👀\nWhy is this the case? This is because the default unit measurement for SVY 21 is in meter.\nAs a result, the density values computer is in ” umber of points per square meter”.\n\nNote: We can retrieve the bandwidth used to compute the KDE layer using bw.diggle().\n\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n295.4419 \n\n\n\n\n6.1.2 Rescaling KDE values\nNoting that the default unit measurement for SVY 21 is in meter, is it possible to convert the unit measurement into kilometer? To do so, we can use the rescale().\n\nchildcareSG_ppp.km &lt;- rescale(childcareSG_ppp, 1000, \"km\")\n\nLet’s run density() using childcareSG_ppp.km (a.k.a. rescaled dataset) and plot out the KDE map.\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp.km,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\nplot(kde_childcareSG_bw)\n\n\n\n\nNotice that output image looks identical to the earlier version, the only changes in the data values (refer to the legend).\n\n\n6.1.3 Working with different automatic bandwidth methods\nBesides bw.diggle(), there are three other spatstat functions that can be used to determine the bandwidth, they are:\n\nbw.CvL(),\nbw.scott(), and\nbw.ppl()\n\nLet’s take a look at the bandwidth returned by these automatic bandwidth calculation methods.\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2954419 \n\n\n\nbw.CvL(childcareSG_ppp.km)\n\n  sigma \n4.54311 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.111666 1.347496 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.2109003 \n\n\nThere is ongoing debate regarding the optimal methods for pattern detection. However, according to a study, it is recommended to employ bw.ppl() when dealing with patterns predominantly characterized by tight clusters. On the other hand, bw.diggle() is suggested for detecting a single tight cluster within a background of random noise. In comparing bw.diggle() and bw.ppl():\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2), mar = c(2, 2, 2, 2))\nplot(kde_childcareSG_bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n6.1.4 Working with different kernel methods\nThe default kernel method employed in density.ppp() is Gaussian. However, there are three alternative options available:\n\nEpanechnikov,\nQuartic, and\nDics\n\n\npar(mfrow=c(2,2), mar = c(2, 2, 2, 2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"),\n     main=\"Disc\")\n\n\n\n\n\n\n6.1.5 Computing KDE by using Fixed Bandwidth\nLet’s compute a KDE layer by defining a bandwidth of 600 meters. We’ll use a sigma value of 0.6 in this case, as the unit of measurement of our childcareSG_ppp.km object is in kilometers, hence the 600m is 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\nA downside of fixed bandwidth is that this method is very sensitive to highly skewed distributions.\n\n\n6.1.6 Computing KDE by using Adaptive Bandwidth\nOne way to overcome this problem is by using adaptive bandwidth with density.adaptive() of spatstat package.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\nWe can now compare the results of fixed and adaptive kernel density estimation.\n\npar(mfrow=c(1,2), mar = c(2, 2, 2, 2))\nplot(kde_childcareSG_bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n6.1.7 Converting KDE output into grid object and grid object into raster\nIn order for a KDE output to be suitable for mapping purposes, we can convert it into a grid object.\n\nNote: The results will be the same.\n\n\ngridded_kde_childcareSG_bw &lt;- as.SpatialGridDataFrame.im(kde_childcareSG_bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\nNext, we will convert the gridded kernal density objects into RasterLayer object by using raster() of raster package.\n\nkde_childcareSG_bw_raster &lt;- raster(gridded_kde_childcareSG_bw)\n\nLet’s take a look at the properties of kde_childcareSG_bw_raster RasterLayer.\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.419757, 0.2695907  (x, y)\nextent     : 2.667538, 56.39644, 15.74872, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -1.227421e-14, 43.27275  (min, max)\n\n\n\nNotice that the crs property is NA.\n\n\n\n6.1.8 Assigning projection systems\nTo assign projection systems:\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.419757, 0.2695907  (x, y)\nextent     : 2.667538, 56.39644, 15.74872, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -1.227421e-14, 43.27275  (min, max)\n\n\nLastly, let’s visualize raster in cartographic quality map using tmap package.\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field.\n\n\n\n6.1.9 Comparing Spatial Point Patterns using KDE\nLet’s compare the KDE of childcare at Punggol, Tampines, Chua Chu Kang and Jurong West planning areas.\n\n6.1.9.1 Extracting study area\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\n\n\n6.1.9.2 Plotting target planning areas\n\npar(mfrow=c(2,2), mar = c(2, 2, 2, 2))\nplot(pg, main = \"PUNGGOL\")\nplot(tm, main = \"TAMPINES\")\nplot(ck, main = \"CHOA CHU KANG\")\nplot(jw, main = \"JURONG WEST\")\n\n\n\n\n\n\n6.1.9.3 Converting the spatial point data frame into generic sp format\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n\n\n6.1.9.4 Creating owin object\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\n\n\n6.1.9.5 Combining childcare points and the study area\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nWe will use rescale() to transform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nLastly, let’s plot out the four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2), mar = c(2, 2, 2, 2))\nplot(childcare_pg_ppp.km, main=\"PUNGGOL\")\nplot(childcare_tm_ppp.km, main=\"TAMPINES\")\nplot(childcare_ck_ppp.km, main=\"CHOA CHU KANG\")\nplot(childcare_jw_ppp.km, main=\"JURONG WEST\")\n\n\n\n\n\n\n6.1.9.6 Computing KDE of four planning areas using Automatic Bandwidth Selection method\nWe will now use the bw.diggle() automatic bandwidth selection to derive the bandwidths for each planning areas.\n\npar(mfrow=c(2,2), mar = c(2, 2, 2, 2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"PUNGGOL\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"TAMPINES\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"CHOA CHU KANG\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JURONG WEST\")\n\n\n\n\n\n\n6.1.9.7 Computing KDE of four planning areas using Fixed Bandwidth Selection method\nFor comparison purposes, let’s also try computing the KDE layers by defining a fixed bandwidth of 250 meters.\n\npar(mfrow=c(2,2), mar = c(2, 2, 2, 2))\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"PUNGGOL\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"TAMPINES\")\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"CHOA CHU KANG\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JURONG WEST\")\n\n\n\n\n\nNote: The sigma value of 0.25 in this case, as the unit of measurement of our childcare_tm_ppp.km object is in kilometers, hence the 250m is 0.25km."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#nearest-neighbor-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#nearest-neighbor-analysis",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "6.2 Nearest Neighbor Analysis",
    "text": "6.2 Nearest Neighbor Analysis\nIn this section, we will be performing the Clark-Evans test of aggregation for SPPA, using the clarkevans.test() of statspat package.\nTo get started, let’s formulate our test hypotheses and state the confidence interval we are using:\n\nH0 = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confidence interval will be used.\n\n\nNote:\nNull Hypothesis (H0) – This can be thought of as the implied hypothesis. “Null” meaning “nothing”. This hypothesis states that there is no difference between groups or no relationship between variables. The null hypothesis is a presumption of status quo or no change.\nAlternative Hypothesis (H1) – This is also known as the claim. This hypothesis should state what you expect the data to show, based on your research on the topic. This is your answer to your research question.\nRead more about null and alternative hypotheses here.\n\n\n6.2.1 Testing spatial point patterns using Clark-Evans Test\n1clarkevans.test(childcareSG_ppp,\n2                correction=\"none\",\n3                clipregion=\"sg_owin\",\n4                alternative=c(\"clustered\"),\n5                nsim=99)\n\n1\n\nchildcareSG_ppp: a spatial point pattern - object of class ppp,\n\n2\n\ncorrection: character string of the type of edge correction to be applied; correction=\"none\" denotes no edge correction is applied,\n\n3\n\nclipregion a window for guard area correction - object of class owin,\n\n4\n\nalternative: string indicating the type of alternative for the hypothesis test. Partially matched; alternative=“clustered” denotes the alternative hypothesis is that R &lt; 1 corresponding to a clustered point pattern\n\n5\n\nnsim: number of Monte Carlo simulations to perform\n\n\nNote: If the argument clipregion is given, then the selected edge corrections will be assumed to include correction=\"guard\".\n\n6.2.1.1 Performing Clark-Evans Test in Choa Chu Kang planning area\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.76075, p-value = 1.575e-05\nalternative hypothesis: two-sided\n\n\n\n\n6.2.1.2 Performing Clark-Evans Test in Tampines planning area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.60102, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, we will be using sf and tidyverse packages:\n\nsf for handling geospatial data\ntidyverse for performing data science tasks such as importing, wrangling and visualising data\n\n\nNote: Tidyverse consists of a family of R packages, such as readr, tidyr, and dplyr.\n\n\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, we will be using sf and tidyverse packages:\n\nsf for handling geospatial data\ntidyverse for performing data science tasks such as importing, wrangling and visualising data\n\n\nNote: Tidyverse consists of a family of R packages, such as readr, tidyr, and dplyr.\n\n\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#extracting-geospatial-and-aspatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#extracting-geospatial-and-aspatial-data-sets",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "2.1 Extracting Geospatial and Aspatial Data Sets",
    "text": "2.1 Extracting Geospatial and Aspatial Data Sets\nStart by creating a new folder labeled Hands-on_Ex01. Within this folder, create a sub-folder named data. Inside the data sub-folder, create two additional sub-folders and rename them geospatial and aspatial respectively. Take note of this hierarchical structure as we will be using it to manage our datasets for the upcoming exercises.\nUnzip CyclingPath.zip and MasterPlan2014SubzoneBoundaryWebSHP.zip and place all the unzipped files and PreSchoolsLocation.kml into the geospatial sub-folder.\nPlace listings.csv into aspatial sub-folder."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "3.1 Importing Geospatial Data",
    "text": "3.1 Importing Geospatial Data\nThe geospatial data we have are:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format\nCyclingPath, a line feature layer in ESRI shapefile format\nPreSchool, a point feature layer in kml file format\n\nNow that we have obtained our data, it’s time to examine the formats they are in and explore the process of importing them into R using st_read() of sf package. The arguments it takes in depends on the file format.\n\nFor shapefile format, we need to provide two arguments:\n\ndsn: To define the data path, a.k.a, the file directory pointing to the shapefile (no file extension needed!)\nlayer: To provide the name of the shapefile\n\nFor kml format, the only argument we need is the complete path with the kml file extension\n\n\n3.1.1 Importing polygon feature data in shapefile format\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe message above reveals that the geospatial objects are multipolygon features. There are a total of 323 multipolygon features and 15 fields in mpsz simple feature data frame. mpsz is in SVY21 projected coordinates systems. The bounding box provides the x extend and y extend of the data.\n\n\n3.1.2 Importing polyline feature data in shapefile form\n\ncyclingpath &lt;- st_read(dsn = \"data/geospatial\", layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe message above reveals that there are a total of 2558 features and 2 fields in cyclingpath linestring feature data frame and it is in SVY21 projected coordinates system too.\n\n\n3.1.3 Importing GIS data in kml format\n\npreschool &lt;- st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe message above reveals that preschool is a point feature data frame. There are a total of 2290 features and 2 fields. Different from the previous two simple feature data frame, preschool is in WGS 84 coordinates system."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "3.2 Checking the Content of A Simple Feature Data Frame",
    "text": "3.2 Checking the Content of A Simple Feature Data Frame\nIn this sub-section, we will learn different ways to retrieve information related to the content of a simple feature data frame.\n\n3.2.1 Working with st_geometry()\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\n\n\n3.2.2 Working with glimpse()\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n3.2.3 Working with head()\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "4.1 Plotting Geospatial Data",
    "text": "4.1 Plotting Geospatial Data\nIn the field of geospatial data science, simply examining feature information is insufficient. We are also interested to visualize geospatial features, and this can be accomplished by using plot().\nAs illustrated below, the default plot of an sf object showcases a multi-plot visualization of all attributes (up to a reasonable amount).\n\nplot(mpsz)\n\n\n\n\nHowever, there might be occasions when our focus is solely on visualizing a particular attribute…\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\nIn some cases, we may just want to visualize the geometry (map outline):\n\nplot(st_geometry(mpsz))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-projections",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-projections",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "4.2 Working with Projections",
    "text": "4.2 Working with Projections\nMap projection is an important property of geospatial data. To effectively process two sets of geospatial data, we need to ensure that both data are projected using similar coordinate system.\nIn this section, we will learn how to project a simple feature data frame from one coordinate system to another coordinate system. This technical process is referred to as projection transformation.\nThere are two common issues that require projection transformation:\n\nMissing or inaccurate coordinate system\nInappropriate coordinate systems\n\n\n4.2.1 Missing/inaccurate coordinate system\nOne of the common issue that can happen during importing geospatial data into RStudio is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz simple feature data frame is projected in SVY21, the output near the end indicates that EPSG is 9001. This is a wrong EPSG code. The correct EPSG code for SVY21 should be 3414. Let’s change it using st_set_crs() of sf package:\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nNow, let us check the CSR again.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG code is 3414 now.\n\n\n4.2.2 Inappropriate coordinate systems\nRecall the geospatial data that was introduced in [3.1 Importing Geospatial Data]. You might have observed variations in the coordinate systems among the data frames:\n\nmpsz and cyclingpath uses SVY21\npreschool uses WGS 84\n\nWhen we are geoprocessing preschool, we might run into issues due to the inappropriate usage of a geographic coordinate system, especially when distance and/or area measurements are essential for the analysis.\nThus, it is a common practiceto transform original data from geographic coordinate system to projected coordinate system.\nIn the case of preschool, st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\nLet us display the content of preschool3414.\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nNotice that it is now in SVY21 projected coordinate system.\n\nYou might notice a change in the values within the bounding box—they are now extended beyond the typical 0-360 range of decimal degrees commonly used by the majority of geographic coordinate systems."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-and-converting-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-and-converting-aspatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "5.1 Importing and Converting Aspatial Data",
    "text": "5.1 Importing and Converting Aspatial Data\nSince listings.csv is in csv file format, we will use read_csv() of readr package to import it.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,457 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,447 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe output R object is called listings and it is a tibble data frame. There are 4252 rows and 16 columns (not features and fields like in our simple data feature frame!)\n\nTake note of the latitude and longitude fields as we will be using them in the next phase.\n\nWe can convert listing into a simple feature data frame by using st_as_sf() of sf packages.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThis results in the creation of a new simple feature data frame - listings_sf.\n\nglimpse(listings_sf)\n\nRows: 3,457\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 64, 78, 220, 85, 75, 69, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.13, 0.16, 0.30, 0.15, 0.11, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 51, 51, 5, 7, 51, 51, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 55, 91, 91, 183, 183, 54, 365, 183, 183…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 2, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\n\nNotice that a new column called geometry has been added! In addition,longtitude and latitude columns have both been dropped."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "6.1 Buffering",
    "text": "6.1 Buffering\nImagine a bustling town with a popular cycling path that has become a hub for outdoor enthusiasts. The local authority, recognizing the path’s significance, has decided to embark on an ambitious project to upgrade and enhance the existing cycling infrastructure. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. Your role in this exciting venture is to determine the extent of land required and their total area.\nFirstly, let’s compute the 5-meter buffers around the cycling paths using the st_buffer() of sf package:\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nNext, let’s calculate the area of the buffers:\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, let’s find the total land involved with sum():\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "title": "Hands-on Exercise 1: Geospatial Data Handling and Wrangling with R",
    "section": "6.2 Point-in-polygon count",
    "text": "6.2 Point-in-polygon count\nHere’s another scenario:\nLet’s say that preschool service group is planning to organize future outreach events and is curious about the number of preschools in each Planning Subzone.\nWe can perform two operations at one go, using both st_intersects() and length().\n\nst_intersects(): To identify pre-schools located inside each Planning Subzone\nlength(): To calculate numbers of pre-schools that fall inside each Planning Subzone\n\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nWe can check the summary statistics of the newly derived PreSch Count field by using summary().\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the Planning Subzone with the most number of pre-school, the top_n() of dplyr package.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nLastly, to find out the density of preschools by Planning Subzone for future outreach events, we will need derive the area of each Planning Subzone using st_area() of sf package:\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "In this hands-on exercise, we will be using the following packages:\n\ntmap for creating thematic maps such as choropleth and proportional symbol maps,\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data\n\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "In this hands-on exercise, we will be using the following packages:\n\ntmap for creating thematic maps such as choropleth and proportional symbol maps,\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data\n\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#extracting-geospatial-and-aspatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#extracting-geospatial-and-aspatial-data-sets",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "2.1 Extracting Geospatial and Aspatial Data Sets",
    "text": "2.1 Extracting Geospatial and Aspatial Data Sets\nFollowing a structure similar to Hands-on Exercise 01, start by creating a new folder labeled Hands-on_Ex02. Within this folder, create a sub-folder named data. Inside the data sub-folder, create two additional sub-folders and rename them geospatial and aspatial respectively.\nUnzip the MasterPlan2014SubzoneBoundaryWebSHP.zip folder and place all files into geospatial sub-folder.\nUnzip the respopagesextod2011to2020.zip folder and place respopagesextod2011to2020.csv into aspatial sub-folder.\n\nNote: Our aspatial data file does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile!"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-geospatial-data",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "3.1 Importing Geospatial Data",
    "text": "3.1 Importing Geospatial Data\nIn the previous exercise, we have learnt to import geospatial data into RStudio by using st_read() of sf package. Let’s try it now!\n\n3.1.1 Importing polygon feature data in shapefile format\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\kt526\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "3.2 Checking the Content of A Simple Feature Data Frame",
    "text": "3.2 Checking the Content of A Simple Feature Data Frame\n\n3.2.1 Working with st_geometry()\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\n\n\n3.2.2 Working with glimpse()\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n3.2.3 Working with head()\n\nhead(mpsz)\n\nSimple feature collection with 6 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 24468.89 ymin: 28369.47 xmax: 32362.39 ymax: 30542.74\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n6        6          7 ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6         BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6 29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-and-converting-attribute-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-and-converting-attribute-data",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "4.1 Importing and Converting Attribute Data",
    "text": "4.1 Importing and Converting Attribute Data\nNext, we will import respopagsex2011to2020.csv file into RStudio using read_csv() of readr package. Save the file into a R dataframe called popdata.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\", show_col_types = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#checking-the-content-of-a-simple-feature-data-frame-1",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#checking-the-content-of-a-simple-feature-data-frame-1",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "4.2 Checking the Content of A Simple Feature Data Frame",
    "text": "4.2 Checking the Content of A Simple Feature Data Frame\n\n4.2.1 Working with glimpse()\n\nglimpse(popdata)\n\nRows: 984,656\nColumns: 7\n$ PA   &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K…\n$ SZ   &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T…\n$ AG   &lt;chr&gt; \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to_4\", \"0_to…\n$ Sex  &lt;chr&gt; \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"Males\", \"M…\n$ TOD  &lt;chr&gt; \"HDB 1- and 2-Room Flats\", \"HDB 3-Room Flats\", \"HDB 4-Room Flats\"…\n$ Pop  &lt;dbl&gt; 0, 10, 30, 50, 0, 0, 40, 0, 0, 10, 30, 60, 0, 0, 40, 0, 0, 10, 30…\n$ Time &lt;dbl&gt; 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011,…\n\n\n\n\n4.2.2 Working with head()\n\nhead(popdata)\n\n# A tibble: 6 × 7\n  PA         SZ                     AG     Sex   TOD                   Pop  Time\n  &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;\n1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 1- and 2-Room …     0  2011\n2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 3-Room Flats       10  2011\n3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 4-Room Flats       30  2011\n4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 5-Room and Exe…    50  2011\n5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HUDC Flats (exclud…     0  2011\n6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males Landed Properties       0  2011"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-preparation",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "4.3 Data Preparation",
    "text": "4.3 Data Preparation\n\n4.3.1 Data wrangling\nTo create a thematic map, it is necessary for us to prepare a data table containing values for the year 2020. This table should encompass variables such as:\n\nYOUNG: age group 0 to 4 until age 20 to 24,\nECONOMY ACTIVE: age group 25 to 29 until age group 60 to 64,\nAGED: age group 65 and above\nTOTAL: all age groups\nDEPENDENCY: the ratio of YOUNG + AGED groups against the ECONOMY ACTIVE group\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n4.3.2 Combine attribute data with geospatial data\nBefore proceeding with the georelational join, an additional step is necessary to standardize the case of values in the PA and SZ fields. This is essential because the PA and SZ fields contain a mix of upper and lowercase characters. Conversely, the SUBZONE_N and PLN_AREA_N fields are consistently in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nFollowing this, we will use left_join() from the dplyr package to merge the geographical data and attribute table using the planning subzone name, denoted as SUBZONE_N and SZ respectively, as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#quick-plotting-choropleth-maps-using-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#quick-plotting-choropleth-maps-using-qtm",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.1 Quick Plotting Choropleth Maps using qtm()",
    "text": "5.1 Quick Plotting Choropleth Maps using qtm()\nA straightforward and quick method for creating a choropleth map with tmap pacakge involves utilizing the qtm(). It is succinct and offers a well-constructed default visualization that is suitable for many scenarios.\nTo generate a static map, tmap_mode() can be employed with the plot option, while for an interactive mode, the view option should be selected. The fill argument is utilized to map the attribute, namely, DEPENDENCY.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#customizing-choropleth-maps-with-tmap-elements",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#customizing-choropleth-maps-with-tmap-elements",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.2 Customizing Choropleth Maps with tmap elements",
    "text": "5.2 Customizing Choropleth Maps with tmap elements\nWhile qtm() is handy for quickly creating choropleth maps, it has a drawback—it makes it challenging to precisely control the appearance of individual map layers. To achieve a high-quality choropleth map with detailed aesthetics, it’s advisable to leverage tmap’s elements, as demonstrated below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n5.2.1 Drawing a base map\nThe fundamental component of tmap is tm_shape(), serving as the cornerstone for constructing maps. To initiate our map creation, we begin with the base map – the fundamental framework onto which we’ll incorporate statistical details. To achieve this, we input the data mpsz_pop2020 into tm_shape() and then enhance it with one or more layer elements, such as tm_fill() and tm_polygons(). Specifically, we use tm_polygons() to outline the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n5.2.2 Drawing a Choropleth Map using tm_polygons()\nTo create a choropleth map illustrating the geographical distribution of a chosen variable by planning subzone, simply assign the target variable (e.g., DEPENDENCY) to tm_polygons(). This straightforward approach allows us to achieve a visual representation similar to qtm().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n5.2.3 Drawing a Choropleth Maps using tm_fill() and tm_border()\nIn fact, tm_polygons() is a wrapper of tm_fill() and tm_border(). With tm_fill(), polygons are shaded using the default color scheme, while tm_borders() adds the shapefile borders to the choropleth map.\nIf we just use tm_fill() on its own…\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nThe shading on the planning subzones reflects their dependency values, but there are no boundaries. Let’s address that:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nThere’s a noticeable difference from using just tm_polygons() – observe the thinner grey borders? This happens because we adjusted the settings for tm_borders. We tweaked parameters like alpha (transparency from 0 to 1), col (border color), lwd (line width), and lty (line type). The default alpha value is typically 1, col is the border color, lwd defaults to 1, and lty defaults to “solid”."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.3 Data Classification methods",
    "text": "5.3 Data Classification methods\nChoropleth maps often use classification methods to group a bunch of data into different categories or classes. In tmap, there are ten methods you can use for this, like fixed, sd, equal, pretty (the default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a classification method, we can simply use the style argument in tm_fill() or tm_polygons().\n\n5.3.1 Built in classification methods\nNow, let’s try using the jenks and equal classification methods with 5 classes!\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n5.3.2 Custom breaks\nFor all the preset styles, the breaks between categories are calculated automatically. However, if you want to customize these breaks, you can explicitly set them using the breaks option in tm_fill().\n\nNote: for tmap, breaks include a minimum and maximum - so if you want n categories, you’ll need to specify n+1 elements in the breaks argument!\n\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we will set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00).\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#customizing-colour-scheme-with-rcolorbrewer",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#customizing-colour-scheme-with-rcolorbrewer",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.4 Customizing colour scheme with RColorBrewer",
    "text": "5.4 Customizing colour scheme with RColorBrewer\ntmap enables the use of color ramps, which can be either user-defined or selected from a set of predefined ramps in the RColorBrewer package.\nTo modify the color, assign your chosen color to the palette parameter in tm_fill().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nDid you notice that the choropleth map is now shaded in blue?\nWe can also reverse the colour shading by adding a “-“ prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#may-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#may-layouts",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.5 May layouts",
    "text": "5.5 May layouts\nMap layout involves bringing together various map elements into a cohesive design. These elements include the objects being mapped, the title, scale bar, compass, margins, and aspect ratios, among others. The color settings and data classification methods we discussed earlier, related to the palette and breakpoints, contribute to shaping the overall look of the map.\n\n5.5.1 Map legend\nIn tmap, various legend options are available to modify the positioning, format, and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n5.5.2 Map style\nTo change a wide variety of layout settings, we can use the tmap_style():\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n5.5.3 Cartographic furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nAnd lastly, reset to the default style with:\n\ntmap_style(\"white\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#facet-maps",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#facet-maps",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.6 Facet maps",
    "text": "5.6 Facet maps\nAt times, comparing maps is often more effective when they are displayed side by side, an arrangement commonly referred to as small multiple maps or facet maps. These arrangements involve organizing numerous maps side-by-side or occasionally stacked vertically. Small multiple maps are particularly useful for illustrating how spatial relationships evolve concerning another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange()\n\n\n5.6.1 By assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\nAssigning multiple values to at least one of the aesthetic arguments:\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n5.6.2 By defining a group-by variable in tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n5.6.3 By creating multiple stand-alone maps with tmap_arrange()\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#mapping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#mapping-spatial-object-meeting-a-selection-criterion",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.7 Mapping Spatial Object Meeting a Selection Criterion",
    "text": "5.7 Mapping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, an alternative approach is to utilize the selection function to map spatial objects that meet specific selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2: R for Geospatial Data Science",
    "section": "",
    "text": "In this in-class exercise, we will be using the following packages:\n\narrow\nlubridate\ntidyverse\ntmap\nsf\n\n\npacman::p_load(arrow, lubridate, tidyverse, tmap, sf)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#getting-started",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#getting-started",
    "title": "In-class Exercise 2: R for Geospatial Data Science",
    "section": "",
    "text": "In this in-class exercise, we will be using the following packages:\n\narrow\nlubridate\ntidyverse\ntmap\nsf\n\n\npacman::p_load(arrow, lubridate, tidyverse, tmap, sf)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-parquet-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-parquet-data",
    "title": "In-class Exercise 2: R for Geospatial Data Science",
    "section": "3.1 Importing parquet data",
    "text": "3.1 Importing parquet data\n\ndf &lt;- read_parquet(\"data/GrabPosisi/part-00000-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet\")\n\nWrite a code chunk to convert the data type of pingtimestamp from character to datetime.\n\ndf$pingtimestamp &lt;- as_datetime(df$pingtimestamp)\n\nWrite a code chunk to save the reformatted df into a new rds called part0.rds. Save the output into a sub-folder called rds.\n\nwrite_rds(df, \"rds/part0.rds\")\n\nUsing the step you learned in previous lesson,\n\nExtract trips’ origin locations\nDerive three new columns for weekday, start_hr and day of the month\nName the output tibble data.frame origin_df\n\n\norigin_df &lt;- df %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(pingtimestamp) %&gt;%\n  filter(row_number()==1) %&gt;%\n  mutate(Weekday = wday(pingtimestamp,\n                        label=TRUE,\n                        abbr=TRUE),\n         start_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\nExtracting trip ending locations\nWrite a code chunk to extract trips’ destination locations. Similarly, derive the weekday, end_hr and day of the month and name the output tibble data.frame destination_df.\n\ndestination_df &lt;- df %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(desc(pingtimestamp)) %&gt;%\n  filter(row_number()==1) %&gt;%\n  mutate(Weekday = wday(pingtimestamp,\n                        label=TRUE,\n                        abbr=TRUE),\n         end_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\nNote: It is recommend to save the output in .rds format.\n\nwrite_rds(origin_df, \"data/rds/origin_df.rds\")\nwrite_rds(destination_df, \"data/rds/destination_df.rds\")\nTo read back our data from the rds folder\norigin_df &lt;- read_rds(\"data/rds/origin_df.rds\")\ndestination_df &lt;- read_rds(\"data/rds/destination_df.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-g-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-g-function",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.1 Analysing Spatial Point Process Using G-Function",
    "text": "7.1 Analysing Spatial Point Process Using G-Function\nThe G-function measures the distribution of the distances from an arbitrary event to its nearest event. In this section, we will learn how to compute G-function estimation by using Gest() and to perform Monte Carlo Simulation test using envelope() of spatstat package.\n\n7.1.1 Choa Chu Kang planning area\n\n7.1.1.1 Computing G-function estimation\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n7.1.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypotheses formulated are as follows:\n\nH0 = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\n\n\n7.1.2 Tampines planning area\n\n7.1.2.1 Computing G-function estimation\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n7.1.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypotheses formulated are as follows:\n\nH0 = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-f-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-f-function",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.2 Analysing Spatial Point Process Using F-Function",
    "text": "7.2 Analysing Spatial Point Process Using F-Function\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape. In this section, we will learn how to compute F-function estimation by using Fest() and perform Monte Carlo Simulation test using envelope() of spatstat package.\n\n7.2.1 Choa Chu Kang planning area\n\n7.2.1.1 Computing F-function estimation\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n7.2.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypotheses formulated are as follows:\n\nH0 = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-function\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n7.2.2 Tampines planning area\n\n7.2.2.1 Computing F-function estimation\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n7.2.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypotheses formulated are as follows:\n\nH0 = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-function\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-k-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-k-function",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.3 Analysing Spatial Point Process Using K-Function",
    "text": "7.3 Analysing Spatial Point Process Using K-Function\nK-function measures the number of events found up to a given distance of any particular event. In this section, you will learn how to compute K-function estimates by using Kest() of spatstat package and perform Monte Carlo Simulation test using envelope() of spatstat package.\n\n7.3.1 Choa Chu Kang planning area\n\n7.3.1.1 Computing K-function estimation\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n7.3.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypotheses formulated are as follows:\n\nH0 = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with K-function\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n7.3.2 Tampines planning area\n\n7.3.2.1 Computing K-function estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n7.3.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypotheses formulated are as follows:\n\nH0 = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with K-function\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-l-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-l-function",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.4 Analysing Spatial Point Process Using L-Function",
    "text": "7.4 Analysing Spatial Point Process Using L-Function\nIn this section, you will learn how to compute K-function estimates by using Lest() of spatstat package and perform Monte Carlo Simulation test using envelope() of spatstat package.\n\n7.4.1 Choa Chu Kang planning area\n\n7.4.1.1 Computing L-function estimation\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n7.4.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypotheses formulated are as follows:\n\nH0 = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with L-function\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n7.4.2 Tampines planning area\n\n7.4.2.1 Computing L-function estimation\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n7.4.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypotheses formulated are as follows:\n\nH0 = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\n\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with L-function\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3: Kernel Density Estimation",
    "section": "",
    "text": "pacman::p_load(maptools, raster, sf, spatstat, tmap, tidyverse)\n\n\nchildcare_sf &lt;- st_read(\"data/geospatial/ChildCareServices.geojson\") %&gt;%\n  st_transform(crs=3414)\n\nReading layer `ChildCareServices' from data source \n  `C:\\kt526\\IS415-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial\\ChildCareServices.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\kt526\\IS415-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nDifferences between st_combine() and st_union()\n\nmpsz_sf %&gt;%\n  st_combine() %&gt;%\n  plot()\n\n\n\n\n\nmpsz_sf %&gt;%\n  st_union() %&gt;%\n  plot()\n\n\n\n\n\nsg_sf &lt;- mpsz_sf %&gt;%\n  st_union()\n\nCreating ppp objects using sf method instead of spatstat (reduces all 3 steps)\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1925 character character \n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\nIn ppp, it is important for us to detect duplicates and remove them. Duplicates are usually found if we are using geo-referencing on postal codes.\nWhat we are doing in jitter is to seperate the points so that they do not overlap.\nPurpose of owin is to define / confine all the data points in the sturdy area.\nCreating owin using sf method\n\nsg_owin &lt;- as.owin(sg_sf) # note that the input has to be a sf layer\n\nExtracting study area using the sf layer\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\n\nplot(pg, main=\"PUNGGOL\")\n\n\n\nplot(tm, main=\"TAMPINES\")\n\n\n\nplot(ck, main=\"CHOA CHU KANG\")\n\n\n\nplot(jw, main=\"JURONG WEST\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03_KDE.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03_KDE.html",
    "title": "In-class Exercise 3: kde",
    "section": "",
    "text": "In this in-class exercise, we will be using the following packages:\n\npacman::p_load(sf, spNetwork, tmap, classInt, viridis, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03_KDE.html#getting-started",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03_KDE.html#getting-started",
    "title": "In-class Exercise 3: kde",
    "section": "",
    "text": "In this in-class exercise, we will be using the following packages:\n\npacman::p_load(sf, spNetwork, tmap, classInt, viridis, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03_KDE.html#importing-geospatial-data",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03_KDE.html#importing-geospatial-data",
    "title": "In-class Exercise 3: kde",
    "section": "2.1 Importing Geospatial Data",
    "text": "2.1 Importing Geospatial Data\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\",\n                   layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `C:\\kt526\\IS415-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\nchildcare &lt;- st_read(dsn=\"data/geospatial\",\n                    layer=\"Punggol_CC\")\n\nReading layer `Punggol_CC' from data source \n  `C:\\kt526\\IS415-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03_KDE.html#visualizing-the-geospatial-data",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03_KDE.html#visualizing-the-geospatial-data",
    "title": "In-class Exercise 3: kde",
    "section": "2.2 Visualizing the Geospatial data",
    "text": "2.2 Visualizing the Geospatial data\n\ntmap_mode(\"view\")\ntm_shape(childcare) + \n  tm_dots() + \n  tm_shape(network) +\n  tm_lines()\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\nNote: The sequence of plotting is based on the sequence of the code.\n\n\nlixels &lt;- lixelize_lines(network,\n                         750,\n                         mindist=375)\n\n\nNote: Why 750? An empirical study was done to say people are willingly to walk 750m. 375 is to ensure that its equal distance.\n\nWhat can we learned from the code chunk above:\n\nThe length of lixel, lx_length is set to 750\nthe minimum length of a lixel, mindist is set to 375\n\nGenerating line center points\n\nsamples &lt;- lines_center(lixels)\n\n\nNote: The points are located in the center based on the length\n\n\ndensities &lt;- nkde(network,\n                  events=childcare,\n                  w=rep(1,nrow(childcare)),\n                  samples=samples,\n                  kernel_name = \"quartic\",\n                  bw = 300,\n                  div = \"bw\",\n                  method = \"simple\",\n                  digits=1,\n                  tol=1,\n                  grid_shape = c(1,1),\n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose=TRUE)\n\n[1] \"checking inputs ...\"\n[1] \"prior data preparation ...\"\n[1] \"Splitting the data with the spatial grid ...\"\n[1] \"start calculating the kernel values ...\"\n[1] \"    quadra 1/1\"\n[1] \"    build graph ...\"\n[1] \"        calculating NKDE values ...\"\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |======================================================================| 100%[1] \"combining the results ...\"\n\n\n\nNote: More important methods are kernel_name and bw.\nWe aggregate events within a 5m radius for faster calculation"
  }
]