---
title: "Take-home Exercise 2:Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan"
execute:
  eval: true
  echo: true
  warning: false
format:
  html:
    code-fold: false
date: 03/01/2024
toc-depth: 3
code-annotations: hover
---

# 1.0 Introduction

## 1.1. Overview - Setting the Scene

[Dengue Hemorrhagic Fever](https://www.cdc.gov/dengue/resources/denguedhf-information-for-health-care-practitioners_2009.pdf) (in short dengue fever) is one of the most widespread mosquito-borne diseases in the most tropical and subtropical regions. It is an acute disease caused by dengue virus infection which is transmitted by female Aedes aegypti and Aedes albopictus mosquitoes.

In 2015, Taiwan had recorded the most severe dengue fever outbreak with **more than 43,000 dengue cases** and **228 deaths**. Since then, the annual reported dengue fever cases were maintained at the level of not more than 200 cases. However, in **2023**, Taiwan recorded **26703 dengue fever cases**.

## 1.2 Objectives

In this study, we are interested to discover:

-   If the distribution of dengue fever outbreak at Tainan City, Taiwan are independent from spatial (space) and spatio-temporal (space-time).

-   If the outbreak is indeed spatial and spatio-temporal dependent, then, you would like to detect where are the clusters and outliers, and the emerging hot spot/cold spot areas.

## 1.3 Getting Started

In this take-home exercise, we will be using the following packages.

```{r}
pacman::p_load(Kendall, plotly, tidyverse, tmap, sf, sp, sfdep)
```

# 2.0 Data Acquisition

We will be using **2 data sets** in this exercise:

+---------------------+----------------+----------------------------------------------------------------+------------------------------------------------------------------------------------------------------+
| Data                | Format         | Description                                                    | Source                                                                                               |
+=====================+================+================================================================+======================================================================================================+
| TAIWAN_VILLAGE_2020 | ESRI Shapefile | A geospatial data of village boundary of Taiwan                | [data.gov.tw](https://data.gov.tw/en/datasets/130549)                                                |
+---------------------+----------------+----------------------------------------------------------------+------------------------------------------------------------------------------------------------------+
| Dengue_Daily.csv    | csv            | An aspatial data of reported dengue cases in Taiwan since 1998 | [Taiwan CDC Open Data Portal](https://data.cdc.gov.tw/en/dataset/dengue-daily-determined-cases-1998) |
+---------------------+----------------+----------------------------------------------------------------+------------------------------------------------------------------------------------------------------+

Create a new folder labelled `Take-home_Ex02` and place all the files into this folder.

# 3.0 Importing Geospatial and Aspatial Data

## 3.1 Importing Geospatial data

**TAIWAN_VILLAGE_2020**

The TAIWAN_VILLAGE_2020 dataset was acquired in ESRI shapefile format (.shp). To utilise this dataset in the R-environment, we need to import it as an sf object using the st_read() function from the sf package. This function is used to read the shapefile containing the administrative boundaries of Tainan City and returns an sf object named `tainan_sf`.

```{r}
tainan_sf <- st_read(dsn = "data/geospatial", 
                layer = "TAINAN_VILLAGE")
```

The dataset "TAINAN_VILLAGE" represents the polygon features delineating village boundaries within the Tainan City region of Taiwan. It comprises 649 features, each feature corresponding to a distinct village area. The dataset includes 10 fields providing additional attributes associated with each village polygon.

## 3.2 Importing Aspatial data

**Dengue_Daily**

The Dengue_Daily dataset is available in csv format (.csv) and was obtained from the Taiwan CDC Open Data Portal. Like the previous dataset, it needs to be imported into the R environment for use. However, since this dataset is aspatial and in csv format, a different method is required for reading it. We will utilize the read_csv() function to import the csv dataset and store the object in a tibble data frame named `dengue`.

```{r}
dengue <- read_csv("data/aspatial/Dengue_Daily.csv")
head(dengue)
```

# 4.0 Data Wrangling

## 4.1 Preparing a study area layer with specific towns of Tainan City, Taiwan

In this Take-home Exercise, we are interested in narrowing our focus to specific towns within Tainan City, specifically **D01, D02, D04, D06, D07, D08, D32, and D39**. To prepare a study area layer focusing on these specific towns, we can do the following:

```{r}
towns <- c('D01', 'D02', 'D04', 'D06', 'D07', 'D08', 'D32', 'D39')
tainan_towns_sf <- tainan_sf %>%
  select(COUNTYNAME,
         TOWNID,
         TOWNNAME,
         VILLNAME,
         geometry) %>%
  mutate(TOWNNAME_VILLNAME = paste(TOWNNAME, VILLNAME, sep="_")) %>%
  filter(TOWNID %in% towns)
```

```{r}
filtered_rows <- tainan_sf[tainan_sf$TOWNID %in% towns, ]
unique_townnames <- unique(filtered_rows$TOWNNAME)
print(unique_townnames)
```

The c() function is used to combine the specified towns into a vector (a one dimensional array) named `towns`. Next, we will filter the Tainan City spatial data frame (`tainan_sf`) based on the `TOWNID` column, selecting only those entries that match the towns of interest listed in the `towns` vector. This refined dataset, named `tainan_towns_sf`, will serve as our study area layer for further analysis or visualization tasks.

::: callout-tip
## Tip

To ensure that the filter() function works properly, we can check the unique values present in the `TOWNID` field using the unique() function.
:::

```{r}
unique(tainan_towns_sf$TOWNID)
```

And here's how our map for the study area looks like:

```{r}
#| echo: false
tmap_mode("plot")

tm_shape(tainan_towns_sf) + 
  tm_polygons("TOWNID")
```

## 4.2 Preparing a dengue fever layer with specific towns of Tainan City, Taiwan

The subsequent tasks entail preparing the dengue fever layer for specific towns within Tainan City, Taiwan. This involves:

1.  Confining dengue fever layer with TOWNIDs D01, D02, D04, D06, D07, D08, D32 and D39
2.  Extracting dengue fever cases within epidemiology week 31-50, 2023

Firstly, we use the colnames() function to see all the column names present in `dengue`.

```{r}
colnames(dengue)
```

After reading in the dengue dataset, we will notice that the dataset contains 26 variables (columns). Similar to `tainan_sf`, not all columns will be relevant for our investigation. So, let us select the relevant columns from `dengue` and rename them so that its easier for our analysis later on.

-   **發病日:** ONSET_DATE

-   **最小統計區中心點X:** X_COORDINATE (longitude)

-   **最小統計區中心點Y:** Y_COORDINATE (latitude)

-   **居住縣市:** COUNTYNAME

-   **居住鄉鎮:** TOWNNAME

-   **居住村里:** VILLNAME

Let us save the output as a variable called `dengue_extracted`. Afterwards, we will display the structure of `dengue_extracted` using str().

```{r}
dengue_extracted <- dengue %>%
  select(發病日,
         最小統計區中心點X,
         最小統計區中心點Y,
         居住縣市,
         居住鄉鎮,
         居住村里) %>%
  rename("ONSET_DATE" = 發病日,
         "X_COORDINATE" = 最小統計區中心點X,
         "Y_COORDINATE" = 最小統計區中心點Y,
         "COUNTYNAME" = 居住縣市,
         "TOWNNAME" = 居住鄉鎮,
         "VILLNAME" = 居住村里)
```

```{r}
str(dengue_extracted)
```

The `dengue_extracted` is a tibble data.frame and we are now left with 6 variables.

We can also use RStudio's [Data Viewer](https://docs.posit.co/ide/user/ide/guide/data/data-viewer.html) to view the contents of `dengue_extracted`.

![](imgs/dengue_extracted_view.png){fig-align="center"}

Notice the following after using the str() and viewing the `dengue_extracted` contents from Data Viewer :

-   `X_COORDINATE` and `Y_COORDINATE` are in chr and contains "None"

-   `VILLNAME` contains "None"

-   `ONSET_DATE` includes year such as 1998 (We only want year 2023)

::: callout-tip
## Tip

The str() function is articularly useful for getting a quick summary of the structure of the data, including the data types of each column and a glimpse of the actual data.
:::

We definitely have to do something about this ... Let us fix these issues and also create a new column called `EPIWEEK` using the code chunk below. The output will be saved in `dengue_2023`.

```{r}
dengue_2023 <- dengue_extracted %>%
  filter(year(ONSET_DATE) == 2023 &
           X_COORDINATE != "None" &
           Y_COORDINATE != "None" &
           VILLNAME != "None") %>%
  mutate(X_COORDINATE = as.numeric(X_COORDINATE),
         Y_COORDINATE = as.numeric(Y_COORDINATE),
         EPIWEEK = epiweek(ONSET_DATE))

str(dengue_2023)
```

After running the code chunk above, we will see that the new column `EPIWEEK` has been added into `dengue_2023`. `X_COORDINATE` and `Y_COORDINATE` are also now having `num` data type.

To check if the "None" values are still present in `X_COORDINATE`, `Y_COORDINATE` and `VILLNAME`, we can run the following code chunk:

```{r}
dengue_2023 %>% 
  select(contains("None"))
```

If we were to look at `dengue_2023` from the Data Viewer, we can observe that the `COUNTYNAME` contains counties besides 台南市, `TOWNNAME` contains more than the 8 unique towns we want and EPIWEEK is not within 31 to 50.

![](imgs/dengue_2023.png){fig-align="center"}

We can verify this by using the unique() function.

Unique County names (`COUNTYNAME`):

```{r}
unique(dengue_2023$COUNTYNAME)
```

Unique Town names (`TOWNNAME`)

```{r}
unique(dengue_2023$TOWNNAME)
```

Unique Epiweek (`EPIWEEK`)

```{r}
unique(dengue_2023$EPIWEEK)
```

### 4.2.1 Confining dengue fever layer with TOWNIDs D01, D02, D04, D06, D07, D08, D32 and D39

We need to filter `COUNTYNAME` to contain only 台南市 and `TOWNNAME` to contain only the 8 specific towns (安南區, 仁德區, 中西區, 南區, 永康區, 東區, 北區, 安平區). We will save the output in `dengue_fever_layer_df`.

```{r}
dengue_fever_layer_df <- dengue_2023 %>%
  mutate(TOWNNAME_VILLNAME = paste(TOWNNAME, VILLNAME, sep="_")) %>%
  filter(COUNTYNAME == "台南市" & TOWNNAME %in% unique_townnames)
```

Now, let us check `COUNTYNAME` and `TOWNNAME` in `dengue_fever_layer_df`. We should observe that we only have 1 specific county and 8 towns.

```{r}
cat("County:", unique(dengue_fever_layer_df$COUNTYNAME))
cat("Towns:", unique(dengue_fever_layer_df$TOWNNAME))
```

### 4.2.2 Extracting dengue fever cases within epidemiology week 31-50, 2023

Let us visualize the distribution of dengue fever cases across the epidemiology weeks in 2023.

```{r}
ggplot(dengue_fever_layer_df, aes(x = EPIWEEK)) +
  geom_histogram(binwidth = 1, color = "grey") +
  labs(x = "EPIWEEK", y = "Number of dengue cases") +
  ggtitle("Distribution of Dengue Cases in 2023 by Epidemiology weeks") +
  theme_minimal()
```

**More than 80%** of the reported dengue fever cases occurred in **epidemiology week 31-50, 2023**. Let us filter out these dengue fever cases that falls within epidemiology week 31 to 50.

```{r}
dengue_2023_epiweeks_31_50_df <- dengue_fever_layer_df %>%
  filter(between(EPIWEEK, 31, 50) )

unique(dengue_2023_epiweeks_31_50_df$EPIWEEK)
```

## 4.3 Preparing a dengue fever layer in spacetime d3 class of sfdep

The next task is to prepare dengue fever layer in spacetime d3 class using the sfdep package.

```{r}
dengue_grp <- dengue_2023_epiweeks_31_50_df %>%
  group_by(TOWNNAME_VILLNAME, EPIWEEK) %>%
  summarise(num_dengue_cases = n()) %>% 
  complete(EPIWEEK = 31:50, fill = list(num_dengue_cases = 0))
dengue_grp <- as_tibble(dengue_grp)
```

```{r}
tainan_towns_with_dengue <- tainan_towns_sf %>% 
  mutate(TOWNNAME_VILLNAME = paste(TOWNNAME, VILLNAME, sep="_")) %>%
  select(TOWNNAME_VILLNAME, geometry) %>%
  filter(TOWNNAME_VILLNAME %in% unique(dengue_grp$TOWNNAME_VILLNAME))
```

```{r}
tainan_dengue_st <- spacetime(.data = dengue_grp,
                              .geometry = tainan_towns_with_dengue,
                              .loc_col = "TOWNNAME_VILLNAME",
                              .time_col = "EPIWEEK")
```

```{r}
is_spacetime_cube(tainan_dengue_st)
```

::: callout-note
## Note

The **`TRUE`** return confirms that `tainan_dengue_st` is indeed an time-space cube.
:::

## 4.4 Preparing for Exploratory Data Analysis

```{r}
total_dengue_cases_by_village <- dengue_grp %>%
  select(TOWNNAME_VILLNAME,
         num_dengue_cases) %>%
  group_by(TOWNNAME_VILLNAME) %>%
  summarise(total_dengue_cases = sum(num_dengue_cases))
```

```{r}
tainan_dengue_cases_by_village <- left_join(tainan_towns_sf,
                                            total_dengue_cases_by_village,
                                            by = "TOWNNAME_VILLNAME") %>% 
  replace_na(list(total_dengue_cases = 0))
```

```{r}
which(colSums(is.na(tainan_dengue_cases_by_village))>0)
```

# 5.0 Exploratory Data Analysis

In this section, we want to visualize the distribution of dengue fever cases across the 8 specific towns (安南區, 仁德區, 中西區, 南區, 永康區, 東區, 北區, 安平區) and within the epidemiology weeks from 31 to 50. By doing so, we can gain insights into the intensity of the disease and discover any patterns.

```{r}
#| code-fold: true

tmap_mode("plot")

tainan_dengue_cases_by_village_map <- tm_shape(tainan_dengue_cases_by_village) +
  tm_fill("total_dengue_cases",
          style = "jenks",
          palette = "Reds",
          title = "Number of Dengue Cases",
          legend.show = TRUE,
          popup.vars = c("total_dengue_cases")) +
  tm_layout(main.title = "Distribution of Dengue Cases in Tainan Towns",
            main.title.position = "center",
            main.title.size = 0.85,
            legend.height = 0.5,
            legend.width = 0.4,
            frame = TRUE) +
  tm_borders(alpha = 0.8) +
  tm_compass(type="8star", size = 1.5) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)

tainan_towns_map <- tm_shape(tainan_towns_sf) + 
  tm_polygons("TOWNNAME") + 
  tm_layout(main.title = "Map of Tainan Towns",
            main.title.position = "center",
            main.title.size = 0.85,
            legend.height = 0.3,
            legend.width = 0.4,
            legend.title.size = 0.8,
            frame = TRUE) +
  tm_borders(alpha = 0.8) +
  tm_compass(type="8star", size = 1.5) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)

tmap_arrange(tainan_dengue_cases_by_village_map, tainan_towns_map)
```

The choropleth map on the left is used to visualize this distribution. The total number of dengue cases reported is by village level and it can range from 0 to 357. This means that there are villages that are totally clear from dengue cases.

Another interesting insight we discover is that villages that are situated nearer to the center tend to have higher number of dengue cases reported.

```{r}
equal <- tm_shape(tainan_dengue_cases_by_village) +
  tm_fill("total_dengue_cases",
          n = 5,
          style = "equal") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal interval classification")

quantile <- tm_shape(tainan_dengue_cases_by_village) +
  tm_fill("total_dengue_cases",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal quantile classification")

tmap_arrange(equal, 
             quantile, 
             asp=1, 
             ncol=2)
```

# 6.0 Spatial Autocorrelation Analysis

> “Everything is related to everything else, but near things are more related than distant things.”
>
> -- Waldo Tobler, The First Law of Geography

**Spatial Autocorrelation** is used to describe the presence of systematic spatial variation or correlation in a variable.

The two main types of Spatial Autocorrelation Analysis are:

-   Global spatial autocorrelation analysis

-   Local spatial autocorrelation analysis

### 6.2.1 Global Spatial Autocorrelation Analysis

#### 6.2.1.1 Gloabl Measures of Spatial Autocorrelation: Moran’s I and Geary’s C

We can assess spatial autocorrelation using the Moran’s I or Geary's C.

+----------------------------------------------------------------------------+--------------------------------------------------------------------------+
| Moran’s I                                                                  | Geary’s C                                                                |
+============================================================================+==========================================================================+
| ![](imgs/global_moran_i.png)                                               | ![](imgs/global_geary_c.png)                                             |
+----------------------------------------------------------------------------+--------------------------------------------------------------------------+
| Describe how features differ from the values in the study area as a whole. | Describing how features differ from their immediate neighbours.          |
|                                                                            |                                                                          |
| The value of Moran's I can range from -1 to 1:                             | The value of Geary's *C* can range from 0 to \>1:                        |
|                                                                            |                                                                          |
| -   positive (I\>0): Clustered, observations tend to be similar;           | -   Large c value (\>1) : Dispersed, observations tend to be dissimilar; |
|                                                                            |                                                                          |
| -   negative(I\<0): Dispersed, observations tend to be dissimilar;         | -   Small c value (\<1) : Clustered, observations tend to be similar;    |
|                                                                            |                                                                          |
| -   approximately zero: observations are arranged randomly over space.     | -   c = 1: observations are arranged randomly over space.                |
+----------------------------------------------------------------------------+--------------------------------------------------------------------------+

In this Take-home Exercise, we use Moran’s I to test the spatial autocorrelation. To test for spatial autocorrelation, we can follow the steps below:

1.  State the null and alternative hypotheses
    -   H~0~ (null hypothesis): The distribution of dengue fever outbreak at Tainan City are independent from space and time (i.e. spatial indepndent, randomly dispersed)
    -   H~1~ (alternative hypothesis): The distribution of dengue fever outbreak at Tainan City are not independent from space and time (i.e. spatial dependent)
2.  Choose the significance level ⍺
    -   Statistically, we select the confident interval as 95% =\> alpha value (⍺) = 0.05.
3.  Derive the Moran's I, z-score and p-value
4.  State the conclusion
    -   Reject the Null hypothesis (H~0~) if p-value \< alpha value (⍺) = 0.05
    -   Failed to reject the Null Hypothesis (H~0~) if p-value \> alpha value (⍺) = 0.05

#### 6.2.1.2 Computing Spatial Weights

To calculate global spatial autocorrelation statistics effectively, we need to first construct the spatial weights for the study area. The spatial weights play a critical role in defining the neighbourhood relationships between geographical units within the study area.

There are several methods to construct spatial weights. We will be using the Contiguity-Based method to construct the spatial weights and derive the Weights Matrix.

**Contiguity-Based Weights**

This method establishes neighbourhood relationships based on contiguity, where geographical units sharing common borders (boundaries) are considered neighbours. Contiguity can be further categorised into the following cases:

![](imgs/contiguity-based_criterions.png){fig-align="center"}

-   "rook" criterion (sharing a common edge)

-   “bishop” criterion (sharing common vertices)

-   "queen" criterion (sharing a common edge or vertex)

::: callout-note
## Note

“rook" and "queen" criterions are more commonly used.
:::

To derive the **Contiguity-Based Weights,**

```{r}
wm_q <- tainan_dengue_cases_by_village %>%
  mutate(nb = st_contiguity(geometry),
         wt = st_weights(nb,
                         style = "W"),
         .before = 1)

glimpse(wm_q)
```

#### 6.2.1.3 Perform Global Moran's I Test

After formulating the null and alternative hypotheses, we can perform the Global Moran's I Test to derive the Moran's I, z-score and p-value using the global_moran_test() function from sfdep package.

```{r}
global_moran_test(wm_q$total_dengue_cases,
                       wm_q$nb,
                       wm_q$wt)
```

**Interpreting the results**

-   The Moran I statistic standard deviate is 11.538.

-   The Moran’s I statistic is 0.420. This indicates positive spatial correlation (signs of clusterings)

-   The p-value is extremely small (\< 2.2e-16).

We observe the p-value obtained is lower than the significance level (⍺) of 0.05. Thus, we have enough evidence to reject the null hypothesis and conclude the distribution of dengue fever outbreak at Tainan City are not independent from space and time, but spatially dependent. This spatial dependency implies that the likelihood of a dengue fever outbreak in one village is not occurred by random chance but is influenced by neighboring villages.

#### 6.2.1.4 Perform Global Moran's I Permutation Test with Monte-Carlo Simulation

In practice, the Monte-Carlo Simulation should be used to perform the statistical test. We can use the global_moran_perm() function of sfdep package to run the Monte-Carlo Simulation.

::: callout-note
## Note

The set.seed() function in R is used to create reproducible results when writing code that involves creating variables that take on random values. The value placed in the seed can be any random integer. By using the set.seed() function, you guarantee that the same random values are produced each time you run the code. Read more about setting seeds [here](https://www.statology.org/set-seed-in-r/).
:::

```{r}
set.seed(1234)
global_moranI_perm <- global_moran_perm(wm_q$total_dengue_cases,
                       wm_q$nb,
                       wm_q$wt,
                       nsim = 999)

global_moranI_perm
```

::: callout-important
The number of simulations is always equal to nsim + 1. Since nsim = 999, this means that we will be performing 1000 simulations.
:::

**Interpreting the results**

-   The Moran’s I statistic is 0.420. This indicates positive spatial correlation (signs of clusterings)

-   The p-value is extremely small (\< 2.2e-16).

The results from the Monte-Carlo Simulation aligns with the Global Moran's I Test conducted earlier on. The p-value obtained is lower than the significance level (⍺) of 0.05. This means that we enough evidence to reject the null hypothesis and conclude the distribution of dengue fever outbreak at Tainan City are not independent from space and time, but spatially dependent.

#### 6.2.1.5 Visualising Global Monte-Carlo Moran's I

Let us visualise the simulated Moran’s I test statistics by plotting the distribution of the statistical values using a histogram.

```{r}
hist(global_moranI_perm$res, 
     freq=TRUE, 
     breaks=20, 
     xlab="Simulated Moran's I")
abline(v=0, 
       col="red") 
```

We can also look at the summary statistics using the summary() function.

```{r}
summary(global_moranI_perm$res[1:999])
```

### 6.2.2 Local Spatial Autocorrelation Analysis

Even though the Global Spatial Autocorrelation analysis can confirm the presence of clusters or a positive spatial relationship between number of dengue cases and their respective villages, it does not pinpoint the specific locations of these clusters. This is where Local Spatial Autocorrelation analysis becomes essentially useful.

#### 6.2.2.1 Computing Local Moran's I and p-value

To conduct the Local Spatial Autocorrelation analysis, we will need to compute the Local Moran’s I using the local_moran() function. The output `lisa` will be saved as a sf data.frame.

```{r}
lisa <- wm_q %>% 
  mutate(local_moran = local_moran(
    total_dengue_cases, nb, wt, nsim = 999),
         .before = 1) %>%
  unnest(local_moran)


head(lisa)
```

Based on the documentation for [sfdep](https://r-spatial.github.io/spdep/reference/localmoran.html), the output will be a will be `data.frame` containing the following columns:

-   `ii`: local moran statistics

-   `eii`: expectation of local moran statistics

-   `var_ii`: variance of local moran statistics

-   `z_ii`: standard deviate of local moran statistics

-   `p_ii`: p-value of local moran statistics

-   `p_ii_sim`: For `localmoran_perm`, [`rank()`](https://rdrr.io/r/base/rank.html) and [`punif()`](https://rdrr.io/r/stats/Uniform.html) of observed statistic rank for \[0, 1\] p-values using `alternative=`

-   `p_folded_sim`: the simulation folded \[0, 0.5\] range ranked p-value

#### 6.2.2.2 Visualizing local Moran’s I and p-value

The tmap functions are used to prepare a choropleth map by using values in the `ii` (local moran statistics) and `p_ii_sim` fields.

```{r}
tmap_mode("plot")
map1 <- tm_shape(lisa) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "Local Moran's I",
            main.title.position = "center",
            main.title.size = 0.8,
            legend.height = 0.3,
            legend.width = 0.4,
            legend.title.size = 0.8,
            frame = TRUE) +
  tm_borders(alpha = 0.8) +
  tm_compass(type="8star", size = 1.5) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)

map2 <- tm_shape(lisa) +
  tm_fill("p_ii_sim",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of Local Moran's I (with simulation)",
            main.title.position = "center",
            main.title.size = 0.8,
            legend.height = 0.3,
            legend.width = 0.4,
            legend.title.size = 0.8,
            frame = TRUE) +
  tm_borders(alpha = 0.8) +
  tm_compass(type="8star", size = 1.5) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)

tmap_arrange(map1, map2, ncol = 2)
```

#### 6.2.2.3 Visualize the Local Indicator of Spatial Association (LISA) map

The LISA map is a categorical map showing outliers and clusters. LISA map is an interpreted map by combining local Moran’s I of geographical areas and their respective p-values. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two types of clusters namely: High-High and Low-Low clusters.

+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
| **Outliers**       | -   **High-Low (HL):** the area having high number of dengue cases are surrounded by neighbors that have low number of dengue cases     |
|                    |                                                                                                                                         |
|                    | -   **Low-High (LH):** the area having low number of dengue cases are surrounded by neighbors that have high number of dengue cases     |
+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
| **Clusters**       | -   **High-High (HH):** Areas having high number of dengue cases are surrounded by neighbors that also have high number of dengue cases |
|                    |                                                                                                                                         |
|                    | -   **Low-Low (LL):** the area having low number of dengue cases are surrounded by neighbors that also have low number of dengue cases  |
+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------+

```{r}
#| code-fold: true
lisa_sig <- lisa  %>%
  filter(p_ii < 0.05)

tmap_mode("plot")
lisa_map <- tm_shape(lisa) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4) +
  tm_layout(main.title = "LISA Map",
            main.title.position = "center",
            main.title.size = 0.85,
            legend.height = 0.3,
            legend.width = 0.4,
            legend.title.size = 0.8,
            frame = TRUE) +
  tm_borders(alpha = 0.8) +
  tm_compass(type="8star", size = 1.5) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)

tmap_arrange(lisa_map, tainan_towns_map, ncol = 2)
```

**Interpreting the results**

+--------------------+---------------------------------------------------------------------------------------------------------------------------------------+
| **Outliers**       | -   **High-Low (HL):** Only 1 village in 中西區 is an outlier (indicated as yellow on LISA map)                                       |
|                    |                                                                                                                                       |
|                    | -   **Low-High (LH):** 4 villages are outliers. These villages are located in 北區, 永康區 and 南區 (indicated as purple on LISA map) |
+--------------------+---------------------------------------------------------------------------------------------------------------------------------------+
| **Clusters**       | -   **High-High (HH):** These villages are located in 安南區, 北區, 永康區, 東區 and 南區 (indicated as red on LISA map)              |
|                    |                                                                                                                                       |
|                    | -   **Low-Low (LL):** These villages are located in 安南區, 安平區, 永康區 and 中西區 (indicated as green on LISA map)                |
+--------------------+---------------------------------------------------------------------------------------------------------------------------------------+

### 6.2.3 Hot Spot and Cold Spot Area Analysis (HCSA)

HCSA uses spatial weights to identify locations of statistically significant hot spots and cold spots in an spatially weighted attribute that are in proximity to one another based on a calculated distance. The analysis groups features when similar high (hot) or low (cold) values are found in a cluster. The polygon features usually represent administration boundaries or a custom grid structure.

#### 6.2.3.1 Derive Spatial Weights

As usual, we will need to derive a spatial weight matrix before we can compute local Gi\* statistics. The spatial weight matrix will saved in `wm_idw`.

```{r}
wm_idw <- tainan_dengue_cases_by_village %>%
  mutate(nb = st_contiguity(geometry),
         wts = st_inverse_distance(nb, geometry,
                                   scale = 1,
                                   alpha = 1),
         .before = 1)
```

#### 6.2.3.2 Compute Gi\* statistics

Next, let us compute the Gi\* statistics with permutation. nsim is set to 999. This means that we will run 1000 simulations.

```{r}
HCSA <- wm_idw %>% 
  mutate(local_Gi = local_gstar_perm(
    total_dengue_cases, nb, wt, nsim = 999),
         .before = 1) %>%
  unnest(local_Gi)
HCSA
```

#### 6.2.3.3 Mapping Gi\* statistics

```{r}
tmap_mode("plot")
map1 <- tm_shape(HCSA) +
  tm_fill("gi_star") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "Gi* of Dengue cases",
            main.title.position = "center",
            main.title.size = 0.85,
            legend.height = 0.3,
            legend.width = 0.4,
            legend.title.size = 0.8,
            frame = TRUE) +
  tm_borders(alpha = 0.8) +
  tm_compass(type="8star", size = 1.5) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)

map2 <- tm_shape(HCSA) +
  tm_fill("p_value",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of Gi*",
            main.title.position = "center",
            main.title.size = 0.85,
            legend.height = 0.3,
            legend.width = 0.4,
            legend.title.size = 0.8,
            frame = TRUE) +
  tm_borders(alpha = 0.8) +
  tm_compass(type="8star", size = 1.5) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)

tmap_arrange(map1, map2, ncol = 2)
```

Now, we are ready to plot the significant (i.e. p-values \< 0.05) hot spot and cold spot areas by using appropriate tmap functions shown in the code chunk below.

```{r}
HCSA_sig <- HCSA  %>%
  filter(p_sim < 0.05)

tmap_mode("plot")
tainan_towns_map <- tm_shape(tainan_towns_sf) + 
  tm_polygons("TOWNNAME") + 
  tm_layout(main.title = "Map of Tainan Towns",
            main.title.position = "center",
            main.title.size = 0.85,
            legend.height = 0.55,
            legend.width = 0.4,
            legend.title.size = 0.8,
            frame = TRUE) +
  tm_borders(alpha = 0.8) +
  tm_compass(type="8star", size = 1.5) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)

HCSA_sig_map <- tm_shape(HCSA) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(HCSA_sig) +
  tm_fill("gi_star") + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Map of significant hot spot and cold spot areas",
            main.title.position = "center",
            main.title.size = 0.85,
            legend.height = 0.3,
            legend.width = 0.4,
            legend.title.size = 0.8,
            frame = TRUE) +
  tm_borders(alpha = 0.8) +
  tm_compass(type="8star", size = 1.5) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)  

tmap_arrange(tainan_dengue_cases_by_village_map, tainan_towns_map,
             lisa_map, HCSA_sig_map, widths = c(.5, .5))
```

::: callout-note
## Interpretation of Getis-Ord Gi and Gi\*

-   A hot spot area: significant and positive if location i is associated with relatively high values of the surrounding locations.

-   A cold spot area: significant and negative if location i is associated with relatively low values in surrounding locations.
:::

**Interpreting the results**

By comparing all the four maps above, we are able to come up with the following conclusions:

-   Certain villages in 安南區 are cold spot areas while some are hot spot areas

-   However, majority of the villages in 安南區 are cold spot areas. These cold spot areas have relatively low number of dengue cases reported (ranging from 0 to 41 number of dengue cases)

-   The villages identified as hot spot areas in 安南區 and 永康區 have relatively high number of dengue cases reported (ranging from 211 to 357 number of dengue cases)

-   Certain villages in 東區 are identify as hot spot areas. These hot spot areas have relatively high number of dengue cases reported (ranging from 91 to 145)

Let us find out the names of these villages that have high number of dengue cases reported

```{r}
# Find the row with the highest gi_star among the filtered data
hotspot_areas <- HCSA_sig %>%
  arrange(desc(gi_star)) %>% 
  head(3)

cat("Villages with high number of dengue cases reported (TOWNNAME_VILLNAME): ", hotspot_areas$TOWNNAME_VILLNAME)
```

# 7.0 Emerging Hot Spot Analysis (EHSA)

Emerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method used for revealing and describing how hot spot and cold spot areas evolve over time. We will be using the spacetime cube that was created previously.

## 7.1 Derive Spatial Weights

Firstly, we need to derive the spatial weights.

```{r}
tainan_dengue_nb <- tainan_dengue_st %>%
  activate("geometry") %>%
  mutate(nb = include_self(st_contiguity(geometry)),
         wt = st_inverse_distance(nb, geometry,
                                  scale = 1,
                                  alpha = 1),
         .before = 1) %>%
  set_nbs("nb") %>%
  set_wts("wt")

head(tainan_dengue_nb)
```

## 7.2 Compute Gi\* statistics

Next, we will compute the Gi\* statistics using local_gstar_perm() function.

```{r}
gi_stars <- tainan_dengue_nb %>% 
  group_by(EPIWEEK) %>% 
  mutate(gi_star = local_gstar_perm(
    num_dengue_cases, nb, wt)) %>% 
  tidyr::unnest(gi_star)
```

## 7.3 Mann-Kendall Test

The Mann-Kendall statistical test for trend is used to assess whether a set of data values is increasing over time or decreasing over time, and whether the trend in either direction is statistically significant. The null and alternative hypotheses we have are:

-   H~0~ (null hypothesis): There is no monotonic trend in the series
-   H~1~ (alternative hypothesis): A trend exists (i.e. this trend can be positive, negative or non-null)

Statistically, we select the confident interval as 95%. Therefore, the significance level (alpha value ⍺) = 0.05. We will be select 安南區_溪墘里 as our study area since it has reported the highest number of dengue cases.

```{r}
cbg <- gi_stars %>% 
  ungroup() %>% 
  filter(TOWNNAME_VILLNAME == "安南區_溪墘里") |> 
  select(TOWNNAME_VILLNAME, EPIWEEK, gi_star)
```

```{r}
p <- ggplot(data = cbg, 
       aes(x = EPIWEEK, 
           y = gi_star)) +
  geom_line() +
  theme_light()

ggplotly(p)
```

**Interpreting the results**

By the looking at the graph of Gi\* plotted against EPIWEEK, we observed a downward trend. This is statistically confirmed by the Mann-Kendall Test. Thus, we can reject the null hypothesis that there is no monotonic trend and infer that as time goes by, the spread of dengue cases in 安南區_溪墘里 gradually decreases in comparison to the other villages.

```{r}
cbg %>%
  summarise(mk = list(
    unclass(
      Kendall::MannKendall(gi_star)))) %>% 
  tidyr::unnest_wider(mk)
```

```{r}
ehsa <- gi_stars %>%
  group_by(TOWNNAME_VILLNAME) %>%
  summarise(mk = list(
    unclass(
      Kendall::MannKendall(gi_star)))) %>%
  tidyr::unnest_wider(mk)
```

```{r}
emerging <- ehsa %>% 
  arrange(sl, abs(tau)) %>% 
  slice(1:5)
```

## 7.4 Performing Emerging Hotspot Analysis

```{r}
ehsa <- emerging_hotspot_analysis(
  x = tainan_dengue_st, 
  .var = "num_dengue_cases", 
  k = 1, 
  nsim = 99
)
```

### 7.4.1 Visualising the distribution of EHSA classes

```{r}
ggplot(data = ehsa,
       aes(x = classification)) +
  geom_bar() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
```

**Interpreting the results**

-   More than 80 villages are classified as oscillating hotspots. This means that these villages are statistically significant hot spot for the final time-step interval that has a history of also being a statistically significant cold spot during a prior time step.

-   Less than 10 villages are classified as new hotspot. This means that these villages are statistically significant hot spot for the final time step and has never been a statistically significant hot spot before.

### 7.4.2 Visualising EHSA

```{r}
tainan_ehsa <- tainan_towns_sf %>%
  left_join(ehsa,
            by = join_by(TOWNNAME_VILLNAME == location))
```

```{r}
ehsa_sig <- tainan_ehsa  %>%
  filter(p_value < 0.05)
tmap_mode("plot")
tm_shape(tainan_ehsa) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(ehsa_sig) +
  tm_fill("classification") + 
  tm_borders(alpha = 0.4)
```

# 8.0 References

-   <https://en.wikipedia.org/wiki/Geary%27s_C>

-   <https://en.wikipedia.org/wiki/Moran%27s_I>

-   <https://www.linkedin.com/pulse/exploratory-spatial-data-analysis-autocorrelation-thomas-dao->

-   <https://www.paulamoraga.com/book-spatial/spatial-autocorrelation.html>

-   <https://is415-ay2023-24t2.netlify.app/lesson/lesson05/lesson05-glsa>
